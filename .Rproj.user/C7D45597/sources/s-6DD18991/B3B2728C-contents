# Posibles soluciones

## Ejercicio 1

### Enunciado

Utilizando R, calcular **el valor presente** de los siguientes flujos de caja:

Año 1: -300
Año 2: +100
Año 3: +250

Tasa de descuento: 7.0% anual.

### Posible solución

```{r}
a <- -300
b <- +100
c <- +250

d <- 7.0/100 # 7.0%

e <- (a/(1+d)^1) + (b/(1+d)^2) + (c/(1+d)^3)
e  # 11.04
```

También es posible solucionar este ejercicio utilizando p.ej. el paquete "FinCal" de R, de la siguiente forma:

```{r}
library(FinCal)
?npv # net present value
tasa <- d
flujo.de.caja <- c(0, a, b, c) # 0 para el año 0
f <- npv(r = tasa, cf = flujo.de.caja)
f
```

## Ejercicio 2

### Enunciado - parte a

- Crear un vector "vector1" con los números "3" y "4" y convertirlo a un data frame y asignar el resultado a una variable "data1"
- Mostrar el nombre de las columnas del data frame "data1"
- Acceder al primer elemento de este data frame (3) y mostrarlo en la pantalla


### Posible solución

```{r}
vector1 <- c(3,4)
vector1
class(vector1)

data1 <- as.data.frame(vector1) # convierte a un data frame
data1 # observe el título de la primera columna del data frame
class(data1)
colnames(data1)
data1[1, ]
```

### Enunciado - parte b

- Crear un vector "vector2" con los siguientes tres *carateres*  "3", "4" y "5" y convertir este vector a un data frame y asignar el resultado a una variable "data2"
- Mostrar el resultado de la conversión, utilizando la función class()

### Posible solución

```{r}
vector2 <- c("3", "4", "5")
class(vector2)
data2 <- as.data.frame(vector2)
class(data2)
```


### Enunciado - parte c

- Ahora, convertir el contenido de este data frame "data2" (caracteres) al tipo de dato "numeric". Es decir, convertir el contenido a tres números y asignar el resultado a una variable "data3"
- Mostrar el resultado de la conversión, utilizando la función class()

### Posible solución

```{r}
data3 <- as.numeric(data2[,1])
class(data3)
data3
```

### Enunciado - parte d

- Crear un vector "vector3" con los 6 estratus (seis categorias: 1 a 6), como se utilizan p.ej. en Colombia. Es decir, crear este vector3 de tipo de dato "factor"
- Convertir el contenido de este vector al tipo de dato "numeric". Es decir, convertir el contenido a seis números y asignar el resultado a una variable "data4"
- Mostrar el resultado de la conversión, utilizando la función class()

### Posible solución

```{r}
vector3 <- as.factor(c(1:6))
class(vector3)
vector3
data4 <- as.numeric(vector3)
class(data4)
data4
```

### Enunciado - parte e

- Crear un data frame "df10" con dos columnas. La primera columna "x" debe contener los datos 1, 2 y 3 y la segunda "y" los datos 4, 5 y 6. Sin embargo, los tres datos de la primera columna deben ser del tipo de dato "numeric" (numérico). Mientras los tres datos de la segunda columna deben ser del tipo de dato "factor" (categórica)
-Ahora convertir los valores de la segunda columna (y), del tipo de dato "factor" a "numeric"
-Mostrar que los valores de la segunda columa "y" ahora realmnente son del tipo de dato "numeric"
 
### Posible solución

```{r}
x <- 1:3
y <- as.factor(c(4:6))
df10 <- data.frame(x,y)
class(df10)
df10

#conversión de factor a númerico
#df10$y <- as.numeric(df10$y)
#df10
#Ojo: ¿Qué pasó aquí?
# Respuesta: Si se utiliza la función as.numeric para un factor, esto convertirá los niveles a numéricos, no a los valores reales. Por lo tanto, se necesita adicionalmente la función as.character para convertir primero el factor a character y luego as.numeric
df10$y <- as.numeric(as.character(df10$y))
class(df10$y)
df10$y
```

## Ejercicio 3

### Enunciado

- Crear un archivo de tipo CSV con los siguientes datos, distribuidos en cinco filas y 4 columnas, y seperados por punto y coma (;):

- #;Estrato;Ingresos;Nombre
- 1;1;100.0;Jaime
- 2;2;150;María
- 3;2;140;Paula
- 4;5;90;Cristina

- Cargar estos datos desde el archivo csv a una variable "dataset10" en R / RStudio. Los datos de las primeras tres columnas deben ser númericos (int o num) y de la útlima de tipo "character" (chr)
- Mostrar la estructura del "dataset10" en la pantalla
- Cambiar el nombre de la primera columna al texto "numero"

### Posible solución

```{r}
dataset10 <- read.csv('ejercicio3.csv', sep = ";", header = TRUE, stringsAsFactors = FALSE)
str(dataset10)

names(dataset10)[1] <- "numero"
str(dataset10)
```

## Ejercicio 4

### Enunciado

- Analizar el paquete "DataExplorer" de R para explorar datos
- Cargar los datos de la siguiente forma: 

url="http://freakonometrics.free.fr/german_credit.csv"
dataset <- read.csv(url, header = TRUE, sep = ",")

- Luego, utilizar el el paquete "DataExplorer", utilizando la función "plot_str()"
- Visualizar los valores faltantes, utilizando una función adecuada del paquete "DataExplorer"
- Crear histogramas para (las variables continúas d)el "dataset", utilizando una función adecuada del paquete "DataExplorer"
- Crear un data frame "dataset2", que contiene los valores de las columnas "Age..years." y "Credit.Amount" del dataset
- Visualizar las correlaciones entre los valores de las columnas "Age..years." y "Credit.Amount" del dataset2
-Aplciar la función plot_bar del paquete "DataExplorer" al dataset

### Posible solución

```{r}
url="http://freakonometrics.free.fr/german_credit.csv"
dataset <- read.csv(url, header = TRUE, sep = ",")

library(DataExplorer)
plot_str(dataset)
plot_missing(dataset)
plot_histogram(dataset)
col <- c("Credit.Amount", "Age..years.")
dataset2 <- dataset[col]
plot_correlation(dataset2)
plot_bar(dataset)
```

## Ejercicio 5

### Enunciado

- Cargar el paquete "tidyverse"
- Utilizar el conjunto de datos "iris", que se instaló con R: data(iris)
- Ver la siguiente descripción al respecto: https://es.wikipedia.org/wiki/Conjunto_de_datos_flor_iris
- Mostrar las primeras 5 filas de "iris" en la pantalla
- Agrupar los datos de iris por la columna "Species" y asignar el resultado a una variable "iris.por.species", utilizando tidyverse
- Mostrar las últimas 3 filas de "iris.por.species"
- Agregar una columna a "iris.por.species", donde se muestra el valor promedio para los valores de la columna "Sepal.Length", utilizando tidyverse

### Posible solución

```{r}
library(tidyverse)
data(iris)
head(iris, 5)

iris.por.species <- iris %>%
  group_by(Species)
tail(iris.por.species, 3)

iris.por.species <- iris.por.species %>% 
  summarize(promedio = mean(Sepal.Length))
tail(iris.por.species, 3)
```

## Ejercicio 6

### Enunciado

- Utilizar el conjunto de datos "iris", que se instaló con R: data(iris)
- Ver la siguiente descripción al respecto: https://es.wikipedia.org/wiki/Conjunto_de_datos_flor_iris
- Mostrar las primeras 5 filas de "iris" en la pantalla
- Utlizando la función apply, calcular el promedio de cada columna del dataset "iris", que contiene números
- Realizar el mismo cálculo, utilizando la función lapply (en lugar de apply())
- Con base en los resultados obtenidos, explicar la diferencia entre apply y lapply
- Ahora bien, realizar el mismo cálculo (promedio de las columnas), pero utilizando un ciclo (bucle), aplicando la función for()

### Posible solución

```{r}
data(iris)
head(iris, 5)
str(iris)
apply(iris[,-5], 2, mean, na.rm=TRUE)
lapply(iris[,-5], mean, na.rm=TRUE)
```

Observe: lapply devuelve una lista, mientras apply devuelve un vector con los resultados

Utilizando **for** en lugar de apply():

```{r}
output <-  NULL # un vector vacío
n <- ncol(iris) # número de columnas
for(i in 1:(n-1)){
  output[i] <- mean(iris[,i]) # aqui as.numeric es obligatorio
}
print(output)
```

## Ejercicio 7

### Enunciado

- Generar en R 15 numeros aleatorios, con base en una distribución uniforme, entre 1 (minimum) y 50 (máximum) y asignar el resultado a una variable "vector.aleatorio1"
- Luego, generar en R otros 15 numeros aleatorios, con base en una distribución normal, con una media de "0" y una desviación estandar de "1", y asignar el resultado a una variable "vector.aleatorio2"
- Cobinar los valores de los 2 vectores en un único vector "vector.aleatorio3" en R / RStudio
- Realizar el "ajuste a la distribución", utilizando el paquete "rriskDistributions"

### Posible solución

```{r}
vector.aleatorio1 <- runif(15, 1, 50)
str(vector.aleatorio1)
vector.aleatorio2 <- rnorm(15, mean = 0, sd = 1)
str(vector.aleatorio2)
vector.aleatorio3 <- c(vector.aleatorio1, vector.aleatorio2)
str(vector.aleatorio3)

library(rriskDistributions)
res <-  fit.cont(vector.aleatorio3)
```

## Ejercicio 8

### Enunciado

Si se requiere saber, cuántas personas de  una región estan dispuestas de trabajar en el extranjero, y si se puede asumir que la población de la región que trabaja o puede trabajar es de 50 mil personas, ¿qué tan grande debe ser la muestra para una encuesta que busca determinar esta disposición para trabajar en otro país?

Asumimos para la generación de esta muestra que el margen de error es de 5% y el nivel de confianza requerido es de 95%. P y Q son 0.5

### Posible solución

```{r}
# para poblaciones menor a 100000
muestra.n <- function(N, P, Q, Z, E){
  ((Z^2)*P*Q*N) / ((E^2)*(N-1)+(Z^2)*P*Q)
}
muestra.n(50000, 0.5, 0.5, 1.96, 0.05)
```
Respuesta: La muestra debe tener 382 personas

## Ejercicio 9

### Enunciado

Realizar un árbol decisión en R, utilizando el paquete "ISLR" y el dataset "Smarket", que viene con este paquete, para clasificar los datos del dataset con el objetivo de determinar, si el mercado (índice S&P500) va a subir o bajar.

- Mostrar las primeras 3 filas de este dataset "Smarket" y analizar de esta forma las columnas (variables) del dataset. Nota: Las variables "Lag.." se refieren a precios determinados en el mercado de capitales (S&P Stock Market Data) y refleja rendimientos diarios de este índice búrsatil, expresado como porcentaje. Utilizar ?Smarket para consultar las páginas de ayuda al respecto
- Mostrar, la estructura de este dataset, utilizando la función str()
- Utilizando la semilla 123 (set.seed(123)), dividir los datos en una parte de entrenamiento (train_data) y otra parte de pruebas (test_data). 66% del total de los datos se deben utilizar para el entrenamiento y el resto para las pruebas
- Analizar el paquete "C50", que permite construir un árbol de decisión
- Construir un árbol de decisión sencillo con el nombre "modelo.AD", utilizando el paquete C50 (con "C" mayúscula), la función C50() y los datos de entrenamiento
- Mostrar los resultados (output), utilizando la función summary() y analizarlos
- Realizar la predicción utilzando el modelo construido y los datos de prueba (test_data), asignando el resultado a una variable "pred"
- Mostrar el resultado de la clasificación en una tabla, utilizando p.ej. la función table()
- Interpretar el resultado obtenido

### Posible Solución

```{r}
library(ISLR)
head(Smarket, n=3)
str(Smarket) # 1250 registros y 
# nota: la variable de salida (de predicción) es de tipo factor

# Particionar los datos en dos partes 66/34
set.seed(123)
d = sort(sample(nrow(Smarket),nrow(Smarket)*0.66, replace=FALSE))
# dividir en una conjunto de  training y test set
train_data <- Smarket[d, ]
test_data  <- Smarket[-d, ]

library(C50)
?C5.0

# crear el árbol de decisión con los datos de entrenamiento
modelo.DT <- C5.0(x = train_data[, -9], y = train_data$Direction) # excluye la columna de la variable de predicción
summary(modelo.DT) 

#Realizar la predicción con los datos de prueba
pred <- predict(modelo.DT, test_data)

# crear la matriz de clasificación
library(gmodels)
CrossTable(test_data$Direction, pred)
#Alternativa
table(test_data$Direction, pred)
```

Respuesta: Todo el modelo esta dominado por la variable "today". Por favor, revisarlo.

## Ejercicio 10

### Enunciado

Realizar una regresión logistica en R, utilizando el paquete "ISLR" y el dataset "Smarket", que viene con este paquete, para clasificar los datos del dataset con el objetivo de determinar, si el mercado (índice S&P500) va a subir o bajar.

- Mostrar las primeras 3 filas de este dataset "Smarket" y analizar de esta forma las columnas (variables) del dataset. Nota: Las variables "Lag.." se refieren a precios determinados en el mercado de capitales (S&P Stock Market Data) y refleja rendimientos diarios de este índice búrsatil, expresado como porcentaje. Utilizar ?Smarket para consultar las páginas de ayuda al respecto
- Mostrar, la estructura de este dataset, utilizando la función str()
- Utilizando la semilla 123 (set.seed(123)), dividir los datos en una parte de entrenamiento (train_data) y otra parte de pruebas (test_data). 66% del total de los datos se deben utilizar para el entrenamiento y el resto para las pruebas
- Realizar un modelo de regresión logística con los datos de entrenamiento, utilizando como variables de entrada únicamente las variables "Lag1", "Lag2" y "Lag3". Asignar el resultado a una variable "modelo.logit", Nota: En este caso no se preocupe de los valores p (p-values) obtenidos para las tres variables de entrada
- Mostrar el resultado de la regresión en la pantalla, utilizando la función summary() para el modelo de la regresión generada
- Luego, realizar la predicción para el S&P500, utilizando el modelo generado y los datos de prueba (test_data) y asignar el resultado (probabilidades) a una variable "probs"
- Si las probabilidades son mayor que 0.5, asigna el valor "1", en el caso contrario el valor "0"
- Mostrar el resultado de la clasificación en una tabla, utilizando p.ej. la función table()
- Interpretar el resultado obtenido

### Posible solución

```{r}
library(ISLR)
head(Smarket)
str(Smarket) # 1250 registros

set.seed(123)
d = sort(sample(nrow(Smarket),nrow(Smarket)*0.66, replace=FALSE))
# dividir en una conjunto de  training y test set
train_data <- Smarket[d, ]
test_data  <- Smarket[-d, ] 

modelo.logit <- glm(Direction ~ Lag1 + Lag2 + Lag3, family = binomial("logit"), data =train_data)

summary(modelo.logit)

# probabilidades:
probs <- predict(modelo.logit, test_data, type = "response")
head(probs)

prediccion <- ifelse(probs > 0.5, 1, 0)
table(prediccion, test_data$Direction)

mean(prediccion) # [1] 0.7670588
```

Conclusión: El modelo comete muchos errores.

## Ejercicio 11

### Enunciado

- Utilizar el paquete "ISLR" y el dataset "Smarket", que viene con este paquete, y 
-"escalar" los datos de la columna "Lag1" de este dataset, utlizando el paquete "scales", y asignar el resultado a una variable "Lag1.scaled"
- Mostrar las últimas 10 filas del resultado en la pantalla

### Posible solución

```{r}
library(ISLR)
head(Smarket)
str(Smarket) # 1250 registros

library(scales)
Lag1.scaled <- scale(Smarket$Lag1)
tail(Lag1.scaled, n=10)
```

