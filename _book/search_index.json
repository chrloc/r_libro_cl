[
["index.html", "Una breve introducción a R con un enfoque financiero y administrativo Sección 1 Prerequisitos", " Una breve introducción a R con un enfoque financiero y administrativo Christian Lochmuller 2019, compilado 2020-02-01 Sección 1 Prerequisitos Los prerequisitos incluyen: Conocimientos en términos de los fundamentos de la programación. Bajar e installar el lenguaje de programación R (“gratuito”): https://www.r-project.org/ Bajar e installar el IDE RStudio Desktop (“gratuito”): https://www.rstudio.com/products/rstudio/download/ Motivación para aprender sobre la programación con R y capacidad de “aprender a aprender”. También es pertinente señalar, que en la nube esta disponible una versión de R / RStudio: https://rstudio.cloud/. Sin embargo, aquí trabaremos con la versión “desktop”. Según Wikipedia, “R es un entorno y lenguaje de programación con un enfoque al análisis estadístico”. Según esta misma fuente, “R proporciona un amplio abanico de herramientas estadísticas”, principalmente en términos de modelos lineales y no lineales, tests estadísticos, análisis de series temporales, algoritmos de clasificación y agrupamiento, etc. R permite también graficar datos en alta calidad. Los usuarios pueden publicar paquetes que extiendan la funcionalidad básica de R. Para mencionar solo un ejemplo, existen paquetes (librerias), que ofrecen funcionalidad “avanzada”, relacionada con las “redes neuronales”, ampliando de esta forma la funcionalidad básica disponible. Esto significa, que se puedan desarrollar aplicaciones nuevas basadas en estos paquetes, que faciliten y mejoren estos paquetes de forma libre y continua, literalmente “construyendo sobre los hombros de otros gigantes”. En la actualidad R no solo ofrece funcionalidad con respecto a operaciones estadísticas, sino también con respecto a nuevos desarrollos como p.ej. el aprendizaje de maquina, la inteligencia artifical y el aprendizaje profundo, también con aplicación financiera. Los paquetes están disponibles, en su gran mayoría, en un repositorio abierto: https://cran.r-project.org/web/packages/, y éstos se pueden bajar libremente a través de la Internet, respetando la licencia de R y RStudio. ¡Bienvenidos a esta breve introducción al lenguaje R con un enfoque y ejemplos financieros y administrativos! "],
["intro.html", "Sección 2 Introducción 2.1 Objetivo 2.2 Usar R como “calculadora” 2.3 Asignar un valor numérico a una variable 2.4 Buscar ayuda 2.5 Organizar el código 2.6 Una opción para explorar: Swirl 2.7 Ejercicio 1", " Sección 2 Introducción 2.1 Objetivo El objetivo de esta sección es introducir al lenguaje R, como utilizarla como calculadora, como organizar el código, etc. 2.2 Usar R como “calculadora” R, como otros lenguajes de programación, se puede utilizar como una calculadora. Esto se muestra a continuación, utilizando algunas operaciones matemáticas comunes como ejemplo. 1+1 # 2 ## [1] 2 3 * 4 * 2 # 24 ## [1] 24 6 / 2 # 3 ## [1] 3 8 / 3 # 2.666667 ## [1] 2.666667 3 * 4 + 5 # 17 ## [1] 17 3 * (4 + 5) # 27 ## [1] 27 2.3 Asignar un valor numérico a una variable A continuación, se presentan algunos ejemplos al respecto: Asignar el valor “2” a la variable “x” Imprimir el valor de la variable “x” a la consola Asignar el valor “5” a la variable “b”, asignar el valor de “b” a la variable “a” Mostrar los valores de “b” y “a” Mostrar la clase del objeto (variable) “a” Observe, el comando para asignar un valor a una variable (objeto) es: &lt;- (ALT + -) x &lt;- 2 x ## [1] 2 a &lt;- b &lt;- 5 b ## [1] 5 a ## [1] 5 class(a) ## [1] &quot;numeric&quot; 2.4 Buscar ayuda F1 ?+ “nombre de la función o del paquete” help(), p.ej.: help(lm) 2.4.1 Un ejemplo La página de ayuda para el paquete “quandmod”, que tenemos que cargar pimero. Si faltan otros paquetes, se muestra en la consola un posible mensaje de error, y se deben instalar estos paquetes faltantes antes de realizar este ejemplo. library(quantmod) ## Warning: package &#39;quantmod&#39; was built under R version 3.5.3 ## Loading required package: xts ## Loading required package: zoo ## ## Attaching package: &#39;zoo&#39; ## The following objects are masked from &#39;package:base&#39;: ## ## as.Date, as.Date.numeric ## Loading required package: TTR ## Version 0.4-0 included new data defaults. See ?getSymbols. ?quantmod ## starting httpd help server ... ## done 2.5 Organizar el código Se recomienda, explorar el siguiente contenido (“style guides”) para aprender sobre como “organizar” el código para facilitar su lectura y comprensión: Google: https://google.github.io/styleguide/Rguide.html Tidyverse: https://style.tidyverse.org/ 2.6 Una opción para explorar: Swirl Un paquete para ayudar en el proceso de aprender R. https://swirlstats.com/students.html 2.7 Ejercicio 1 Utilizando R, calcular el valor presente de los siguientes flujos de caja: Año 1: -300 Año 2: +100 Año 3: +250 Tasa de descuento: 7.0% anual. "],
["tipos.html", "Sección 3 Usar tipos de datos 3.1 Objetivo 3.2 Datos booleanos y operadores de lógica 3.3 Tipo de dato fecha 3.4 Tipo de dato vector 3.5 Vectores de caracteres (strings) 3.6 Acceder a elementos de un vector 3.7 Factors (variables categóricas) 3.8 Funciones matemáticas para vectores 3.9 Usar pipes (un concepto “interesante”) 3.10 Data frames 3.11 Listas 3.12 Ejercicio 2", " Sección 3 Usar tipos de datos 3.1 Objetivo A continuación, se presenta información sobre diferentes tipos de datos, que ofrece R, y como manipularlos. 3.2 Datos booleanos y operadores de lógica Estos operadores devuelven el valor “TRUE” (verdadero) o “FALSE” (falso). A continuación, se muestran algunos ejemplos. Dónde: TRUE = 1 y FALSE = 0. TRUE * 2 ## [1] 2 FALSE * 2 ## [1] 0 d &lt;- TRUE d ## [1] TRUE is.logical(d) ## [1] TRUE class(d) ## [1] &quot;logical&quot; # ¿2 es igual a 3? 2 == 3 ## [1] FALSE # ¿2 no es igual a 3? 2 != 3 ## [1] TRUE 2 &lt;= 3 ## [1] TRUE 2 &gt;= 3 ## [1] FALSE # &quot;¿datos&quot; es igual a &quot;info&quot;? &quot;datos&quot; == &quot;info&quot; ## [1] FALSE &quot;datos&quot; &lt; &quot;info&quot; ## [1] TRUE 3.3 Tipo de dato fecha La función as.Date() vs. la función as.POSIXct(): Convertir el siguiente string “2014-06-08” en una fecha con el nombre (de la variable) “fecha1” (notación angloamericana: YYYY-MM-DD) Mostrar esta fecha “fecha1” en la pantalla Mostrar la clase de la variable “fecha1”, utilizando el comando class() Convertir esta variable “fecha1” a un número Mostrar este número en la pantalla y dar una interpretación de este número Convertir el siguiente string “2014-06-08 17:42” en una fecha con el nombre (de la variable) “fecha2” (notación de tipo time stamp: YYYY-MM-DD hh:mm) Mostrar esta fecha “fecha2” en la pantalla Mostrar la clase de la variable “fecha2”, utilizando el comando class() Convertir esta variable “fecha2” a un número Mostrar este número en la pantalla y dar una interpretación de este número fecha1 &lt;- as.Date(&quot;2014-06-08&quot;) fecha1 ## [1] &quot;2014-06-08&quot; class(fecha1) ## [1] &quot;Date&quot; as.numeric(fecha1) # convertir una fecha a tipo de dato &quot;numérico&quot; devuelve la cantidad de días desde 1970 ## [1] 16229 fecha2 &lt;- as.POSIXct(&quot;2014-06-08 17:42&quot;) fecha2 ## [1] &quot;2014-06-08 17:42:00 -05&quot; class(fecha2) ## [1] &quot;POSIXct&quot; &quot;POSIXt&quot; as.numeric(fecha2) # devuelve la cantidad de segundos desde 1970 ## [1] 1402267320 Una manipulación más fácil de las fechas se puede lograr utilizando el paquete “lubridate” y el paquete “chron” de R. 3.4 Tipo de dato vector Crear un vector numérico “x”, que contiene los números 1 hasta 10 Mostrar el contenido del vector “x” en la pantalla Crear un vector numérico “y”, que contiene los números 11 hasta 1 Mostrar el contenido del vector “y” en la pantalla Multiplicar el contenido del vector “x” por 2 y mostrar el resultado en la pantalla Luego, agregar 2 al contenido del vector “x” y mostrar el resultado en la pantalla Después, restar 3 del contenido del vector “x” y mostrar el resultado en la pantalla Dividir el contenido del vector “x” por 4 y mostrar el resultado en la pantalla Llevar el contenido del vector “x” a la 2 y mostrar el resultado en la pantalla Calcular la raíz cuadrada del contenido del vector “x” y mostrar el resultado en la pantalla x &lt;- c (1, 2, 3, 4, 5, 6, 7, 8, 9, 10) x ## [1] 1 2 3 4 5 6 7 8 9 10 y &lt;- 11:1 y ## [1] 11 10 9 8 7 6 5 4 3 2 1 x * 2 ## [1] 2 4 6 8 10 12 14 16 18 20 x + 2 ## [1] 3 4 5 6 7 8 9 10 11 12 x - 3 ## [1] -2 -1 0 1 2 3 4 5 6 7 x / 4 ## [1] 0.25 0.50 0.75 1.00 1.25 1.50 1.75 2.00 2.25 2.50 x^2 ## [1] 1 4 9 16 25 36 49 64 81 100 sqrt(x) ## [1] 1.000000 1.414214 1.732051 2.000000 2.236068 2.449490 2.645751 ## [8] 2.828427 3.000000 3.162278 Crear un vector numérico “x” con los números 1 a 10 Luego, crear un vector “y” con números desde -5 hasta +4 Sumar el contenido del vector “x” con el contenido del vector “y” Determinar la longitud del vector “x” Determinar la longitud del vector “y” ¿Cuál es la longitud de la suma de los vectores “x” y “y”? ¿Qué pasa, si se suman vectores de una longitud diferente, p.ej.: x + c(1,2), donde c(1,2) genera un vector con los números 1 y 2? ¿Cuál es la longitud del resultado (length(x + c(1,2)) ? ¿Qué pasa, si un vector no es un múltiple del otro, en términos de su longitud: x + c(1,2,3)? x &lt;- 1:10 y &lt;- -5:4 x + y ## [1] -4 -2 0 2 4 6 8 10 12 14 length(x) ## [1] 10 length(y) ## [1] 10 length(x + y) #10 ## [1] 10 # Ojo: # El vector más corto se recicla. # Esto significa que sus elementos se repiten hasta # existe coincidencia con cada elemento del vector más largo. x + c(1, 2) ## [1] 2 4 4 6 6 8 8 10 10 12 length(x + c(1, 2)) ## [1] 10 x + c(1, 2, 3) # termina con una advertencia (warning) ## Warning in x + c(1, 2, 3): longitud de objeto mayor no es múltiplo de la ## longitud de uno menor ## [1] 2 4 6 5 7 9 8 10 12 11 x &lt;= 5 ## [1] TRUE TRUE TRUE TRUE TRUE FALSE FALSE FALSE FALSE FALSE 3.5 Vectores de caracteres (strings) Un ejemplo con diferentes frutas como elementos de un solo vector “q”. Crear un vector “q” con los siguientes 10 elementos: Manzana, Pera, Piña, Naranja, Mandarina, Banano, Durazno, Uva, Fresa, Melocotón. Determinar para “q” el número de caracteres de cada elemento del vector, utilizando la función nchar() q &lt;- c(&quot;Manzana&quot;, &quot;Pera&quot;, &quot;Piña&quot;, &quot;Naranja&quot;, &quot;Mandarina&quot;, &quot;Banano&quot;, &quot;Durazno&quot;, &quot;Uva&quot;, &quot;Fresa&quot;, &quot;Melocotón&quot;) nchar(q) ## [1] 7 4 4 7 9 6 7 3 5 9 3.6 Acceder a elementos de un vector Utilicaremos el vector “x” anteriormente creado, que contiene los números 1 hasta 10 Imprimir el contenido del vector “x” a la pantalla (consola) Acceder al primer elemento del vector “x”, utilizando la notación de corchetes Acceder a todos los elementos del vector “x” menos el primero Acceder al primer y cuarto elemento del vector “x” únicamente Acceder a los primeros tres elementos del vector “x” únicamente x ## [1] 1 2 3 4 5 6 7 8 9 10 x[1] # primer elemento ## [1] 1 x[-1] # todos los elementos del vector menos el primer elemento ## [1] 2 3 4 5 6 7 8 9 10 x[c(1, 4)] # el primer elemento y el cuarto elemento ## [1] 1 4 x[1:3] # los primeros tres elementos ## [1] 1 2 3 Proveer un nombre para cada elemento del vector, utilizando una pareja de tipo “nombre-valor”. Crear un vector con las siguientes parejas de tipo “nombre-valor”: Uno: a; Dos: f; Tres: m Crear un vector “v” con los números 1 hasta 3 Asignar como nombre a los tres elementos de “v” las letras a, b y c, utilizando la función names() e Imprimir el contenido de “v” a la pantalla c(Uno=&quot;a&quot;, Dos=&quot;f&quot;, Tres=&quot;m&quot;) ## Uno Dos Tres ## &quot;a&quot; &quot;f&quot; &quot;m&quot; v &lt;- 1:3 names(v) &lt;-c(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;) v ## a b c ## 1 2 3 3.7 Factors (variables categóricas) Utilicaremos el vector “q” anteriormente creado, que contiene los 10 nombres de frutas diferentes. Crear un nuevo vector “q2” con los siguientes elementos: q (es decir el vector ya creado), Manzana, Piña, Pera, Melocotón, Manzana, Pera Determinar la longitud de “q2”, utilizando la función length() Convertir “q2” al tipo de dato “factor” (es decir, a una variable categórica) y asignar el resultado a una variable “q2Factor” Imprimir “q2Factor” a la pantalla Determinar la clase del objeto “q2Factor” q2 &lt;-c(q, &quot;Manzana&quot;, &quot;Piña&quot;, &quot;Pera&quot;, &quot;Melocotón&quot;, &quot;Manzana&quot;, &quot;Pera&quot;) length(q2) ## [1] 16 q2Factor &lt;- as.factor(q2) q2Factor ## [1] Manzana Pera Piña Naranja Mandarina Banano Durazno ## [8] Uva Fresa Melocotón Manzana Piña Pera Melocotón ## [15] Manzana Pera ## 10 Levels: Banano Durazno Fresa Mandarina Manzana Melocotón ... Uva class(q2Factor) ## [1] &quot;factor&quot; 3.8 Funciones matemáticas para vectores Utilicaremos el vector “x” anteriormente creado, que contiene los números 1 hasta 10 Determinar el promedio de los valores del vector “x” Consultar todas funciones que contienen la secuencia de letra “mea”, incluyendo p.ej. “mean”, utilizando la función apropos() Generar un vector “z” con los siguientes 7 elementos: 1, 2, NA, 8, 3, NA, 3. Donde NA representa un dato faltante Generar un vector “zChar” con los siguientes 3 elementos: Manzana, NA, Pera Realizar una prueba (de tipo booleana), si los vectores “z” y “zChar” contienen elementos NA, utilizando la función is.na() Determinar el promedio para los valores del vector “z” Crear el vector “p” con los siguientes elementos: 1, NULL, 3 Imprimir “p” a la pantalla Determinar la longitud de “p” Asignar el valor NULL a una variable “d” Realizar una prueba (de tipo booleana), si “d” es nulo, utilizando la función is.null() mean(x) # el promedio ## [1] 5.5 apropos(&quot;mea&quot;) ## [1] &quot;.colMeans&quot; &quot;.rowMeans&quot; &quot;colMeans&quot; ## [4] &quot;influence.measures&quot; &quot;kmeans&quot; &quot;mean&quot; ## [7] &quot;mean.Date&quot; &quot;mean.default&quot; &quot;mean.difftime&quot; ## [10] &quot;mean.POSIXct&quot; &quot;mean.POSIXlt&quot; &quot;rollmean&quot; ## [13] &quot;rollmean.default&quot; &quot;rollmeanr&quot; &quot;rowMeans&quot; ## [16] &quot;runMean&quot; &quot;weighted.mean&quot; z &lt;- c(1, 2, NA, 8, 3, NA, 3) zChar &lt;- c(&quot;Manzana&quot;, NA, &quot;Pera&quot;) is.na(z) ## [1] FALSE FALSE TRUE FALSE FALSE TRUE FALSE is.na(zChar) ## [1] FALSE TRUE FALSE mean(z) ## [1] NA mean(z, na.rm=TRUE) # #remover los datos faltantes primero, utilizando el parametro na.rm=TRUE ## [1] 3.4 p &lt;- c(1, NULL,3) p ## [1] 1 3 length(p) # es decir el valor nulo, NULL, no se almacena en &quot;p&quot; ## [1] 2 d &lt;- NULL is.null(d) ## [1] TRUE 3.9 Usar pipes (un concepto “interesante”) Nota: Pipe significa “then”, es decir “entonces”. Un pipe se lea desde la izquierda hacia la derecha. Instalar y cargar el paquete “magrittr”, que se requiere para aplicar los “pipes”, utilizando install.packages(“magrittr”, dependencies=TRUE) y luego library(magrittr) Determinar el promedio de “x”, donde x es un vector de números de 1 a 10 (ya hemos hecho este cálculo) Luego, realizar este mismo cálculo utilizando el operador pipe (%&gt;%), que se puede producir in RStudio así: CTRL + SHIFT + m Generar un vector “z” con los siguientes elementos: 1, 2, NA, 8, 3, NA, 3 Determinar la suma de los elementos “NA” en “z” Luego, realizar este mismo cálculo utilizando el operador pipe (%&gt;%) library(tidyverse) # para utilizar p.ej. pipes ## -- Attaching packages -- tidyverse 1.2.1 -- ## v ggplot2 3.1.0 v purrr 0.2.5 ## v tibble 2.1.3 v dplyr 0.8.3 ## v tidyr 1.0.2 v stringr 1.3.1 ## v readr 1.3.1 v forcats 0.3.0 ## Warning: package &#39;tibble&#39; was built under R version 3.5.3 ## Warning: package &#39;tidyr&#39; was built under R version 3.5.3 ## Warning: package &#39;dplyr&#39; was built under R version 3.5.3 ## -- Conflicts ----- tidyverse_conflicts() -- ## x dplyr::filter() masks stats::filter() ## x dplyr::first() masks xts::first() ## x dplyr::lag() masks stats::lag() ## x dplyr::last() masks xts::last() mean(x) ## [1] 5.5 x %&gt;% mean(.) ## [1] 5.5 z &lt;- c(1, 2, NA, 8, 3, NA, 3) sum(is.na(z)) ## [1] 2 z %&gt;% is.na %&gt;% sum(.) ## [1] 2 3.10 Data frames El data frame es un tipo de dato muy común y además un tipo de dato muy útil, que organiza los datos en filas y columnas. El data frame es parecido a una hoja de cálculo en MS-Excel Crear un vector “x” con los números de 10 a 1 Crear un vector “y” con los números de -4 a 5 Crear un vector “q” con los siguientes elementos (frutas): Manzana, Pera, Piña, Naranja, Mandarina, Banano, Durazno, Uva, Fresa, Melocotón Generar un data frame “df”, que contiene “x”, “y” y “q”. Es decir, los 3 vectores, donde cada vector conforma una columna en el data frame “df” Imprimir el contenido del data frame “df” a la pantalla x &lt;- 10:1 y &lt;- -4:5 q &lt;- c(&quot;Manzana&quot;, &quot;Pera&quot;, &quot;Piña&quot;, &quot;Naranja&quot;, &quot;Mandarina&quot;, &quot;Banano&quot;, &quot;Durazno&quot;, &quot;Uva&quot;, &quot;Fresa&quot;, &quot;Melocotón&quot;) df &lt;- data.frame(x, y, q) df ## x y q ## 1 10 -4 Manzana ## 2 9 -3 Pera ## 3 8 -2 Piña ## 4 7 -1 Naranja ## 5 6 0 Mandarina ## 6 5 1 Banano ## 7 4 2 Durazno ## 8 3 3 Uva ## 9 2 4 Fresa ## 10 1 5 Melocotón También hubiera sido posible, asignar nombres (para las columnas) en el proceso de generar el data frame, lo que normalmente es una “buena idea”. Primero=x, Segundo=y, Fruta=q df &lt;- data.frame(Primero=x, Segundo=y, Fruta=q) df ## Primero Segundo Fruta ## 1 10 -4 Manzana ## 2 9 -3 Pera ## 3 8 -2 Piña ## 4 7 -1 Naranja ## 5 6 0 Mandarina ## 6 5 1 Banano ## 7 4 2 Durazno ## 8 3 3 Uva ## 9 2 4 Fresa ## 10 1 5 Melocotón Determinar la cantidad de filas, que tiene el data frame “df” Determinar la cantidad de columnas, que tiene el data frame “df” Determinar las dimensiones (cantidad de filas y columnes) del data frame “df” Mostrar los nombres de las filas del data frame “df” Mostrar los nombres de las columnas del data frame “df” Asignar como nombres de las filas las siguientes etiquetas (nombres): Uno, Dos, Tres, Cuatro, Cinco, Seis, Siete, Ocho, Nueve, Diez. Mostrar los nombres de las filas del data frame “df” nrow(df) ## [1] 10 ncol(df) ## [1] 3 dim(df) ## [1] 10 3 names(df) ## [1] &quot;Primero&quot; &quot;Segundo&quot; &quot;Fruta&quot; rownames(df) ## [1] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; &quot;5&quot; &quot;6&quot; &quot;7&quot; &quot;8&quot; &quot;9&quot; &quot;10&quot; colnames(df) ## [1] &quot;Primero&quot; &quot;Segundo&quot; &quot;Fruta&quot; rownames(df) &lt;- c(&quot;Uno&quot;, &quot;Dos&quot;, &quot;Tres&quot;, &quot;Cuatro&quot;, &quot;Cinco&quot;, &quot;Seis&quot;, &quot;Siete&quot;, &quot;Ocho&quot;, &quot;Nueve&quot;, &quot;Diez&quot;) rownames(df) ## [1] &quot;Uno&quot; &quot;Dos&quot; &quot;Tres&quot; &quot;Cuatro&quot; &quot;Cinco&quot; &quot;Seis&quot; &quot;Siete&quot; ## [8] &quot;Ocho&quot; &quot;Nueve&quot; &quot;Diez&quot; Cambiar los nombres de las filas nuevamente a los valores iniciales. Es decir, al indice genérico. Mostrar los nombres de las filas del data frame “df” Mostrar las primeras 6 filas del data frame “df” Mostrar las primeras 8 filas del data frame “df” Mostrar las últimas 6 filas del data frame “df” Mostrar la clase del objeto (data frame) “df” rownames(df) &lt;- NULL rownames(df) ## [1] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; &quot;5&quot; &quot;6&quot; &quot;7&quot; &quot;8&quot; &quot;9&quot; &quot;10&quot; head(df) # las primeras 6 filas ## Primero Segundo Fruta ## 1 10 -4 Manzana ## 2 9 -3 Pera ## 3 8 -2 Piña ## 4 7 -1 Naranja ## 5 6 0 Mandarina ## 6 5 1 Banano head(df, 8) # las primeras 8 filas ## Primero Segundo Fruta ## 1 10 -4 Manzana ## 2 9 -3 Pera ## 3 8 -2 Piña ## 4 7 -1 Naranja ## 5 6 0 Mandarina ## 6 5 1 Banano ## 7 4 2 Durazno ## 8 3 3 Uva tail(df) ## Primero Segundo Fruta ## 5 6 0 Mandarina ## 6 5 1 Banano ## 7 4 2 Durazno ## 8 3 3 Uva ## 9 2 4 Fresa ## 10 1 5 Melocotón class(df) ## [1] &quot;data.frame&quot; Acceder a todos los datos de la columna “Fruta” del data frame “df” Acceder al elemento en la tercera fila y segunda columna del data frame “df” Mostrar los elementos en la tercera fila, en la columna 2 y 3 del data frame “df” Determinar la clase de los elementos (datos) en la columna “Fruta” del data frame “df” df$Fruta ## [1] Manzana Pera Piña Naranja Mandarina Banano Durazno ## [8] Uva Fresa Melocotón ## 10 Levels: Banano Durazno Fresa Mandarina Manzana Melocotón ... Uva #...entrega el mismo resultado: df[, 3] # todos los datos de la columna 3 ## [1] Manzana Pera Piña Naranja Mandarina Banano Durazno ## [8] Uva Fresa Melocotón ## 10 Levels: Banano Durazno Fresa Mandarina Manzana Melocotón ... Uva df[,&quot;Fruta&quot;] ## [1] Manzana Pera Piña Naranja Mandarina Banano Durazno ## [8] Uva Fresa Melocotón ## 10 Levels: Banano Durazno Fresa Mandarina Manzana Melocotón ... Uva df[[&quot;Fruta&quot;]] # entrega el mimso resultado ## [1] Manzana Pera Piña Naranja Mandarina Banano Durazno ## [8] Uva Fresa Melocotón ## 10 Levels: Banano Durazno Fresa Mandarina Manzana Melocotón ... Uva df[3, 2] # elemento de la tercera fila y segunda columna: -2 ## [1] -2 # row 3, columns 2 through 3 df[3, 2:3] ## Segundo Fruta ## 3 -2 Piña class(df[, &quot;Fruta&quot;]) # factor ## [1] &quot;factor&quot; 3.11 Listas Una lista puede contener datos númericos, caractéres, etc. Es decir, una mezcla de varios tipos de datos. También fotos o listas pueden ser parte de una lista. Crear una lista de tres elementos: 1, 2, 3 Luego, crear una lista de un solo elemento, que es un vector con los números 1 a 3 Después, crear una lista “lista3” con dos elementos, uno es una lista (1,2,3) y otro un vector de cinco números (3 a 7) Posteriormente, crear una lista de dos elementos, uno debe ser el data frame “df” y otro un vector con los números 1 a 10 Luego, crear una lista “lista4” con los siguientes 3 elementos: df, números 1 a 10, lista3 Imprimir “lista4” a la pantalla Mostrar los nombres de lista4 Asignar los siguientes nombres a la “lista4”: data.frame, vector, lista Imprimir “lista4” a la pantalla Crear una lista “lista5” con los elementos, df, números 1 a 10, lista3 con los nombres: ElDataFrame, ElVector, LaLista, utilizando parejas de ‘nombre-valor’ Mostrar los nombres de “lista5” Imprimir “lista5” a la pantalla list(1, 2, 3) ## [[1]] ## [1] 1 ## ## [[2]] ## [1] 2 ## ## [[3]] ## [1] 3 list(c(1, 2, 3)) ## [[1]] ## [1] 1 2 3 (lista3 &lt;- list(c(1, 2, 3), 3:7)) # observe, como se colocaron las paréntesis en este caso ## [[1]] ## [1] 1 2 3 ## ## [[2]] ## [1] 3 4 5 6 7 list(df, 1:10) ## [[1]] ## Primero Segundo Fruta ## 1 10 -4 Manzana ## 2 9 -3 Pera ## 3 8 -2 Piña ## 4 7 -1 Naranja ## 5 6 0 Mandarina ## 6 5 1 Banano ## 7 4 2 Durazno ## 8 3 3 Uva ## 9 2 4 Fresa ## 10 1 5 Melocotón ## ## [[2]] ## [1] 1 2 3 4 5 6 7 8 9 10 lista4 &lt;- list(df, 1:10, lista3) lista4 ## [[1]] ## Primero Segundo Fruta ## 1 10 -4 Manzana ## 2 9 -3 Pera ## 3 8 -2 Piña ## 4 7 -1 Naranja ## 5 6 0 Mandarina ## 6 5 1 Banano ## 7 4 2 Durazno ## 8 3 3 Uva ## 9 2 4 Fresa ## 10 1 5 Melocotón ## ## [[2]] ## [1] 1 2 3 4 5 6 7 8 9 10 ## ## [[3]] ## [[3]][[1]] ## [1] 1 2 3 ## ## [[3]][[2]] ## [1] 3 4 5 6 7 names(lista4) # listas pueden también tener nombres como un data frame ## NULL names(lista4) &lt;-c(&quot;data.frame&quot;, &quot;vector&quot;, &quot;lista&quot;) names(lista4) ## [1] &quot;data.frame&quot; &quot;vector&quot; &quot;lista&quot; lista5 &lt;- list(ElDataFrame=df, ElVector=1:10, LaLista=lista3) # parejas de nombre-valor en la creación de una lista names(lista5) ## [1] &quot;ElDataFrame&quot; &quot;ElVector&quot; &quot;LaLista&quot; lista5 ## $ElDataFrame ## Primero Segundo Fruta ## 1 10 -4 Manzana ## 2 9 -3 Pera ## 3 8 -2 Piña ## 4 7 -1 Naranja ## 5 6 0 Mandarina ## 6 5 1 Banano ## 7 4 2 Durazno ## 8 3 3 Uva ## 9 2 4 Fresa ## 10 1 5 Melocotón ## ## $ElVector ## [1] 1 2 3 4 5 6 7 8 9 10 ## ## $LaLista ## $LaLista[[1]] ## [1] 1 2 3 ## ## $LaLista[[2]] ## [1] 3 4 5 6 7 Para acceder a un elemento individual de una lista, utilice corchetes dobles, especificando el número del elemento o el nombre, que se quiere acceder. Tenga en cuenta que esto permite el acceso a un solo elemento a la vez. Ejemplo: Acceder al primer elemento de la lista5 lista5[[1]] ## Primero Segundo Fruta ## 1 10 -4 Manzana ## 2 9 -3 Pera ## 3 8 -2 Piña ## 4 7 -1 Naranja ## 5 6 0 Mandarina ## 6 5 1 Banano ## 7 4 2 Durazno ## 8 3 3 Uva ## 9 2 4 Fresa ## 10 1 5 Melocotón 3.11.1 Una lista de listas Crear 3 listas con números: La lista “dataset1” con números 1 a 3 La lista “dataset2” con números 4 a 6 La lista “dataset3” con números 7 a 9 dataset1 &lt;- list(1:3) # números 1 hasta 3 print(dataset1) ## [[1]] ## [1] 1 2 3 dataset2 &lt;- list(4:6) # números 4 hasta 6 print(dataset2) ## [[1]] ## [1] 4 5 6 dataset3 &lt;- list(7:9) # números 7 hasta 9 print(dataset3) ## [[1]] ## [1] 7 8 9 Unir las 3 listas en una nueva lista con el nombre “data.list” data.list &lt;- list(dataset1, dataset2, dataset3) data.list ## [[1]] ## [[1]][[1]] ## [1] 1 2 3 ## ## ## [[2]] ## [[2]][[1]] ## [1] 4 5 6 ## ## ## [[3]] ## [[3]][[1]] ## [1] 7 8 9 Acceder en la lista “dataset1” al segundo elemento dataset1[[1]][2] #2 ## [1] 2 Ahora de la lista de las 3 listas, acceder al segundo elemento. Es decir, al contenido de la segunda lista (dataset2), que esta parte de la lista “data.list” data.list[2] # 4 5 6 ## [[1]] ## [[1]][[1]] ## [1] 4 5 6 data.list[2][1] # 4 5 6 ## [[1]] ## [[1]][[1]] ## [1] 4 5 6 Acceder al segundo elemento de la segunda lista (dataset2), que es parte de la lista “data.list” data.list[[2]][[1]][2] # 5 ## [1] 5 3.12 Ejercicio 2 3.12.1 Parte a Crear un vector “vector1” con los números “3” y “4” y convertirlo a un data frame y asignar el resultado a una variable “data1” Mostrar el nombre de las columnas del data frame data1 Acceder al primer elemento del data frame (3) y mostrarlo en la pantalla 3.12.2 Parte b Crear un vector “vector2” con el texto (string) “3”, “4” y “5” y convertirlo a un data frame y asignar el resultado a una variable “data2” Mostrar el resultado de la conversión, utilizando la función class() 3.12.3 Parte c Ahora, convertir el contenido de este data frame “data2” (caracteres) al tipo de dato “numeric”. Es decir, convertir el contenido a tres números y asignar el resultado a una variable “data3” Mostrar el resultado de la conversión, utilizando la función class() 3.12.4 Parte d Crear un vector “vector3” con los 6 estratos (seis categorías: 1 a 6), como se utilizan p.ej. en Colombia. Es decir, crear este vector3 de tipo de dato “factor” Convertir el contenido de este vector al tipo de dato “numeric”. Es decir, convertir el contenido a seis números y asignar el resultado a una variable “data4” Mostrar el resultado de la conversión, utilizando la función class() 3.12.5 Parte e Crear un data frame “df10” con dos columnas. La primera columna “x” debe contener los datos 1, 2 y 3 y la segunda “y” los datos 4, 5 y 6. Sin embargo, los tres datos de la primera columna deben ser del tipo de dato “numeric” (numérico). Mientras los tres datos de la segunda columna deben ser del tipo de dato “factor” (categórica) -Ahora convertir los valores de la segunda columna (y), del tipo de dato “factor” a “numeric” -Mostrar que los valores de la segunda columna “y” ahora realmente son del tipo de dato “numeric” Nota: Observar bien lo que hace la función as.numeric() en el presente caso "],
["cargar.html", "Sección 4 Cargar datos a R/RStudio 4.1 Objetivo 4.2 Leer datos desde un archivo de tipo csv y xlsx 4.3 Leer datos desde un archivo csv de una página web (url) 4.4 Leer datos de acciones, utilizando el paquete quantmod 4.5 Leer datos de una tabla de una página web: wikipedia 4.6 Cargar un conjunto de datos, que viene con R 4.7 Cargar datos financieros con el paquete tidyquant 4.8 Cargar datos de criptomonedas 4.9 Cargar datos de Eurostat con R 4.10 Ejercicio 3", " Sección 4 Cargar datos a R/RStudio 4.1 Objetivo El objetivo de esta sección consiste en explicar diferentes escenarios para cargar (“importar”) datos de diferentes fuentes a R / RStudio. Esto como una condición previa para analizar posteriormente estos datos. La explicación incluye fuentes de datos financieros como la cotización de acciones. 4.2 Leer datos desde un archivo de tipo csv y xlsx Primero, vamos a generar manualmente un archivo en MS-Excel con los siguientes datos: id Nombre Apellido Ingresos Egresos Calificación 1 Jimmy Toro 4000000 3500000 80 2 Joe Arango 3500000 4000000 20 3 Diana Ramírez 3000000 3000000 50 4 Cris Mesa 2500000 2000000 70 5 Manuela Meier 2000000 1000000 70 6 Lucia Müller 1500000 1400000 45 7 Andrés Aveláez 1000000 1000000 40 8 Bill Jaramillo 750000 800000 10 9 Gabriel Arias 500000 500000 12 10 Javier Gómez 450000 450000 10 Determinar su directorio de trabajo para R, utilizando la función getwd() Guardar este archivo como csv (comma separated value), bajo el nombre “test1csv.csv”, en su directorio de trabajo (working directory de R) Guardarlo también como archivo de Excel (xlsx), bajo el nombre “test1excel.xlsx”, en su directorio de trabajo de R Ahora, leer el contenido del archivo csv, utilizando en RStudio la función read.csv(), tomando en cuenta que los datos tienen un “encabezado” y asignar el resultado a una variable “dataset” Visualizar el contenido de la tabla de datos (dataset), utilizando la función View() Determinar la clase del (objeto) “dataset” Determinar la estructura de “dataset”, utilizando la función str() Mostrar “Meier”, que es un elemento en la fila con el id “5”, columna #3 del “dataset” (quinta fila, tercera columna) dataset &lt;- read.csv(&#39;test1csv.csv&#39;, sep = &#39;;&#39;) # si el separador es coma o punto coma, depende como Excel almacena el archivo csv... View(dataset) class(dataset) ## [1] &quot;data.frame&quot; str(dataset) ## &#39;data.frame&#39;: 10 obs. of 6 variables: ## $ id : int 1 2 3 4 5 6 7 8 9 10 ## $ Nombre : Factor w/ 10 levels &quot;Andres&quot;,&quot;Bill&quot;,..: 7 8 4 3 10 9 1 2 5 6 ## $ Apellido : Factor w/ 10 levels &quot;Arango&quot;,&quot;Arias&quot;,..: 10 1 9 7 6 8 3 5 2 4 ## $ Ingresos : int 4000000 3500000 3000000 2500000 2000000 1500000 1000000 750000 500000 450000 ## $ Egresos : int 3500000 4000000 3000000 2000000 1000000 1400000 1000000 800000 500000 450000 ## $ Calificación: int 80 20 50 70 70 45 40 10 12 10 dataset[5,3] ## [1] Meier ## 10 Levels: Arango Arias Avelaez Gomez Jaramillo Meier Mesa ... Toro Ahora, leer el contenido del archivo xlsx, utilizando en RStudio la función read_excel() del paquete readxl, tomando en cuenta que los datos tienen un “encabezado” y asignar el resultado a la variable “dataset2” Visualizar el contenido de la tabla de datos (dataset2), utilizando la función View() Determinar la clase del “dataset2” Determinar la estructura de “dataset2”, utilizando la función str() Mostrar los ingresos de la persona “Javier Gómez” (observación en la fila #10 y columna #4), que es parte del “dataset2” library(readxl) ## Warning: package &#39;readxl&#39; was built under R version 3.5.3 dataset2 &lt;- read_excel(&#39;test1excel.xlsx&#39;, sheet=&#39;Hoja2&#39;) # en el proceso de guardar como xlxs se genera esta hoja 2 View(dataset2) class(dataset2) ## [1] &quot;tbl_df&quot; &quot;tbl&quot; &quot;data.frame&quot; str(dataset2) ## Classes &#39;tbl_df&#39;, &#39;tbl&#39; and &#39;data.frame&#39;: 10 obs. of 6 variables: ## $ id : num 1 2 3 4 5 6 7 8 9 10 ## $ Nombre : chr &quot;Jimmy&quot; &quot;Joe&quot; &quot;Diana&quot; &quot;Cristina&quot; ... ## $ Apellido : chr &quot;Toro&quot; &quot;Arango&quot; &quot;Ramirez&quot; &quot;Mesa&quot; ... ## $ Ingresos : num 4000000 3500000 3000000 2500000 2000000 1500000 1000000 750000 500000 450000 ## $ Egresos : num 3500000 4000000 3000000 2000000 1000000 1400000 1000000 800000 500000 450000 ## $ Calificación: num 80 20 50 70 70 45 40 10 12 10 dataset[10,4] ## [1] 450000 Explorar la función file.choose() para el archivo csv, utilizando el comando “dataset3 &lt;- read.csv(file.choose(), header=TRUE)” Explorar la estructura de #dataset3&quot; Cambiar el código para los parámetros de la función read.csv() de tal forma, que se utiliza “stringsAsFactors=FALSE” para evitar que los datos de tipo “string” se convierten en una variable categórica (factor) Solución: dataset3 &lt;- read.csv(file.choose(), header=TRUE) Nota: El comando file.choose() abre una ventana nueva, que permite seleccionar un archivo en cualquier parte del equipo de cómputo o en una memoria externa. 4.3 Leer datos desde un archivo csv de una página web (url) Cargar datos de solicitudes de crédito de la siguiente url, donde se encuentra un archivo “german_credit.csv”: url=“http://freakonometrics.free.fr/german_credit.csv” y asignar el resultado a una variable “credito”. Tomar en cuenta que estos datos tienen un encabezado y que las columnas están separadas por coma. Analizar la estructura de los datos “credito” url=&quot;http://freakonometrics.free.fr/german_credit.csv&quot; credito &lt;- read.csv(url, header = TRUE, sep = &quot;,&quot;) str(credito) ## &#39;data.frame&#39;: 1000 obs. of 21 variables: ## $ Creditability : int 1 1 1 1 1 1 1 1 1 1 ... ## $ Account.Balance : int 1 1 2 1 1 1 1 1 4 2 ... ## $ Duration.of.Credit..month. : int 18 9 12 12 12 10 8 6 18 24 ... ## $ Payment.Status.of.Previous.Credit: int 4 4 2 4 4 4 4 4 4 2 ... ## $ Purpose : int 2 0 9 0 0 0 0 0 3 3 ... ## $ Credit.Amount : int 1049 2799 841 2122 2171 2241 3398 1361 1098 3758 ... ## $ Value.Savings.Stocks : int 1 1 2 1 1 1 1 1 1 3 ... ## $ Length.of.current.employment : int 2 3 4 3 3 2 4 2 1 1 ... ## $ Instalment.per.cent : int 4 2 2 3 4 1 1 2 4 1 ... ## $ Sex...Marital.Status : int 2 3 2 3 3 3 3 3 2 2 ... ## $ Guarantors : int 1 1 1 1 1 1 1 1 1 1 ... ## $ Duration.in.Current.address : int 4 2 4 2 4 3 4 4 4 4 ... ## $ Most.valuable.available.asset : int 2 1 1 1 2 1 1 1 3 4 ... ## $ Age..years. : int 21 36 23 39 38 48 39 40 65 23 ... ## $ Concurrent.Credits : int 3 3 3 3 1 3 3 3 3 3 ... ## $ Type.of.apartment : int 1 1 1 1 2 1 2 2 2 1 ... ## $ No.of.Credits.at.this.Bank : int 1 2 1 2 2 2 2 1 2 1 ... ## $ Occupation : int 3 3 2 2 2 2 2 2 1 1 ... ## $ No.of.dependents : int 1 2 1 2 1 2 1 2 1 1 ... ## $ Telephone : int 1 1 1 1 1 1 1 1 1 1 ... ## $ Foreign.Worker : int 1 1 1 2 2 2 2 2 1 1 ... 4.4 Leer datos de acciones, utilizando el paquete quantmod Cargar el paquete “quantmod” Analizar con el comando de “help” (?) el contenido de este paquete Este paquete requiere que se defina (al principio) un entorno (environment): new.env() que se asigna a una variable, p.ej. con el nombre “stockData” library(quantmod) ?quantmod stockData &lt;- new.env() #Generar un entorno nuevo # para que quandmod pueda guardar los datos en este entorno Definir una fecha de inicio y final para bajar los datos. Utilizar como fecha final la fecha actual y como fecha de inicio una fecha “cercana” a la fecha final startDate = as.Date(&quot;2020-01-20&quot;) endDate = Sys.Date() Definir una lista de los tickers (empresas) para las cuales se requieren los datos. P.ej. Amazon: ticker - AMZN tickers &lt;- c(&quot;AMZN&quot;) Descargar los datos históricos de la/s acción/es (para todos los tickers), utilizando la función getsymbols() de quandmod y como fuente yahoo (src = “yahoo”) getSymbols(tickers, env = stockData, src = &quot;yahoo&quot;, from = startDate, to = endDate) ## &#39;getSymbols&#39; currently uses auto.assign=TRUE by default, but will ## use auto.assign=FALSE in 0.5-0. You will still be able to use ## &#39;loadSymbols&#39; to automatically load data. getOption(&quot;getSymbols.env&quot;) ## and getOption(&quot;getSymbols.auto.assign&quot;) will still be checked for ## alternate defaults. ## ## This message is shown once per session and may be disabled by setting ## options(&quot;getSymbols.warning4.0&quot;=FALSE). See ?getSymbols for details. ## [1] &quot;AMZN&quot; Analizar las primeras 6 filas de estos datos ya descargados Observar la clase de los datos (class()) head(stockData$AMZN) ## AMZN.Open AMZN.High AMZN.Low AMZN.Close AMZN.Volume ## 2020-01-21 1865.00 1894.27 1860.00 1892.00 3707800 ## 2020-01-22 1896.09 1902.50 1883.34 1887.46 3216300 ## 2020-01-23 1885.11 1889.98 1872.76 1884.58 2484600 ## 2020-01-24 1891.37 1894.99 1847.44 1861.64 3766200 ## 2020-01-27 1820.00 1841.00 1815.34 1828.34 3528500 ## 2020-01-28 1840.50 1858.11 1830.02 1853.25 2808000 ## AMZN.Adjusted ## 2020-01-21 1892.00 ## 2020-01-22 1887.46 ## 2020-01-23 1884.58 ## 2020-01-24 1861.64 ## 2020-01-27 1828.34 ## 2020-01-28 1853.25 class(stockData) # environment ## [1] &quot;environment&quot; 4.5 Leer datos de una tabla de una página web: wikipedia Instalar y cargar los paquetes “tidyverse” y “rvest” Leer datos desde la tabla en https://en.wikipedia.org/wiki/List_of_countries_and_dependencies_by_population, utilizando la función read_html() para guardar el resultado en una variable “urldata” Observar la clase de la varialbe “urldata” Extraer la/s tabla/s mediante: tab &lt;- urldata %&gt;% html_nodes(“table”) Observar el contenido de la variable “tab” Escoger la primera tabla con: tab[[1]] Transformar a un data frame con: tab &lt;- tab[[1]] %&gt;% html_table(header = TRUE, fill = TRUE) Observar la clase de la variable “tab”&quot; Mostrar su contenido library(tidyverse) library(rvest) ## Loading required package: xml2 ## ## Attaching package: &#39;rvest&#39; ## The following object is masked from &#39;package:purrr&#39;: ## ## pluck ## The following object is masked from &#39;package:readr&#39;: ## ## guess_encoding url = &quot;https://en.wikipedia.org/wiki/List_of_countries_and_dependencies_by_population&quot; urldata &lt;- read_html(url) class(urldata) ## [1] &quot;xml_document&quot; &quot;xml_node&quot; tab &lt;- urldata %&gt;% html_nodes(&quot;table&quot;) tab ## {xml_nodeset (2)} ## [1] &lt;table class=&quot;wikitable sortable mw-datatable&quot; style=&quot;margin:auto;te ... ## [2] &lt;table class=&quot;nowraplinks hlist mw-collapsible autocollapse navbox-i ... tab[[1]] # el primer elemento es la tabla que se quiere cargar... ## {xml_node} ## &lt;table class=&quot;wikitable sortable mw-datatable&quot; style=&quot;margin:auto;text-align:right&quot;&gt; ## [1] &lt;tbody&gt;\\n&lt;tr&gt;\\n&lt;th data-sort-type=&quot;number&quot;&gt;Rank&lt;/th&gt;\\n&lt;th&gt;Country&lt;br ... tab &lt;- tab[[1]] %&gt;% html_table(header = TRUE, fill = TRUE) class(tab) # data frame ## [1] &quot;data.frame&quot; View(tab) # los contenidos se cargaron, más o menos, bien, # en términos del formato ... 4.6 Cargar un conjunto de datos, que viene con R Con la instalación básica de R vienen algunos datasets (pre-loaded datasets in R) Utilizar el paquete (library) “datasets” y la función data() para imprimir a la pantalla una lista con los conjuntos de datos disponibles library(datasets) data() # abre una pestaña en RStudio donde se muestran todos los datasets disponibles Cargar el dataset con el nombre “EuStockMarkets”, utilizando la función data() Convertir este datset a un data frame y asignar el resultado a la variable “dataset.Eur” Mostrar las primeras 10 filas de “dataset.Eur” Mostrar la estructura de “dataset.Eur” data(&quot;EuStockMarkets&quot;) dataset.Eur &lt;- as.data.frame(EuStockMarkets) head(dataset.Eur, n=10) ## DAX SMI CAC FTSE ## 1 1628.75 1678.1 1772.8 2443.6 ## 2 1613.63 1688.5 1750.5 2460.2 ## 3 1606.51 1678.6 1718.0 2448.2 ## 4 1621.04 1684.1 1708.1 2470.4 ## 5 1618.16 1686.6 1723.1 2484.7 ## 6 1610.61 1671.6 1714.3 2466.8 ## 7 1630.75 1682.9 1734.5 2487.9 ## 8 1640.17 1703.6 1757.4 2508.4 ## 9 1635.47 1697.5 1754.0 2510.5 ## 10 1645.89 1716.3 1754.3 2497.4 str(dataset.Eur) ## &#39;data.frame&#39;: 1860 obs. of 4 variables: ## $ DAX : num 1629 1614 1607 1621 1618 ... ## $ SMI : num 1678 1688 1679 1684 1687 ... ## $ CAC : num 1773 1750 1718 1708 1723 ... ## $ FTSE: num 2444 2460 2448 2470 2485 ... 4.7 Cargar datos financieros con el paquete tidyquant 4.7.1 Renta variable - precio de acciones Con respecto al paquete “tidyquant”, ver también el siguiente vínculo: https://rdrr.io/cran/tidyquant/man/tq_get.html Encontrar todas las bolsas disponibles, utilizando la función tq_exchange_options() library(tidyquant) ## Warning: package &#39;tidyquant&#39; was built under R version 3.5.3 ## Loading required package: lubridate ## ## Attaching package: &#39;lubridate&#39; ## The following object is masked from &#39;package:base&#39;: ## ## date ## Loading required package: PerformanceAnalytics ## ## Attaching package: &#39;PerformanceAnalytics&#39; ## The following object is masked from &#39;package:graphics&#39;: ## ## legend ## == Need to Learn tidyquant? =============== ## Business Science offers a 1-hour course - Learning Lab #9: Performance Analysis &amp; Portfolio Optimization with tidyquant! ## &lt;/&gt; Learn more at: https://university.business-science.io/p/learning-labs-pro &lt;/&gt; tq_exchange_options() ## [1] &quot;AMEX&quot; &quot;NASDAQ&quot; &quot;NYSE&quot; Encontrar todos los indices búrsatiles disponibles, utilizando la función tq_index_options() tq_index_options() ## [1] &quot;DOW&quot; &quot;DOWGLOBAL&quot; &quot;SP400&quot; &quot;SP500&quot; &quot;SP600&quot; Explorar el índice S&amp;P500 (SP500), utilizando la función glimpse(), que es parecida a str(). Se requiere el paquete XLConnect library(XLConnect) ## Warning: package &#39;XLConnect&#39; was built under R version 3.5.3 ## Loading required package: XLConnectJars ## Warning: package &#39;XLConnectJars&#39; was built under R version 3.5.3 ## XLConnect 0.2-15 by Mirai Solutions GmbH [aut], ## Martin Studer [cre], ## The Apache Software Foundation [ctb, cph] (Apache POI), ## Graph Builder [ctb, cph] (Curvesapi Java library) ## http://www.mirai-solutions.com ## https://github.com/miraisolutions/xlconnect glimpse(tq_index(&quot;SP500&quot;)) ## Getting holdings for SP500 ## Observations: 506 ## Variables: 8 ## $ symbol &lt;chr&gt; &quot;AAPL&quot;, &quot;MSFT&quot;, &quot;AMZN&quot;, &quot;FB&quot;, &quot;BRK.B&quot;, &quot;GOOGL&quot;,... ## $ company &lt;chr&gt; &quot;Apple Inc.&quot;, &quot;Microsoft Corporation&quot;, &quot;Amazon.... ## $ identifier &lt;chr&gt; &quot;03783310&quot;, &quot;59491810&quot;, &quot;02313510&quot;, &quot;30303M10&quot;,... ## $ sedol &lt;chr&gt; &quot;2046251&quot;, &quot;2588173&quot;, &quot;2000019&quot;, &quot;B7TL820&quot;, &quot;20... ## $ weight &lt;dbl&gt; 0.049707688, 0.048436500, 0.028628617, 0.018528... ## $ sector &lt;chr&gt; &quot;Information Technology&quot;, &quot;Information Technolo... ## $ shares_held &lt;dbl&gt; 48051176, 87766840, 4791285, 27685640, 22503532... ## $ local_currency &lt;chr&gt; &quot;USD&quot;, &quot;USD&quot;, &quot;USD&quot;, &quot;USD&quot;, &quot;USD&quot;, &quot;USD&quot;, &quot;USD&quot;... Utilizar la función tq_get_options() para obtener una lista con opciones para obtener (get) datos financieros tq_get_options() # vamos a utilizar opción [1] &quot;stock.prices&quot; ## [1] &quot;stock.prices&quot; &quot;stock.prices.google&quot; &quot;stock.prices.japan&quot; ## [4] &quot;financials&quot; &quot;key.ratios&quot; &quot;dividends&quot; ## [7] &quot;splits&quot; &quot;economic.data&quot; &quot;exchange.rates&quot; ## [10] &quot;metal.prices&quot; &quot;quandl&quot; &quot;quandl.datatable&quot; ## [13] &quot;alphavantager&quot; &quot;rblpapi&quot; Obtener los precios (stock.prices) de los últimos 10 dias de las siguientes acciones: Facebook (FB) y Microsoft (MSFT), utilizando la función tq_get() Mostrar las últimas 6 registros de estas acciones, utilizando la función tail() start &lt;- Sys.Date() - 10 acciones &lt;- tq_get(c(&quot;FB&quot;, &quot;MSFT&quot;), get = c(&quot;stock.prices&quot;), from = start, to = Sys.Date()) # se puede entrar también una fecha específica (entre comillas), como p.ej.: &quot;2020-02-01&quot; tail(acciones) ## # A tibble: 6 x 8 ## symbol date open high low close volume adjusted ## &lt;chr&gt; &lt;date&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 MSFT 2020-01-24 168. 168. 164. 165. 24918100 165. ## 2 MSFT 2020-01-27 161. 163. 160. 162. 32078100 162. ## 3 MSFT 2020-01-28 164. 166. 163. 165. 24899900 165. ## 4 MSFT 2020-01-29 168. 169. 166. 168. 34754500 168. ## 5 MSFT 2020-01-30 174. 174. 171. 173. 51597500 173. ## 6 MSFT 2020-01-31 172. 172. 170. 170. 36113300 170. Extraer (mostrar) los primeros registros de los precios (stock.prices) para el símbolo de “MSFT” a2 &lt;- acciones[acciones$symbol==&quot;MSFT&quot;, ] head(a2) ## # A tibble: 6 x 8 ## symbol date open high low close volume adjusted ## &lt;chr&gt; &lt;date&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 MSFT 2020-01-22 167. 167. 166. 166. 24138800 166. ## 2 MSFT 2020-01-23 166. 167. 165. 167. 19680800 167. ## 3 MSFT 2020-01-24 168. 168. 164. 165. 24918100 165. ## 4 MSFT 2020-01-27 161. 163. 160. 162. 32078100 162. ## 5 MSFT 2020-01-28 164. 166. 163. 165. 24899900 165. ## 6 MSFT 2020-01-29 168. 169. 166. 168. 34754500 168. 4.7.2 Renta fija Aquí, se trata de cargar 1-Y y 3-M bonos libre de riesgos (EE.UU. treasury bills) utilizando R Utilizar nuevamente el paquete tidyquant y la función “tq_get()” para bajar los datos de precios para bonos del estado de la página web de FRED, Federal Reserve Bank of St. Louis Economic Data. Se deben bajar los datos para “TB1YR” y “TB3MS”. Es decir, treasury bills de un año (1YR) y de tres meses (3MS) Stöckl, S. (21/09/2018). Tidy Portfoliomanagement in R. library(tidyquant) tbills &lt;- tq_get(c(&quot;TB1YR&quot;,&quot;TB3MS&quot;), get = &quot;economic.data&quot;) %&gt;% group_by(symbol) head(tbills) ## # A tibble: 6 x 3 ## # Groups: symbol [1] ## symbol date price ## &lt;chr&gt; &lt;date&gt; &lt;dbl&gt; ## 1 TB1YR 2010-01-01 0.32 ## 2 TB1YR 2010-02-01 0.33 ## 3 TB1YR 2010-03-01 0.37 ## 4 TB1YR 2010-04-01 0.42 ## 5 TB1YR 2010-05-01 0.35 ## 6 TB1YR 2010-06-01 0.3 4.8 Cargar datos de criptomonedas Utilizar el paquete “coinmarketcapr” Descargar las criptomonedas “top”, utilizando el comando get_marketcap_ticker_all() de este paquete, y asignar el resultado a una variable “top_cc” Analizar la clase de esta variable Mostrar las primeras 6 filas de esta variable, utilizando la función kable(), aquí (head(top_cc)), la cual es parte del paquete knitr, y analizar estos datos library(coinmarketcapr) ## Warning: package &#39;coinmarketcapr&#39; was built under R version 3.5.3 library(knitr) ## Warning: package &#39;knitr&#39; was built under R version 3.5.3 top_cc &lt;- get_marketcap_ticker_all() class(top_cc) #top_cc es un dataframe ## [1] &quot;data.frame&quot; # kable es un generador de tablas (del paquete knitr) y muestra las primeras filas (head) de los datos kable(head(top_cc)) id name symbol rank price_usd price_btc X24h_volume_usd market_cap_usd available_supply total_supply max_supply percent_change_1h percent_change_24h percent_change_7d last_updated bitcoin Bitcoin BTC 1 9374.5968622 1.0000000 26190920558 170566571339 18194550 18194550 2.1e+07 0.06 0.52 12.17 2020-02-01 16:01:33 ethereum Ethereum ETH 2 183.4257296 0.0195370 11581828364 20089426050 109523490 109523490 NA 0.35 1.70 13.66 2020-02-01 16:02:22 xrp XRP XRP 3 0.2411904 0.0000257 1596900259 10536535753 43685558183 99991098384 1.0e+11 -0.04 1.12 9.32 2020-02-01 16:02:06 bitcoin-cash Bitcoin Cash BCH 4 379.9734028 0.0404716 3318357880 6936628203 18255563 18255563 2.1e+07 0.06 1.89 22.01 2020-02-01 16:02:08 bitcoin-sv Bitcoin SV BSV 5 279.8897225 0.0298116 2135586282 5108677247 18252465 18252465 2.1e+07 -0.23 2.48 7.56 2020-02-01 16:02:12 tether Tether USDT 6 1.0014753 0.0001067 35149920329 4649216188 4642367414 4776930644 NA -0.04 0.19 0.07 2020-02-01 16:02:22 4.8.1 Para cargar datos históricos de criptomonedas Utilizar el paquete crypto de R y la función crypto_history(), p.ej. para bajar los datos para Bitcoin, en términos de la última cotización (parámetro “limit” = 1) Asignar el resultado a una variable “bitc” Mostrar las primeras seis filas de “bitc” Mostrar los primeros seis valores de la columna “close” de “bitc” library(crypto) ## Warning: package &#39;crypto&#39; was built under R version 3.5.3 moneda &lt;- &#39;BTC&#39; #&quot;bitcoin&quot; #start &lt;- &#39;20191201&#39; limit &lt;- 1 # últimos 1 cotizaciones bitc &lt;- crypto_history(coin = moneda, limit = limit, sleep = 7.5) ## &lt;U+2665&gt; If this helps you become rich please consider donating ## ## ERC-20: 0x375923Bf82F0b728d23A5704261a6e16341fd860 ## XRP: rK59semLsuJZEWftxBFhWuNE6uhznjz2bK ## ## &gt; Scraping historical crypto data ## head(bitc) ## slug symbol name date ranknow open high low close ## 1 bitcoin BTC Bitcoin 2013-04-28 1 135.30 135.98 132.10 134.21 ## 2 bitcoin BTC Bitcoin 2013-04-29 1 134.44 147.49 134.00 144.54 ## 3 bitcoin BTC Bitcoin 2013-04-30 1 144.00 146.93 134.05 139.00 ## 4 bitcoin BTC Bitcoin 2013-05-01 1 139.00 139.89 107.72 116.99 ## 5 bitcoin BTC Bitcoin 2013-05-02 1 116.38 125.60 92.28 105.21 ## 6 bitcoin BTC Bitcoin 2013-05-03 1 106.25 108.13 79.10 97.75 ## volume market close_ratio spread ## 1 0 1488566728 0.5438144 3.88 ## 2 0 1603768865 0.7813195 13.49 ## 3 0 1542813125 0.3843168 12.88 ## 4 0 1298954594 0.2881567 32.17 ## 5 0 1168517495 0.3880552 33.32 ## 6 0 1085995169 0.6424389 29.03 head(bitc[,&quot;close&quot;]) # primeras seis filas de la columna &quot;close&quot; ## [1] 134.21 144.54 139.00 116.99 105.21 97.75 4.9 Cargar datos de Eurostat con R Eurostat es la oficina estadística de la Unión Europea. Su misión es proporcionar estadísticas de alta calidad para Europa. Instalar y utilizar el paquete (library) eurostat R Tools for Eurostat open data Explorar el manual para el paquete “eurostat”, utilizando el comando ?eurostat Véase también: http://ropengov.github.io/eurostat/articles/cheatsheet.html library(dplyr) # debe ser una versión de dplyr mayor a 0.8 library(eurostat) # R Tools para Eurostat open data (requiere versión dplyr &gt; 0.8) ## Warning: package &#39;eurostat&#39; was built under R version 3.5.3 ?eurostat # página de ayuda Cargar los datos desde Eurostat, utilizando la función get_eurostat(), y asignar el resultado a una variable “contenido” (tabla de contenido). Nota: La carga de estos datos se demora un rato library(eurostat) contenido &lt;- get_eurostat_toc() Mostrar para el contenido las primeras filas en una tabla, utilizando knitr::kable()… Esto requiere el paquete “knitr” library(knitr) kable(head(contenido)) title code type last update of data last table structure change data start data end values Database by themes data folder NA NA NA NA NA General and regional statistics general folder NA NA NA NA NA European and national indicators for short-term analysis euroind folder NA NA NA NA NA Business and consumer surveys (source: DG ECFIN) ei_bcs folder NA NA NA NA NA Consumer surveys (source: DG ECFIN) ei_bcs_cs folder NA NA NA NA NA Consumers - monthly data ei_bsco_m dataset 30.01.2020 31.01.2020 1980M01 2020M01 NA Utilizando la función search_eurostat(), se puede buscar en la tabla de contenido, p.ej. por conjuntos de datos (datasets), que están relacionados con las “tasas de intéres” (interest rates): kable(head(search_eurostat(“interest rates”)), n=25) Donde n=5 limita el resultado a 5 filas kable(head(search_eurostat(&quot;interest rates&quot;)), n=5) title code type last update of data last table structure change data start data end values Candidate countries and potential candidates: exchange rates and interest rates cpc_ecexint dataset 18.03.2019 18.03.2019 2005 2018 NA ENP countries: exchange rates and interest rates enpr_ecexint dataset 14.01.2020 14.01.2020 2005 2018 NA Money market interest rates - annual data irt_st_a dataset 06.01.2020 06.01.2020 1970 2019 NA Money market interest rates - quarterly data irt_st_q dataset 08.01.2020 06.01.2020 1970Q1 2019Q4 NA Money market interest rates - monthly data irt_st_m dataset 14.01.2020 06.01.2020 1970M01 2019M12 NA Nota: Los códigos para el conjunto de datos se pueden buscar también en la base de datos de Eurostat. Esta base de datos proporciona códigos en forma de un árbol de navegación de datos, entre paréntesis después de cada conjunto de datos: https://ec.europa.eu/eurostat/data/database Para descargar los datos de un conjunto de datos, utilizar la función search_eurostat() de la siguiente forma, donde code[1] es importante para que este id sea el code correspondiente, que se muestra en la tabla anterior id &lt;- search_eurostat(&quot;Money market interest rates - annual data&quot;, type = &quot;dataset&quot;)$code[1] print(id) ## [1] &quot;irt_st_a&quot; Ahora, se puede “aprovechar” de este “id”, de la siguiente forma, utilizando la función get_eurostat() y asignando el resultado a una variable “datos” datos &lt;- get_eurostat(id, time_format = &quot;num&quot;) ## Table irt_st_a cached at C:\\Users\\CHRIST~1\\AppData\\Local\\Temp\\RtmpMvYhUV/eurostat/irt_st_a_num_code_TF.rds Ver los “datos”, utilizando la función str() y con head(), los primeros 5 registros de “datos” str(datos) ## Classes &#39;tbl_df&#39;, &#39;tbl&#39; and &#39;data.frame&#39;: 1399 obs. of 4 variables: ## $ int_rt: Factor w/ 5 levels &quot;IRT_DTD&quot;,&quot;IRT_M1&quot;,..: 1 1 2 2 2 2 3 3 3 4 ... ## $ geo : Factor w/ 15 levels &quot;EA&quot;,&quot;UK&quot;,&quot;DK&quot;,..: 1 2 3 1 4 2 3 1 2 3 ... ## $ time : num 2019 2019 2019 2019 2019 ... ## $ values: num -0.39 0.67 -0.44 -0.4 -0.16 0.72 -0.06 -0.22 1 -0.37 ... head(datos, n=5) ## # A tibble: 5 x 4 ## int_rt geo time values ## &lt;fct&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 IRT_DTD EA 2019 -0.39 ## 2 IRT_DTD UK 2019 0.67 ## 3 IRT_M1 DK 2019 -0.44 ## 4 IRT_M1 EA 2019 -0.4 ## 5 IRT_M1 SE 2019 -0.16 4.10 Ejercicio 3 Crear un archivo de tipo CSV con los siguientes datos, distribuidos en cinco filas y 4 columnas, y separados por punto y coma (;): #;Estrato;Ingresos;Nombre 1;1;100.0;Jaime 2;2;150;María 3;2;140;Paula 4;5;90;Cristina Cargar estos datos desde el archivo csv a una variable “dataset10” en R / RStudio. Los datos de las primeras tres columnas deben ser numéricos (int o num) y de la última de tipo “character” (chr) Mostrar la estructura del “dataset10” en la pantalla Cambiar el nombre de la primera columna al texto “numero” "],
["explorar.html", "Sección 5 Explorar datos 5.1 Objetivo 5.2 Desarrollar un entendimiento inicial del conjunto de datos 5.3 Comprobar, si existen datos faltantes 5.4 Visualizaciones para explorar datos 5.5 Guardar un histograma 5.6 Apalancarse por el paquete DescTools 5.7 Ejercicio 4", " Sección 5 Explorar datos 5.1 Objetivo El objetivo de esta sección consiste en presentar diferentes formas para realizar EDA - Exploratory Data Analysis. La presentación incluye formas gráficas al respecto. Para empezar con una “exploración” necesitamos datos. P.ej. algunos datos de la web, desde un archivo csv … véase http://freakonometrics.free.fr/german_credit.csv url=&quot;http://freakonometrics.free.fr/german_credit.csv&quot; dataset &lt;- read.csv(url, header = TRUE, sep = &quot;,&quot;) 5.2 Desarrollar un entendimiento inicial del conjunto de datos Mostrar la clase del dataset Explorar las dimensiones del dataset Ver las primeras 6 filas del dataset Explorar la estructura del dataset Mostrar un resumen estadístico de las variables del dataset class(dataset) ## [1] &quot;data.frame&quot; dim(dataset) ## [1] 1000 21 head(dataset) ## Creditability Account.Balance Duration.of.Credit..month. ## 1 1 1 18 ## 2 1 1 9 ## 3 1 2 12 ## 4 1 1 12 ## 5 1 1 12 ## 6 1 1 10 ## Payment.Status.of.Previous.Credit Purpose Credit.Amount ## 1 4 2 1049 ## 2 4 0 2799 ## 3 2 9 841 ## 4 4 0 2122 ## 5 4 0 2171 ## 6 4 0 2241 ## Value.Savings.Stocks Length.of.current.employment Instalment.per.cent ## 1 1 2 4 ## 2 1 3 2 ## 3 2 4 2 ## 4 1 3 3 ## 5 1 3 4 ## 6 1 2 1 ## Sex...Marital.Status Guarantors Duration.in.Current.address ## 1 2 1 4 ## 2 3 1 2 ## 3 2 1 4 ## 4 3 1 2 ## 5 3 1 4 ## 6 3 1 3 ## Most.valuable.available.asset Age..years. Concurrent.Credits ## 1 2 21 3 ## 2 1 36 3 ## 3 1 23 3 ## 4 1 39 3 ## 5 2 38 1 ## 6 1 48 3 ## Type.of.apartment No.of.Credits.at.this.Bank Occupation No.of.dependents ## 1 1 1 3 1 ## 2 1 2 3 2 ## 3 1 1 2 1 ## 4 1 2 2 2 ## 5 2 2 2 1 ## 6 1 2 2 2 ## Telephone Foreign.Worker ## 1 1 1 ## 2 1 1 ## 3 1 1 ## 4 1 2 ## 5 1 2 ## 6 1 2 str(dataset) ## &#39;data.frame&#39;: 1000 obs. of 21 variables: ## $ Creditability : int 1 1 1 1 1 1 1 1 1 1 ... ## $ Account.Balance : int 1 1 2 1 1 1 1 1 4 2 ... ## $ Duration.of.Credit..month. : int 18 9 12 12 12 10 8 6 18 24 ... ## $ Payment.Status.of.Previous.Credit: int 4 4 2 4 4 4 4 4 4 2 ... ## $ Purpose : int 2 0 9 0 0 0 0 0 3 3 ... ## $ Credit.Amount : int 1049 2799 841 2122 2171 2241 3398 1361 1098 3758 ... ## $ Value.Savings.Stocks : int 1 1 2 1 1 1 1 1 1 3 ... ## $ Length.of.current.employment : int 2 3 4 3 3 2 4 2 1 1 ... ## $ Instalment.per.cent : int 4 2 2 3 4 1 1 2 4 1 ... ## $ Sex...Marital.Status : int 2 3 2 3 3 3 3 3 2 2 ... ## $ Guarantors : int 1 1 1 1 1 1 1 1 1 1 ... ## $ Duration.in.Current.address : int 4 2 4 2 4 3 4 4 4 4 ... ## $ Most.valuable.available.asset : int 2 1 1 1 2 1 1 1 3 4 ... ## $ Age..years. : int 21 36 23 39 38 48 39 40 65 23 ... ## $ Concurrent.Credits : int 3 3 3 3 1 3 3 3 3 3 ... ## $ Type.of.apartment : int 1 1 1 1 2 1 2 2 2 1 ... ## $ No.of.Credits.at.this.Bank : int 1 2 1 2 2 2 2 1 2 1 ... ## $ Occupation : int 3 3 2 2 2 2 2 2 1 1 ... ## $ No.of.dependents : int 1 2 1 2 1 2 1 2 1 1 ... ## $ Telephone : int 1 1 1 1 1 1 1 1 1 1 ... ## $ Foreign.Worker : int 1 1 1 2 2 2 2 2 1 1 ... summary(dataset) ## Creditability Account.Balance Duration.of.Credit..month. ## Min. :0.0 Min. :1.000 Min. : 4.0 ## 1st Qu.:0.0 1st Qu.:1.000 1st Qu.:12.0 ## Median :1.0 Median :2.000 Median :18.0 ## Mean :0.7 Mean :2.577 Mean :20.9 ## 3rd Qu.:1.0 3rd Qu.:4.000 3rd Qu.:24.0 ## Max. :1.0 Max. :4.000 Max. :72.0 ## Payment.Status.of.Previous.Credit Purpose Credit.Amount ## Min. :0.000 Min. : 0.000 Min. : 250 ## 1st Qu.:2.000 1st Qu.: 1.000 1st Qu.: 1366 ## Median :2.000 Median : 2.000 Median : 2320 ## Mean :2.545 Mean : 2.828 Mean : 3271 ## 3rd Qu.:4.000 3rd Qu.: 3.000 3rd Qu.: 3972 ## Max. :4.000 Max. :10.000 Max. :18424 ## Value.Savings.Stocks Length.of.current.employment Instalment.per.cent ## Min. :1.000 Min. :1.000 Min. :1.000 ## 1st Qu.:1.000 1st Qu.:3.000 1st Qu.:2.000 ## Median :1.000 Median :3.000 Median :3.000 ## Mean :2.105 Mean :3.384 Mean :2.973 ## 3rd Qu.:3.000 3rd Qu.:5.000 3rd Qu.:4.000 ## Max. :5.000 Max. :5.000 Max. :4.000 ## Sex...Marital.Status Guarantors Duration.in.Current.address ## Min. :1.000 Min. :1.000 Min. :1.000 ## 1st Qu.:2.000 1st Qu.:1.000 1st Qu.:2.000 ## Median :3.000 Median :1.000 Median :3.000 ## Mean :2.682 Mean :1.145 Mean :2.845 ## 3rd Qu.:3.000 3rd Qu.:1.000 3rd Qu.:4.000 ## Max. :4.000 Max. :3.000 Max. :4.000 ## Most.valuable.available.asset Age..years. Concurrent.Credits ## Min. :1.000 Min. :19.00 Min. :1.000 ## 1st Qu.:1.000 1st Qu.:27.00 1st Qu.:3.000 ## Median :2.000 Median :33.00 Median :3.000 ## Mean :2.358 Mean :35.54 Mean :2.675 ## 3rd Qu.:3.000 3rd Qu.:42.00 3rd Qu.:3.000 ## Max. :4.000 Max. :75.00 Max. :3.000 ## Type.of.apartment No.of.Credits.at.this.Bank Occupation ## Min. :1.000 Min. :1.000 Min. :1.000 ## 1st Qu.:2.000 1st Qu.:1.000 1st Qu.:3.000 ## Median :2.000 Median :1.000 Median :3.000 ## Mean :1.928 Mean :1.407 Mean :2.904 ## 3rd Qu.:2.000 3rd Qu.:2.000 3rd Qu.:3.000 ## Max. :3.000 Max. :4.000 Max. :4.000 ## No.of.dependents Telephone Foreign.Worker ## Min. :1.000 Min. :1.000 Min. :1.000 ## 1st Qu.:1.000 1st Qu.:1.000 1st Qu.:1.000 ## Median :1.000 Median :1.000 Median :1.000 ## Mean :1.155 Mean :1.404 Mean :1.037 ## 3rd Qu.:1.000 3rd Qu.:2.000 3rd Qu.:1.000 ## Max. :2.000 Max. :2.000 Max. :2.000 5.3 Comprobar, si existen datos faltantes Se debe analizar, si existen datos faltantes en el dataset, ya que la falta de datos afecta la calidad de los datos y puede “sesgar” el análisis de los mismos 5.3.1 Opción 1 Utilizar la función is.na() para determinar si existen datos faltantes (NAs) y mostrar las primeras 6 filas al respecto head(is.na(dataset)) # muestra el valor True para un dato faltante ## Creditability Account.Balance Duration.of.Credit..month. ## [1,] FALSE FALSE FALSE ## [2,] FALSE FALSE FALSE ## [3,] FALSE FALSE FALSE ## [4,] FALSE FALSE FALSE ## [5,] FALSE FALSE FALSE ## [6,] FALSE FALSE FALSE ## Payment.Status.of.Previous.Credit Purpose Credit.Amount ## [1,] FALSE FALSE FALSE ## [2,] FALSE FALSE FALSE ## [3,] FALSE FALSE FALSE ## [4,] FALSE FALSE FALSE ## [5,] FALSE FALSE FALSE ## [6,] FALSE FALSE FALSE ## Value.Savings.Stocks Length.of.current.employment Instalment.per.cent ## [1,] FALSE FALSE FALSE ## [2,] FALSE FALSE FALSE ## [3,] FALSE FALSE FALSE ## [4,] FALSE FALSE FALSE ## [5,] FALSE FALSE FALSE ## [6,] FALSE FALSE FALSE ## Sex...Marital.Status Guarantors Duration.in.Current.address ## [1,] FALSE FALSE FALSE ## [2,] FALSE FALSE FALSE ## [3,] FALSE FALSE FALSE ## [4,] FALSE FALSE FALSE ## [5,] FALSE FALSE FALSE ## [6,] FALSE FALSE FALSE ## Most.valuable.available.asset Age..years. Concurrent.Credits ## [1,] FALSE FALSE FALSE ## [2,] FALSE FALSE FALSE ## [3,] FALSE FALSE FALSE ## [4,] FALSE FALSE FALSE ## [5,] FALSE FALSE FALSE ## [6,] FALSE FALSE FALSE ## Type.of.apartment No.of.Credits.at.this.Bank Occupation ## [1,] FALSE FALSE FALSE ## [2,] FALSE FALSE FALSE ## [3,] FALSE FALSE FALSE ## [4,] FALSE FALSE FALSE ## [5,] FALSE FALSE FALSE ## [6,] FALSE FALSE FALSE ## No.of.dependents Telephone Foreign.Worker ## [1,] FALSE FALSE FALSE ## [2,] FALSE FALSE FALSE ## [3,] FALSE FALSE FALSE ## [4,] FALSE FALSE FALSE ## [5,] FALSE FALSE FALSE ## [6,] FALSE FALSE FALSE 5.3.2 Opción 2 Si se trata de un conjunto de datos con muchos datos, es mejor analizar los datos faltantes de forma gráfica, utilizando el paquete “Amelia” y la función missmap(). En este caso de nuestro dataset no existen datos faltantes, como se puede observar en la gráfica abajo arrojada por missmap if(!require(&#39;Amelia&#39;)) install.packages(&#39;Amelia&#39;); library(Amelia) ## Loading required package: Amelia ## Warning: package &#39;Amelia&#39; was built under R version 3.5.3 ## Loading required package: Rcpp ## Warning: package &#39;Rcpp&#39; was built under R version 3.5.3 ## ## ## ## Amelia II: Multiple Imputation ## ## (Version 1.7.5, built: 2018-05-07) ## ## Copyright (C) 2005-2020 James Honaker, Gary King and Matthew Blackwell ## ## Refer to http://gking.harvard.edu/amelia/ for more information ## ## missmap(dataset, main=&quot;Datos faltantes en el conjunto de datos - dataset&quot;, col=c(&quot;red&quot;,&quot;grey&quot;),legend=FALSE) 5.3.3 Opción 3 La función summary() muestra, si hay datos faltantes para una variable del conjunto de datos (dataset). Si existen datos faltantes, esto se indica como NAs. Usar la función summary() es muy útil y común, ya que el resultado muestra una estadística descripitva para cada atributo (coloumna) de los datos de forma resumida. Nota: Como se muestra el resultado depende del tipo de una variable. El resultado de una variable continúa se muestre diferente al resultado de una variable categórica summary(dataset) ## Creditability Account.Balance Duration.of.Credit..month. ## Min. :0.0 Min. :1.000 Min. : 4.0 ## 1st Qu.:0.0 1st Qu.:1.000 1st Qu.:12.0 ## Median :1.0 Median :2.000 Median :18.0 ## Mean :0.7 Mean :2.577 Mean :20.9 ## 3rd Qu.:1.0 3rd Qu.:4.000 3rd Qu.:24.0 ## Max. :1.0 Max. :4.000 Max. :72.0 ## Payment.Status.of.Previous.Credit Purpose Credit.Amount ## Min. :0.000 Min. : 0.000 Min. : 250 ## 1st Qu.:2.000 1st Qu.: 1.000 1st Qu.: 1366 ## Median :2.000 Median : 2.000 Median : 2320 ## Mean :2.545 Mean : 2.828 Mean : 3271 ## 3rd Qu.:4.000 3rd Qu.: 3.000 3rd Qu.: 3972 ## Max. :4.000 Max. :10.000 Max. :18424 ## Value.Savings.Stocks Length.of.current.employment Instalment.per.cent ## Min. :1.000 Min. :1.000 Min. :1.000 ## 1st Qu.:1.000 1st Qu.:3.000 1st Qu.:2.000 ## Median :1.000 Median :3.000 Median :3.000 ## Mean :2.105 Mean :3.384 Mean :2.973 ## 3rd Qu.:3.000 3rd Qu.:5.000 3rd Qu.:4.000 ## Max. :5.000 Max. :5.000 Max. :4.000 ## Sex...Marital.Status Guarantors Duration.in.Current.address ## Min. :1.000 Min. :1.000 Min. :1.000 ## 1st Qu.:2.000 1st Qu.:1.000 1st Qu.:2.000 ## Median :3.000 Median :1.000 Median :3.000 ## Mean :2.682 Mean :1.145 Mean :2.845 ## 3rd Qu.:3.000 3rd Qu.:1.000 3rd Qu.:4.000 ## Max. :4.000 Max. :3.000 Max. :4.000 ## Most.valuable.available.asset Age..years. Concurrent.Credits ## Min. :1.000 Min. :19.00 Min. :1.000 ## 1st Qu.:1.000 1st Qu.:27.00 1st Qu.:3.000 ## Median :2.000 Median :33.00 Median :3.000 ## Mean :2.358 Mean :35.54 Mean :2.675 ## 3rd Qu.:3.000 3rd Qu.:42.00 3rd Qu.:3.000 ## Max. :4.000 Max. :75.00 Max. :3.000 ## Type.of.apartment No.of.Credits.at.this.Bank Occupation ## Min. :1.000 Min. :1.000 Min. :1.000 ## 1st Qu.:2.000 1st Qu.:1.000 1st Qu.:3.000 ## Median :2.000 Median :1.000 Median :3.000 ## Mean :1.928 Mean :1.407 Mean :2.904 ## 3rd Qu.:2.000 3rd Qu.:2.000 3rd Qu.:3.000 ## Max. :3.000 Max. :4.000 Max. :4.000 ## No.of.dependents Telephone Foreign.Worker ## Min. :1.000 Min. :1.000 Min. :1.000 ## 1st Qu.:1.000 1st Qu.:1.000 1st Qu.:1.000 ## Median :1.000 Median :1.000 Median :1.000 ## Mean :1.155 Mean :1.404 Mean :1.037 ## 3rd Qu.:1.000 3rd Qu.:2.000 3rd Qu.:1.000 ## Max. :2.000 Max. :2.000 Max. :2.000 5.3.4 Opción 4 Cargar el paquete “ez” y ejectuar la función exPrecis() para el conjunto de datos (dataset) if(!require(&#39;ez&#39;)) install.packages(&#39;ez&#39;); library(ez) ## Loading required package: ez ## Warning: package &#39;ez&#39; was built under R version 3.5.3 ezPrecis(dataset) ## Data frame dimensions: 1000 rows, 21 columns ## type missing values min max ## Creditability numeric 0 2 0 1 ## Account.Balance numeric 0 4 1 4 ## Duration.of.Credit..month. numeric 0 33 4 72 ## Payment.Status.of.Previous.Credit numeric 0 5 0 4 ## Purpose numeric 0 10 0 10 ## Credit.Amount numeric 0 923 250 18424 ## Value.Savings.Stocks numeric 0 5 1 5 ## Length.of.current.employment numeric 0 5 1 5 ## Instalment.per.cent numeric 0 4 1 4 ## Sex...Marital.Status numeric 0 4 1 4 ## Guarantors numeric 0 3 1 3 ## Duration.in.Current.address numeric 0 4 1 4 ## Most.valuable.available.asset numeric 0 4 1 4 ## Age..years. numeric 0 53 19 75 ## Concurrent.Credits numeric 0 3 1 3 ## Type.of.apartment numeric 0 3 1 3 ## No.of.Credits.at.this.Bank numeric 0 4 1 4 ## Occupation numeric 0 4 1 4 ## No.of.dependents numeric 0 2 1 2 ## Telephone numeric 0 2 1 2 ## Foreign.Worker numeric 0 2 1 2 5.4 Visualizaciones para explorar datos Utlizar el paquete “ggplot2” para la visualización de los datos y el paquete “farver” (High Performance Colour Space Manipulation) Utilizar el diagrama de bigote (diagrama de caja o boxplot), únicamente para variables continuas, para visualizar datos extremos (outliers) Aquí, generar un boxplot para las 2 variables “Creditibility” (lo que significa default) y “Credit.Amount” (Monto del crédito) del dataset library(ggplot2) library(farver) ## Warning: package &#39;farver&#39; was built under R version 3.5.3 dataset.boxplot &lt;- ggplot(data=dataset, aes(x = as.factor(Creditability), y = Credit.Amount)) # agregar la capa del boxplot mediante la función geom_boxplot() dataset.boxplot + geom_boxplot() # y utilizar etiquetas adecuadas mediante la función labs() dataset.boxplot + geom_boxplot() + labs(x=&quot;Default (0 or 1)&quot;, y = &quot;Amount&quot;) Utilizar histogramas. Estos diagramas se pueden utilizar para variables continuas y categóricas (factor) Histogramas proveen información sobre un posible sesgo en la distribución de los datos (skewness) y sobre su nivel de levantamiento o cuán aplanada es la distribución (kurtosis). Es decir, se puede ver el nivel de normalidad de la distribución dataset.histogram &lt;-ggplot(data=dataset, aes(x = Creditability)) + theme(legend.position=&quot;none&quot;) dataset.histogram + geom_bar(colour=&quot;darkgreen&quot;, fill=&quot;white&quot; ) + labs(x=&quot;Default 0 or 1&quot;, y=&quot;Frequency&quot;) 5.5 Guardar un histograma Guardar la gráfica en un archivo de tipo “png”, bajo el nombre “HistogramDefault.png” en el directorio de trabajo de R, utilizando la función ggsave() Comprobar en el directorio de trabajo, si usted puede encontrar este archivo en este lugar (una vez guardado) y abrirlo con un visor de imágenes (herramienta de windows) … #ggsave(file=&quot;HistogramDefault.png&quot;) 5.6 Apalancarse por el paquete DescTools El paquete DescTools provee funcionalidad en términos de una estadística descriptiva y de un análisis exploratorio de los datos para comprender mejor los datos (antes de generar modelos). Donde DescTools = Tools for Descriptive Statistics and Exploratory Data Analysis. Cargar este paquete, utilizando la función library() library(DescTools) ## Warning: package &#39;DescTools&#39; was built under R version 3.5.3 Consultar la páginas de ayuda de DescTools: ?DescTools ?DescTools Describir de la variable data los datos de la columna “Credit.Amount”, utilizando la función Desc(). Nota: Es con D mayúscula Observar el resultado en la pantalla Desc(dataset$Credit.Amount) ## ------------------------------------------------------------------------- ## dataset$Credit.Amount (integer) ## ## length n NAs unique 0s mean meanCI ## 1&#39;000 1&#39;000 0 923 0 3&#39;271.25 3&#39;096.08 ## 100.0% 0.0% 0.0% 3&#39;446.41 ## ## .05 .10 .25 median .75 .90 .95 ## 708.95 934.70 1&#39;365.50 2&#39;319.50 3&#39;972.25 7&#39;179.40 9&#39;162.70 ## ## range sd vcoef mad IQR skew kurt ## 18&#39;174.00 2&#39;822.75 0.86 1&#39;627.15 2&#39;606.75 1.94 4.25 ## ## lowest : 250, 276, 338, 339, 343 ## highest: 15&#39;653, 15&#39;672, 15&#39;857, 15&#39;945, 18&#39;424 Para la columna dataset$Credit.Amount realizar un qq-plot (gráfica), utilizando el paquete DescTools Interpretar el resultado, que muestra la gráfica (el QQ-Plot) PlotQQ(dataset$Credit.Amount) Ahora, utilizar la función PlotFdist() de DescTools para la misma variable (Credit.Amount) Observar el resultado, que combina una gráfica de la distribución de frecuencias, un histograma, un diagrama de caja (box plot) y ecdf.plotd PlotFdist(dataset$Credit.Amount) Generar una tabla de frecuencias para la variable Credit.Amount, utilizando la función Freq() Observar el resultado Freq(dataset$Credit.Amount) ## level freq perc cumfreq cumperc ## 1 [0,2e+03] 432 43.2% 432 43.2% ## 2 (2e+03,4e+03] 322 32.2% 754 75.4% ## 3 (4e+03,6e+03] 97 9.7% 851 85.1% ## 4 (6e+03,8e+03] 79 7.9% 930 93.0% ## 5 (8e+03,1e+04] 30 3.0% 960 96.0% ## 6 (1e+04,1.2e+04] 19 1.9% 979 97.9% ## 7 (1.2e+04,1.4e+04] 9 0.9% 988 98.8% ## 8 (1.4e+04,1.6e+04] 11 1.1% 999 99.9% ## 9 (1.6e+04,1.8e+04] 0 0.0% 999 99.9% ## 10 (1.8e+04,2e+04] 1 0.1% 1&#39;000 100.0% Generar un diagrama de caja de dos dimensiones (two dimensional boxplot). Es decir, un “bagplot”. Este diagrama se genera con base en dos variables numéricos “x” y “y”. Aquí vamos a utilizar: Credit.Amount y Duration.of.Credit..month Observar el resultado ¿Qué se puede decir, con respecto a valores extremos (outliers)? PlotBag(dataset$Credit.Amount, dataset$Duration.of.Credit..month.) 5.7 Ejercicio 4 Analizar el paquete “DataExplorer” de R para explorar datos Cargar los datos de la siguiente forma: url=“http://freakonometrics.free.fr/german_credit.csv” dataset &lt;- read.csv(url, header = TRUE, sep = “,”) Luego, utilizar el paquete “DataExplorer”, utilizando la función “plot_str()” Visualizar los valores faltantes, utilizando una función adecuada del paquete “DataExplorer” Crear histogramas para (las variables continúas) del “dataset”, utilizando una función adecuada del paquete “DataExplorer” Crear un data frame “dataset2”, que contiene los valores de las columnas “Age..years.” y “Credit.Amount” del dataset Visualizar las correlaciones entre los valores de las columnas “Age..years.” y “Credit.Amount” del dataset2 Aplicar la función plot_bar del paquete “DataExplorer” al dataset "],
["tidy.html", "Sección 6 El paquete tidyverse y su funcionalidad 6.1 Objetivo y contextualización 6.2 tibble (parte del ecosistema tidyverse) 6.3 Utilizar y aplicar funciones del tidyverse 6.4 Ejercicio más avanzado 6.5 Ejercicio 5", " Sección 6 El paquete tidyverse y su funcionalidad 6.1 Objetivo y contextualización Conocer un sistema “interesante” de paquetes en R para agilizar la programación y lectura de código. El tidyverse es un sistema coherente de varios paquetes para la manipulación, exploración y visualización de datos. Los elementos de tidyverse comparten una filosofía de diseño común. Los elementos del tidyverse conforman un conjunto de paquetes. La siguiente página web informa sobre estos: https://www.tidyverse.org/packages/ El siguiente vínculo presenta una visualización gráfica y panorámica del tidyverse: https://rviews.rstudio.com/post/2017-06-09-What-is-the-tidyverse_files/tidyverse1.png Tidy data se refiere a “datos ordenados”. Es un término que describe un enfoque estandarizado para estructurar conjuntos de datos para facilitar su análisis y las visualizaciones Frigaard, M. (12/05/2017). Getting Started with tidyverse in R Hay tres principios para los datos ordenados Frigaard, M. (12/05/2017). Getting Started with tidyverse in R: Variables conforman las columnas Las observaciones forman las filas Los valores entran en las celdas 6.2 tibble (parte del ecosistema tidyverse) Un tibble, o tbl_df, es una presentación moderna de un data frame. Manteniendo elementos que en el tiempo se han demostrado como efectivo y descartando lo que no lo es (https://tibble.tidyverse.org/). Leer algunos datos de la web (http://freakonometrics.free.fr/german_credit.csv), desde un archivo csv … véase aquí y asignar el resultado a una variable “dataset” url=&quot;http://freakonometrics.free.fr/german_credit.csv&quot; dataset &lt;- read.csv(url, header = TRUE, sep = &quot;,&quot;) Transformar estos datos a un tibble, utilizando la función as_tibble() del paquete tidyverse Mostrar en la pantalla las primeras seis filas de este tibble library(tidyverse) # dplyr ?tidyverse dataset &lt;- as_tibble(dataset) class(dataset) # [1] &quot;tbl_df&quot; &quot;tbl&quot; &quot;data.frame&quot; ## [1] &quot;tbl_df&quot; &quot;tbl&quot; &quot;data.frame&quot; print(head(dataset, n= 5)) ## # A tibble: 5 x 21 ## Creditability Account.Balance Duration.of.Cre~ Payment.Status.~ Purpose ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 1 1 18 4 2 ## 2 1 1 9 4 0 ## 3 1 2 12 2 9 ## 4 1 1 12 4 0 ## 5 1 1 12 4 0 ## # ... with 16 more variables: Credit.Amount &lt;int&gt;, ## # Value.Savings.Stocks &lt;int&gt;, Length.of.current.employment &lt;int&gt;, ## # Instalment.per.cent &lt;int&gt;, Sex...Marital.Status &lt;int&gt;, ## # Guarantors &lt;int&gt;, Duration.in.Current.address &lt;int&gt;, ## # Most.valuable.available.asset &lt;int&gt;, Age..years. &lt;int&gt;, ## # Concurrent.Credits &lt;int&gt;, Type.of.apartment &lt;int&gt;, ## # No.of.Credits.at.this.Bank &lt;int&gt;, Occupation &lt;int&gt;, ## # No.of.dependents &lt;int&gt;, Telephone &lt;int&gt;, Foreign.Worker &lt;int&gt; Ver los nombres de las variables (columnas) colnames(dataset) # devuelve los nombres de las columnas ## [1] &quot;Creditability&quot; ## [2] &quot;Account.Balance&quot; ## [3] &quot;Duration.of.Credit..month.&quot; ## [4] &quot;Payment.Status.of.Previous.Credit&quot; ## [5] &quot;Purpose&quot; ## [6] &quot;Credit.Amount&quot; ## [7] &quot;Value.Savings.Stocks&quot; ## [8] &quot;Length.of.current.employment&quot; ## [9] &quot;Instalment.per.cent&quot; ## [10] &quot;Sex...Marital.Status&quot; ## [11] &quot;Guarantors&quot; ## [12] &quot;Duration.in.Current.address&quot; ## [13] &quot;Most.valuable.available.asset&quot; ## [14] &quot;Age..years.&quot; ## [15] &quot;Concurrent.Credits&quot; ## [16] &quot;Type.of.apartment&quot; ## [17] &quot;No.of.Credits.at.this.Bank&quot; ## [18] &quot;Occupation&quot; ## [19] &quot;No.of.dependents&quot; ## [20] &quot;Telephone&quot; ## [21] &quot;Foreign.Worker&quot; # rownames(dataset) # devuelve los números de las filas... Mostrar, en una tabla (de frecuencias), las frecuencias para los valores (binarios) de la variable “Creditability” (columna “Creditability”), utilizando la función table() Observar el resultado: ¿Cuántas observaciones son de “buena paga”? table(dataset$Creditability) # 300 = 0 y 700 = 1, donde 1 significa &quot;buena calidad crediticia&quot; ## ## 0 1 ## 300 700 6.3 Utilizar y aplicar funciones del tidyverse 6.3.1 filter Filtrar el dataset, por ejemplo por el campo Creditability == 0, utilizando tidyverse con el comando pipe [ %&gt;% ] y la función filter() Mostrar las primeras 5 filas dataset %&gt;% filter(Creditability == 0) %&gt;% head(n=5) ## # A tibble: 5 x 21 ## Creditability Account.Balance Duration.of.Cre~ Payment.Status.~ Purpose ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 0 2 36 2 5 ## 2 0 1 18 2 0 ## 3 0 4 18 4 6 ## 4 0 2 36 3 9 ## 5 0 1 15 2 0 ## # ... with 16 more variables: Credit.Amount &lt;int&gt;, ## # Value.Savings.Stocks &lt;int&gt;, Length.of.current.employment &lt;int&gt;, ## # Instalment.per.cent &lt;int&gt;, Sex...Marital.Status &lt;int&gt;, ## # Guarantors &lt;int&gt;, Duration.in.Current.address &lt;int&gt;, ## # Most.valuable.available.asset &lt;int&gt;, Age..years. &lt;int&gt;, ## # Concurrent.Credits &lt;int&gt;, Type.of.apartment &lt;int&gt;, ## # No.of.Credits.at.this.Bank &lt;int&gt;, Occupation &lt;int&gt;, ## # No.of.dependents &lt;int&gt;, Telephone &lt;int&gt;, Foreign.Worker &lt;int&gt; 6.3.2 arrange Ordenar el resultado anterior por la columna edad (Age..years.) de manera descendente, utilizando la función arrange() dataset %&gt;% filter(Creditability ==0) %&gt;% arrange(desc(Age..years.)) %&gt;% head(n=5) ## # A tibble: 5 x 21 ## Creditability Account.Balance Duration.of.Cre~ Payment.Status.~ Purpose ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 0 2 9 1 1 ## 2 0 4 18 2 0 ## 3 0 1 6 2 0 ## 4 0 2 12 2 3 ## 5 0 3 30 3 9 ## # ... with 16 more variables: Credit.Amount &lt;int&gt;, ## # Value.Savings.Stocks &lt;int&gt;, Length.of.current.employment &lt;int&gt;, ## # Instalment.per.cent &lt;int&gt;, Sex...Marital.Status &lt;int&gt;, ## # Guarantors &lt;int&gt;, Duration.in.Current.address &lt;int&gt;, ## # Most.valuable.available.asset &lt;int&gt;, Age..years. &lt;int&gt;, ## # Concurrent.Credits &lt;int&gt;, Type.of.apartment &lt;int&gt;, ## # No.of.Credits.at.this.Bank &lt;int&gt;, Occupation &lt;int&gt;, ## # No.of.dependents &lt;int&gt;, Telephone &lt;int&gt;, Foreign.Worker &lt;int&gt; 6.3.3 group_by y summarize Contar las observaciones por el campo destino (“Purpose”) del crédito, utilizando la función group_by() y la función summarize() Mostrar el resultado en la pantalla dataset %&gt;% group_by(Purpose) %&gt;% summarize(cantidad = n()) ## # A tibble: 10 x 2 ## Purpose cantidad ## &lt;int&gt; &lt;int&gt; ## 1 0 234 ## 2 1 103 ## 3 2 181 ## 4 3 280 ## 5 4 12 ## 6 5 22 ## 7 6 50 ## 8 8 9 ## 9 9 97 ## 10 10 12 6.3.4 select Seleccionar únicamente las columnas “Creditability”&quot; y “Credit.Amount”&quot; del dataset, utilizando la función select(), y mostrar las primeras 5 filas dataset %&gt;% select(Creditability, Credit.Amount) %&gt;% head(n=5) ## # A tibble: 5 x 2 ## Creditability Credit.Amount ## &lt;int&gt; &lt;int&gt; ## 1 1 1049 ## 2 1 2799 ## 3 1 841 ## 4 1 2122 ## 5 1 2171 6.3.5 mutate Agregar una nueva columna “Avg.Amount” al dataset que contiene el promedio del monto del crédito (Credit.Amount), utilizando la función mutate() Mostrar las primeras 5 filas del “dataset” dataset %&gt;% mutate(Avg.Amount = mean(Credit.Amount)) %&gt;% head(n=5) ## # A tibble: 5 x 22 ## Creditability Account.Balance Duration.of.Cre~ Payment.Status.~ Purpose ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 1 1 18 4 2 ## 2 1 1 9 4 0 ## 3 1 2 12 2 9 ## 4 1 1 12 4 0 ## 5 1 1 12 4 0 ## # ... with 17 more variables: Credit.Amount &lt;int&gt;, ## # Value.Savings.Stocks &lt;int&gt;, Length.of.current.employment &lt;int&gt;, ## # Instalment.per.cent &lt;int&gt;, Sex...Marital.Status &lt;int&gt;, ## # Guarantors &lt;int&gt;, Duration.in.Current.address &lt;int&gt;, ## # Most.valuable.available.asset &lt;int&gt;, Age..years. &lt;int&gt;, ## # Concurrent.Credits &lt;int&gt;, Type.of.apartment &lt;int&gt;, ## # No.of.Credits.at.this.Bank &lt;int&gt;, Occupation &lt;int&gt;, ## # No.of.dependents &lt;int&gt;, Telephone &lt;int&gt;, Foreign.Worker &lt;int&gt;, ## # Avg.Amount &lt;dbl&gt; Agregar una nueva columna “Default” al dataset, que contiene el valor “Yes”, si el valor del campo “Creditability” es igual a “0”, en el caso contrario, colocar el valor “No”. Utilizar la función mutate() con ifelse() al respecto Mostrar las primeras 5 filas del “dataset” dataset %&gt;% mutate(Default = ifelse(Creditability==0, &#39;Yes&#39;, &#39;No&#39;)) %&gt;% head(n=5) ## # A tibble: 5 x 22 ## Creditability Account.Balance Duration.of.Cre~ Payment.Status.~ Purpose ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 1 1 18 4 2 ## 2 1 1 9 4 0 ## 3 1 2 12 2 9 ## 4 1 1 12 4 0 ## 5 1 1 12 4 0 ## # ... with 17 more variables: Credit.Amount &lt;int&gt;, ## # Value.Savings.Stocks &lt;int&gt;, Length.of.current.employment &lt;int&gt;, ## # Instalment.per.cent &lt;int&gt;, Sex...Marital.Status &lt;int&gt;, ## # Guarantors &lt;int&gt;, Duration.in.Current.address &lt;int&gt;, ## # Most.valuable.available.asset &lt;int&gt;, Age..years. &lt;int&gt;, ## # Concurrent.Credits &lt;int&gt;, Type.of.apartment &lt;int&gt;, ## # No.of.Credits.at.this.Bank &lt;int&gt;, Occupation &lt;int&gt;, ## # No.of.dependents &lt;int&gt;, Telephone &lt;int&gt;, Foreign.Worker &lt;int&gt;, ## # Default &lt;chr&gt; # o con case_when() # dataset &lt;- dataset %&gt;% # mutate(Default = case_when(Creditability == 1 ~ &#39;No&#39;, # Creditability == 0 ~ &#39;Yes&#39; )) 6.4 Ejercicio más avanzado 6.4.1 Procesar datos bursátiles con pipes (%&gt;%) Cargar el paquete (library) tidyverse Bajar los datos de la bolsa New York Stock Exchange (NYSE), mediante la función tq_exchange(“NYSE”) y asignar el resultado a la variable “nyse” Bajar los datos de la bolsa NASDAQ, mediante la función tq_exchange(“NASDAQ”) y asignar el resultado a la variable “nasdaq” Unir los registros de las dos fuentes de datos (variables) “nyse” y “nasdaq”, utlizando la función rbind(), creando una variable nueva “nyse_nasdaq” Bajar los datos del indice búrsatil S&amp;P500 (SP500), mediante la función tq_index(“SP500”) y asignar el resultado a la variable “sp500” Une “sp500” y “nyse_nasdaq”, utilizando un “inner join” (función inner_join()) y tomando el atributo (columna) “symbol”, dado que estas dos fuentes tienen este atributo en común Filtrar por registros, donde el año del IPO (“ipo.year”) es menor al año 2000 y donde el campo “market.cap” no tiene datos faltantes (NA) Ordenar por el campo (columna) “weight” de forma descendente y mostrar únicamente las primeras 10 filas, utilizando la función slice() Mostrar el resultado en la pantalla Es decir, lo que se hace aquí es que queremos utilizar el conjunto de datos que consiste, por un lado, en las diez acciones más grandes dentro del índice S&amp;P500, que tuvieron su IPO antes de enero del año 2000. Por otro lado, debemos combinar ambos conjuntos de datos (“S&amp;P500” y “NYSE más NASDAQ”, usando un “inner join”, porque solo queremos mantener los símbolos del S&amp;P500, que también se negocian en NYSE o NASDAQ Stöckl, S. (21/09/2018). Tidy Portfoliomanagement in R. library(tidyverse) library(tidyquant) # debe ser la versión actual (&gt;=0.5.9) tq_exchange_options() # &quot;AMEX&quot; &quot;NASDAQ&quot; &quot;NYSE&quot; ## [1] &quot;AMEX&quot; &quot;NASDAQ&quot; &quot;NYSE&quot; nyse &lt;- tq_exchange(&quot;NYSE&quot;) ## Getting data... nasdaq &lt;- tq_exchange(&quot;NASDAQ&quot;) ## Getting data... nyse_nasdaq &lt;- rbind(nyse,nasdaq) sp500 &lt;- tq_index(&quot;SP500&quot;) ## Getting holdings for SP500 acciones.seleccion &lt;- sp500 %&gt;% inner_join(nyse_nasdaq, by=c(&quot;symbol&quot;)) %&gt;% select(symbol,last.sale.price, market.cap, weight, ipo.year)%&gt;% # join datasets filter(ipo.year&lt;2000 &amp; !is.na(market.cap)) %&gt;% # filtrar años con año del ipo&lt;2000 o ipo=NA arrange(desc(weight)) %&gt;% # ordenar en orden descendente slice(1:10) print(acciones.seleccion) # se puede observar que AAPL (Apple) es la empresa &quot;más grande&quot;... ## # A tibble: 10 x 5 ## symbol last.sale.price market.cap weight ipo.year ## &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 AAPL 310. $1356.9B 0.0497 1980 ## 2 MSFT 170. $1298.65B 0.0484 1986 ## 3 AMZN 2009. $995.92B 0.0286 1997 ## 4 CSCO 46.0 $195.02B 0.00737 1990 ## 5 ADBE 351. $171.26B 0.00635 1986 ## 6 NVDA 236. $144.7B 0.00553 1999 ## 7 AMGN 216. $128.37B 0.00494 1983 ## 8 ORCL 52.4 $168.24B 0.00425 1986 ## 9 SBUX 84.8 $99.56B 0.00373 1992 ## 10 QCOM 85.3 $97.45B 0.00368 1991 6.5 Ejercicio 5 Cargar el paquete “tidyverse” Utilizar el conjunto de datos “iris”, que se instaló con R: data(iris) Ver la siguiente descripción al respecto: https://es.wikipedia.org/wiki/Conjunto_de_datos_flor_iris Mostrar las primeras 5 filas de “iris” en la pantalla Agrupar los datos de iris por la columna “Species” y asignar el resultado a una variable “iris.por.species”, utilizando tidyverse Mostrar las últimas 3 filas de “iris.por.species” Agregar una columna a “iris.por.species”, donde se muestra el valor promedio para los valores de la columna “Sepal.Length”, utilizando tidyverse "],
["bucles.html", "Sección 7 Bucles / ciclos 7.1 Objetivo 7.2 ¿Qué son las funciones del tipo “apply()”? 7.3 apply 7.4 lapply 7.5 sapply 7.6 Ejercicio 6", " Sección 7 Bucles / ciclos 7.1 Objetivo Programar un ciclo de una forma “sencilla”. Es decir, un secuencia de comandos que se ejecuta repetidas veces, pero sin escribir mucho código. 7.2 ¿Qué son las funciones del tipo “apply()”? Respuesta: ciclos, bucles o “loops” apply - se utiliza para una matriz. Para “iterar” sobre sus filas o columnas. tapply - se utiliza para una matriz para extraer subconjuntos de datos y aplicar una función sobre ellos. Para data frames es parecido al concepto de “group by” en SQL (Standard Query Language) eapply - se utiliza para un entorno (environment (E)) lapply - se utiliza para iterar sobre los elementos de una lista ( list (L)) sapply - una versión más sencilla de lapply. Es decir, simplifica el resultado (simplify (S)), ya que el resultado no se muestra como una lista, sino como matriz o vector vapply - devuelve un valor predeterminado (pre-defined return value (V)) replicate - ejecuta una función varias veces y se utiliza, en términos generales, en la generación de números (variables) aleatorios mapply - versión multivariada (multivariate (M)) de sapply. Los argumentos de la función se pueden “reciclar” rapply - una versión recursiva de lapply (recursive (R) version) A continuación, nos enfocamos en la aplicación de las funciones: apply, lapply y sapply. Dónde, apply se utiliza para matrices y lapply y sapply para listas y vectores. Consultar la ayuda para la función apply ?apply 7.3 apply Apply tiene la siguiente signatura: apply(X, MARGIN, FUN, …) Donde, x es una matriz y margin es 1 (rows) o 2 (columns) y FuN es una función (function), p.ej. una función parecida a la función promedio: mean() Generar primero “manualmente” un data frame “dataset” con los siguientes datos para poder demostrar después el funcionamiento de las funciones del tipo apply() id Nombre Apellido Ingresos Egresos Calificación 1 Jimmy Toro 4000000 3500000 80 2 Joe Arango 3500000 4000000 20 3 Diana Ramírez 3000000 3000000 50 4 Cris Mesa 2500000 2000000 70 5 Manuela Meier 2000000 1000000 70 6 Lucia Müller 1500000 1400000 45 7 Andrés Aveláez 1000000 1000000 40 8 Bill Jaramillo 750000 800000 10 9 Gabriel Arias 500000 500000 12 10 Javier Gómez 450000 450000 10 dataset &lt;- data.frame(id= 1:10, Nombre = c(&quot;Jimmy&quot;, &quot;Joe&quot;, &quot;Diana&quot;, &quot;Cris&quot;, &quot;Manuela&quot;, &quot;Lucia&quot;, &quot;Andrés&quot;, &quot;Bill&quot;, &quot;Gabriel&quot;, &quot;Javier&quot;), Apellido = c(&quot;Toro&quot;, &quot;Arango&quot;, &quot;Ramírez&quot;, &quot;Mesa&quot;, &quot;Meier&quot;, &quot;Müller&quot;, &quot;Aveláez&quot;, &quot;Jaramillo&quot;, &quot;Arias&quot;, &quot;Gómez&quot;), Ingresos = c(4000000, 3500000, 3000000, 2500000, 2000000, 1500000, 1000000, 750000, 500000, 450000), Egresos = c(3500000, 4000000, 3000000, 2000000, 1000000, 1400000, 1000000, 800000, 500000, 450000), Calificacion = c(80, 20, 50, 70, 70, 45, 40, 10, 12, 10) ) class(dataset) ## [1] &quot;data.frame&quot; print(dataset) # imprimir el dataset a la pantalla (consola) ## id Nombre Apellido Ingresos Egresos Calificacion ## 1 1 Jimmy Toro 4000000 3500000 80 ## 2 2 Joe Arango 3500000 4000000 20 ## 3 3 Diana Ramírez 3000000 3000000 50 ## 4 4 Cris Mesa 2500000 2000000 70 ## 5 5 Manuela Meier 2000000 1000000 70 ## 6 6 Lucia Müller 1500000 1400000 45 ## 7 7 Andrés Aveláez 1000000 1000000 40 ## 8 8 Bill Jaramillo 750000 800000 10 ## 9 9 Gabriel Arias 500000 500000 12 ## 10 10 Javier Gómez 450000 450000 10 Determinar el valor máximo para las filas (para cada fila) del dataset, utlizando apply() con la función max apply(dataset, 1, max) # 1 = por filas ## [1] &quot;Toro&quot; &quot;Joe&quot; &quot;Ramírez&quot; &quot;Mesa&quot; &quot;Meier&quot; ## [6] &quot;Müller&quot; &quot;Aveláez&quot; &quot;Jaramillo&quot; &quot;Gabriel&quot; &quot;Javier&quot; Determinar el valor máximo para las columnas (para cada columna) del dataset, utilizando apply/() con la función max apply(dataset, 2, max) # 2 = por columnas ## id Nombre Apellido Ingresos Egresos ## &quot;10&quot; &quot;Manuela&quot; &quot;Toro&quot; &quot;4000000&quot; &quot;4000000&quot; ## Calificacion ## &quot;80&quot; Determinar, si el dataset tiene datos faltantes, utilizando apply con la función is.na apply(dataset, 2, is.na) ## id Nombre Apellido Ingresos Egresos Calificacion ## [1,] FALSE FALSE FALSE FALSE FALSE FALSE ## [2,] FALSE FALSE FALSE FALSE FALSE FALSE ## [3,] FALSE FALSE FALSE FALSE FALSE FALSE ## [4,] FALSE FALSE FALSE FALSE FALSE FALSE ## [5,] FALSE FALSE FALSE FALSE FALSE FALSE ## [6,] FALSE FALSE FALSE FALSE FALSE FALSE ## [7,] FALSE FALSE FALSE FALSE FALSE FALSE ## [8,] FALSE FALSE FALSE FALSE FALSE FALSE ## [9,] FALSE FALSE FALSE FALSE FALSE FALSE ## [10,] FALSE FALSE FALSE FALSE FALSE FALSE Determinar la estructura del dataset, utilizando la función str() str(dataset) # data frame ## &#39;data.frame&#39;: 10 obs. of 6 variables: ## $ id : int 1 2 3 4 5 6 7 8 9 10 ## $ Nombre : Factor w/ 10 levels &quot;Andrés&quot;,&quot;Bill&quot;,..: 7 8 4 3 10 9 1 2 5 6 ## $ Apellido : Factor w/ 10 levels &quot;Arango&quot;,&quot;Arias&quot;,..: 10 1 9 7 6 8 3 5 2 4 ## $ Ingresos : num 4000000 3500000 3000000 2500000 2000000 1500000 1000000 750000 500000 450000 ## $ Egresos : num 3500000 4000000 3000000 2000000 1000000 1400000 1000000 800000 500000 450000 ## $ Calificacion: num 80 20 50 70 70 45 40 10 12 10 Mejor es, utilizar únicamente datos numéricos para las siguientes operaciones. De acuerdo con lo anterior, generar una variable “dataset.num” a partir del dataset, utilizando las siguientes columnas (numéricas): “Ingresos”, “Egresos” y “Calificacion” dataset.num &lt;- dataset[ , c(&quot;Ingresos&quot;, &quot;Egresos&quot;, &quot;Calificacion&quot;)] print(dataset.num) ## Ingresos Egresos Calificacion ## 1 4000000 3500000 80 ## 2 3500000 4000000 20 ## 3 3000000 3000000 50 ## 4 2500000 2000000 70 ## 5 2000000 1000000 70 ## 6 1500000 1400000 45 ## 7 1000000 1000000 40 ## 8 750000 800000 10 ## 9 500000 500000 12 ## 10 450000 450000 10 Determinar para “dataset.num” el promedio por filas, utilizando apply() con mean apply(dataset.num, 1, mean) # calcula el promedio por columna (2) ## [1] 2500026.7 2500006.7 2000016.7 1500023.3 1000023.3 966681.7 666680.0 ## [8] 516670.0 333337.3 300003.3 Determinar para “datset.num” el promedio por columnas, utilizando apply() con mean apply(dataset.num, 2, mean) # calcula el promedio por columna (2) ## Ingresos Egresos Calificacion ## 1920000.0 1765000.0 40.7 #mean(dataset$Ingresos) # validación para la columna &quot;ingresos&quot; Determinar el promedio para la tercera fila del dataset.num apply(dataset.num[3, ], 1, mean) # 1 = por filas ## 3 ## 2000017 7.3.1 apply vs for (for loop) Comparar apply() con un bucle (loop), utilizando for(), para calcular el promedio para cada fila #loop output &lt;- NULL # preparando un vector vacío nrow(dataset.num) # 10; comprobando por la cantidad de filas del data frame ## [1] 10 for(i in 1:nrow(dataset.num)){ output[i] &lt;- mean(as.numeric(dataset.num[i, ])) # aqui as.numeric es obligatorio } print(output) ## [1] 2500026.7 2500006.7 2000016.7 1500023.3 1000023.3 966681.7 666680.0 ## [8] 516670.0 333337.3 300003.3 Hacer lo mismo que lo anterior (for loop), pero utilizando apply() en lugar de for, lo que significa escribir menos código… Después, utilizar rowMeans(), que debe arrojar el mismo resultado en este caso apply(dataset.num, 1, mean) ## [1] 2500026.7 2500006.7 2000016.7 1500023.3 1000023.3 966681.7 666680.0 ## [8] 516670.0 333337.3 300003.3 rowMeans(dataset.num) # da igual ## [1] 2500026.7 2500006.7 2000016.7 1500023.3 1000023.3 966681.7 666680.0 ## [8] 516670.0 333337.3 300003.3 7.4 lapply Utilizar lapply(), lo que devuelve una lista. Es decir, apply y lapply se diferencian en el sentido, que lapply recibe y devuelve una lista. Vamos a crear entonces una lista de 3 data frames (dataset.A, dataset.B y dataset.C), para tener tres veces el dataset.num y Colocar estos tres data frames en una lista con el nombre dataset.list Mostar dataset.list en la pantalla, utilizando el comando print() Ahora, extraer de esta lista de cada data frame el primer elemento, utilizando lapply() dataset.A &lt;- dataset.num dataset.B &lt;- dataset.num dataset.C &lt;- dataset.num # class(dataset.A) # [1] &quot;data.frame&quot; dataset.list &lt;- list(dataset.A, dataset.B, dataset.C) print(dataset.list) ## [[1]] ## Ingresos Egresos Calificacion ## 1 4000000 3500000 80 ## 2 3500000 4000000 20 ## 3 3000000 3000000 50 ## 4 2500000 2000000 70 ## 5 2000000 1000000 70 ## 6 1500000 1400000 45 ## 7 1000000 1000000 40 ## 8 750000 800000 10 ## 9 500000 500000 12 ## 10 450000 450000 10 ## ## [[2]] ## Ingresos Egresos Calificacion ## 1 4000000 3500000 80 ## 2 3500000 4000000 20 ## 3 3000000 3000000 50 ## 4 2500000 2000000 70 ## 5 2000000 1000000 70 ## 6 1500000 1400000 45 ## 7 1000000 1000000 40 ## 8 750000 800000 10 ## 9 500000 500000 12 ## 10 450000 450000 10 ## ## [[3]] ## Ingresos Egresos Calificacion ## 1 4000000 3500000 80 ## 2 3500000 4000000 20 ## 3 3000000 3000000 50 ## 4 2500000 2000000 70 ## 5 2000000 1000000 70 ## 6 1500000 1400000 45 ## 7 1000000 1000000 40 ## 8 750000 800000 10 ## 9 500000 500000 12 ## 10 450000 450000 10 lapply(dataset.list, &quot;[&quot;, 1, 1) # una lista con 3 veces: 4000000 o 4e+06 ## [[1]] ## [1] 4000000 ## ## [[2]] ## [1] 4000000 ## ## [[3]] ## [1] 4000000 # donde [ se refiere a los segundos corchetes ya que R sabe que estamos iterando sobre los elementos de una lista. # lapply(dataset.list, &quot;[&quot;, 1, 1) es igual a: # dataset.list[[1]][1,1]; dataset.list[[2]][1,1]; dataset.list[[3]][1,1] Utilizando lapply() y la función rowMeans(), determinar el promedio de cada fila para los 3 elementos (data frames) en datset.list Luego, en lugar de utilizar rowMeans(), aplicar una función (es decir, function (x)) para acceder al primer elemento de cada uno de los 3 data frames de dataset.list lapply(dataset.list, rowMeans) ## [[1]] ## [1] 2500026.7 2500006.7 2000016.7 1500023.3 1000023.3 966681.7 666680.0 ## [8] 516670.0 333337.3 300003.3 ## ## [[2]] ## [1] 2500026.7 2500006.7 2000016.7 1500023.3 1000023.3 966681.7 666680.0 ## [8] 516670.0 333337.3 300003.3 ## ## [[3]] ## [1] 2500026.7 2500006.7 2000016.7 1500023.3 1000023.3 966681.7 666680.0 ## [8] 516670.0 333337.3 300003.3 lapply(dataset.list, function(x) x[1,1]) # 3 veces: 4e+06 ## [[1]] ## [1] 4000000 ## ## [[2]] ## [1] 4000000 ## ## [[3]] ## [1] 4000000 Calcular la diferencia (resta) entre los valores de la primera y la segunda fila para cada uno de los 3 data frames de dataset.list. Es decir, valores de la primera fila menos valores de la segunda fila lapply(dataset.list, function(z) z[1,] - z[2,]) # Ingresos y Egresos: 5e+05 Cali. 60 ## [[1]] ## Ingresos Egresos Calificacion ## 1 500000 -500000 60 ## ## [[2]] ## Ingresos Egresos Calificacion ## 1 500000 -500000 60 ## ## [[3]] ## Ingresos Egresos Calificacion ## 1 500000 -500000 60 7.5 sapply En comparación con el comando anterior de lapply(), el comando sapply() recibe una lista, pero devuelve un vector (o una matriz). En este sentido, sapply es una versión más simple de lapply, ya que se devuelve un vector (matriz) en lugar de una lista, lo que es más fácil a leer y entender. Ahora, extraer del data frame dataset.list de cada data frame el primer elemento, utilizando sapply() y observar la diferencia con respecto a lapply() sapply(dataset.list, &quot;[&quot;, 1, 1) # devuelve un vector con 3 elementos: [1] 4e+06 4e+06 4e+06 ## [1] 4000000 4000000 4000000 Ahora, extraer la segunda columna (“Egresos”“) de cada uno de los 3 data frames en la lista (dataset.list) Luego, extraer los valores de la segunda fila de cada uno de los 3 data frames en la lista (dataset.list) Después, extraer los valores de la segunda fila de cada uno de los 3 data frames en la lista (dataset.list), pero únicamente los valores de las segunda hasta la tercera columna sapply(dataset.list, &quot;[&quot;, 2) # 2 para la segunda columna... (como vector) ## $Egresos ## [1] 3500000 4000000 3000000 2000000 1000000 1400000 1000000 800000 ## [9] 500000 450000 ## ## $Egresos ## [1] 3500000 4000000 3000000 2000000 1000000 1400000 1000000 800000 ## [9] 500000 450000 ## ## $Egresos ## [1] 3500000 4000000 3000000 2000000 1000000 1400000 1000000 800000 ## [9] 500000 450000 sapply(dataset.list, &quot;[&quot;, 2, ) # segunda fila, todas las columnas (como matriz) ## [,1] [,2] [,3] ## Ingresos 3500000 3500000 3500000 ## Egresos 4000000 4000000 4000000 ## Calificacion 20 20 20 sapply(dataset.list, &quot;[&quot;, 2, 2:3) # segunda fila, columnas 2 hasta 3 (como matriz) ## [,1] [,2] [,3] ## Egresos 4000000 4000000 4000000 ## Calificacion 20 20 20 ¿Cuál es el valor mínimo en cada fila de los 3 data frames de dataset.list? sapply(dataset.list, apply, 1, min) ## [,1] [,2] [,3] ## [1,] 80 80 80 ## [2,] 20 20 20 ## [3,] 50 50 50 ## [4,] 70 70 70 ## [5,] 70 70 70 ## [6,] 45 45 45 ## [7,] 40 40 40 ## [8,] 10 10 10 ## [9,] 12 12 12 ## [10,] 10 10 10 which.min(dataset.list[[1]][1,]) # indica que los valores mínimos son en la tercera columna (&quot;Calificacion&quot;) ## Calificacion ## 3 7.6 Ejercicio 6 Utilizar el conjunto de datos “iris”, que se instaló con R: data(iris) Ver la siguiente descripción al respecto: https://es.wikipedia.org/wiki/Conjunto_de_datos_flor_iris Mostrar las primeras 5 filas de “iris” en la pantalla Utlizando la función apply, calcular el promedio de cada columna del dataset “iris”, que contiene números Realizar el mismo cálculo, utilizando la función lapply (en lugar de apply()) Con base en los resultados obtenidos, explicar la diferencia entre apply y lapply Ahora bien, realizar el mismo cálculo (promedio de las columnas), pero utilizando un ciclo (bucle), aplicando la función for() "],
["ajusteDistri.html", "Sección 8 Ajuste de datos a una distribución 8.1 Objetivo 8.2 Distribución normal 8.3 Distribución exponencial 8.4 Distribución uniforme 8.5 Distribución lognormal 8.6 Distribución Poisson (discreta) 8.7 Distribución binomial 8.8 Unir todo en un data frame 8.9 Realizar el ajuste 8.10 Ejercicio 7", " Sección 8 Ajuste de datos a una distribución 8.1 Objetivo Determinar, a cuál distribución se ajustan datos, utilizando el paquete rriskDistributions de R. Cargar el paquete / library rriskDistributions library(rriskDistributions) ## Warning: package &#39;rriskDistributions&#39; was built under R version 3.5.3 8.2 Distribución normal Generar 1000 datos a partir de una distribución normal (función rnorm()) con media = 0 y sd = 1 (sd = standard deviation) Iniciar con una semilla 123 y finalmente mostrar las primeras seis filas de los datos generados set.seed(123) datos.norm &lt;- rnorm(1000, mean = 0, sd = 1) head(datos.norm) ## [1] -0.56047565 -0.23017749 1.55870831 0.07050839 0.12928774 1.71506499 Graficar los datos, utilizando un histograma hist(datos.norm) 8.3 Distribución exponencial Generar 1000 datos a partir una distribución exponencial (función rexp()). Iniciar con una semilla 123 y finalmente mostrar las primeras seis filas de los datos generados set.seed(123) datos.exp &lt;- rexp(1000) # mostrar los primeros 6 datos head(datos.exp) ## [1] 0.84345726 0.57661027 1.32905487 0.03157736 0.05621098 0.31650122 Graficar los datos, utilizando un histograma hist(datos.exp) 8.4 Distribución uniforme Generar 1000 datos a partir una distribución uniforme (función runif(), con min = 0 y max = 50). Iniciar con una semilla 123 y finalmente mostrar las primeras seis filas de los datos generados set.seed(123) datos.unif &lt;- runif(1000, min = 0, max = 10) # mostrar los primeros 6 datos head(datos.unif) ## [1] 2.875775 7.883051 4.089769 8.830174 9.404673 0.455565 Graficar los datos en un histograma hist(datos.unif) 8.5 Distribución lognormal Generar 1000 datos a partir una distribución lognormal (función log(), con mean = 10, sd = 2.5): log(m^2 / sqrt(s^2 + m^2)) Utilizar la siguiente referencia como “ayuda”: https://msalganik.wordpress.com/2017/01/21/making-sense-of-the-rlnorm-function-in-r/ Iniciar con una semilla 123 y finalmente mostrar las primeras seis filas de los datos generados # source: https://msalganik.wordpress.com/2017/01/21/making-sense-of-the-rlnorm-function-in-r/ set.seed(123) m &lt;- 10 s &lt;- 2.5 location &lt;- log(m^2 / sqrt(s^2 + m^2)) shape &lt;- sqrt(log(1 + (s^2 / m^2))) print(paste(&quot;location:&quot;, location)) ## [1] &quot;location: 2.27227278208583&quot; print(paste(&quot;shape:&quot;, shape)) ## [1] &quot;shape: 0.24622067706924&quot; datos.lognorm &lt;- rlnorm(1000, location, shape) # mostrar los primeros 6 datos head(datos.lognorm) ## [1] 8.450893 9.166892 14.240058 9.871318 10.015222 14.798965 # prueba mean(datos.lognorm) ## [1] 10.03593 sd(datos.lognorm) ## [1] 2.504223 Graficar los datos, utilizando un histograma hist(datos.lognorm) 8.6 Distribución Poisson (discreta) Generar 1000 datos a partir una distribución Poisson, que es una distribución discreta (función rpois(), rate = 10, donde rate = cantidad de eventos en promedio por periodo). Iniciar con una semilla 123 y finalmente mostrar las primeras seis filas de los datos generados set.seed(123) rate = 10 # cantidad de eventos en promedio por periodo datos.poiss &lt;- rpois(1000, rate) # mostrar los primeros 6 datos head(datos.poiss) ## [1] 8 9 14 10 10 15 Graficar los datos en un histograma hist(datos.poiss) 8.7 Distribución binomial Generar 1000 datos a partir una distribución binomial (0 y 1), utilizando la función rbinom() con: n=1 # Bernoulli trials, p=.5 # probabilidad Iniciar con una semilla 123 y finalmente mostrar las primeras seis filas de los datos generados set.seed(123) n=1 # Bernoulli trials p=.5 # definir la probabilidad datos.binom &lt;- rbinom(1000,n,p) # cada vez diferente # mostrar los primeros 6 datos head(datos.binom) ## [1] 0 1 0 1 1 0 # tabla table(datos.binom) ## datos.binom ## 0 1 ## 507 493 Graficar los datos, utilizando un histograma hist(datos.binom) 8.8 Unir todo en un data frame Unir datos.norm, datos.exp, datos.unif, datos.lognorm y datos.poiss en un solo data frame con el nombre “datos” datos &lt;- data.frame(normal = datos.norm, expon = datos.exp, uniforme = datos.unif, logn = datos.lognorm, poiss = datos.poiss) 8.9 Realizar el ajuste Utilizar la función fit.cont() del paquete rriskDistributions para distribuciones continuas con el fin de realizar el ajuste. Nota: Este proceso es “pesado” y se demora un rato … Finalmente, se abre una nueva ventana, que informa sobre la distribución “más ajustada”. Esta figura no se muestra a continuación. Sin embargo, el resultado se presentará en una tabla library(rriskDistributions) # utilizar la función fit.cont() para distribuciones continuas res1 &lt;- fit.cont(datos$normal) ## ## Begin fitting distributions --------------------------------------- ## * fitting normal distribution ... OK ## * fitting Cauchy distribution ... OK ## * fitting logistic distribution ... OK ## * fitting beta distribution ... failed ## * fitting exponential distribution ... failed ## * fitting chi-square distribution ... failed ## * fitting uniform distribution ... OK ## * fitting gamma distribution ... failed ## * fitting lognormal distribution ... failed ## * fitting Weibull distribution ... failed ## * fitting F-distribution ... failed ## * fitting Student&#39;s t-distribution ... OK ## * fitting Gompertz distribution ... failed ## * fitting triangular distribution ... failed ## End fitting distributions ----------------------------------------- ## logL AIC BIC Chisq(value) Chisq(p) AD(value) ## Normal -1410.1 2824.2 2834.01 17.91 0.85 0.30 ## Cauchy -1583.96 3171.91 3181.73 216.84 0.00 11.99 ## Logistic -1419.22 2842.43 2852.25 19.91 0.75 0.58 ## Uniform NULL NULL NULL Inf 0.00 Inf ## Student -1410.68 2823.37 2828.28 17.88 0.88 0.40 ## H(AD) KS(value) H(KS) ## Normal not rejected 0.02 not rejected ## Cauchy rejected 0.08 rejected ## Logistic not rejected 0.02 not rejected ## Uniform NULL 0.07 rejected ## Student NULL 0.02 not rejected ## ## Chosen continuous distribution is: Normal (norm) ## Fitted parameters are: ## mean sd ## 0.01612787 0.99119900 #res2 &lt;- fit.cont(datos$expon) # quitar el # #res3 &lt;- fit.cont(datos$uniforme) # quitar el # #res4 &lt;- fit.cont(datos$logn) # quitar el # #res5 &lt;- fit.cont(datos$poiss) # quitar el # 8.10 Ejercicio 7 Generar en R 15 números aleatorios, con base en una distribución uniforme, entre 1 (mínimum) y 50 (máximum) y asignar el resultado a una variable “vector.aleatorio1” Luego, generar en R otros 15 números aleatorios, con base en una distribución normal, con una media de “0” y una desviación estándar de “1”, y asignar el resultado a una variable “vector.aleatorio2” Combinar los valores de los 2 vectores en un único vector “vector.aleatorio3” en R / RStudio Realizar el “ajuste a la distribución”, utilizando el paquete “rriskDistributions” "],
["regLineal.html", "Sección 9 Un modelo lineal “sencillo” (regresión lineal) 9.1 Objetivo 9.2 Cargar datos sobre carros 9.3 Crear el modelo lineal (regresión lineal) 9.4 Realizar una predicción", " Sección 9 Un modelo lineal “sencillo” (regresión lineal) 9.1 Objetivo Construir un modelo lineal para realizar una predicción. Aquí esta predicción se refiere a un puntaje (score) que refleja la eficiencia de un carro con respecto al consumo de gasolina. 9.2 Cargar datos sobre carros Utilizar el dataset mtcars, que viene con la instalación de R: data(“mtcars”) Primero, analizar estos datos con la función View() Asignar estos datos a un data frame “df” y Mostrar las primeras seis filas de df y adicionalmente mostrar la clase de “df” data(&quot;mtcars&quot;) View(mtcars) df &lt;- mtcars head(df) ## mpg cyl disp hp drat wt qsec vs am gear carb ## Mazda RX4 21.0 6 160 110 3.90 2.620 16.46 0 1 4 4 ## Mazda RX4 Wag 21.0 6 160 110 3.90 2.875 17.02 0 1 4 4 ## Datsun 710 22.8 4 108 93 3.85 2.320 18.61 1 1 4 1 ## Hornet 4 Drive 21.4 6 258 110 3.08 3.215 19.44 1 0 3 1 ## Hornet Sportabout 18.7 8 360 175 3.15 3.440 17.02 0 0 3 2 ## Valiant 18.1 6 225 105 2.76 3.460 20.22 1 0 3 1 class(df) # data.frame ## [1] &quot;data.frame&quot; Colocar los nombres de los modelos de los carros en una primera columna (columna adicional) del data frame “df”. Esta columna debe tener el nombre (título) “modelos” Esto se puede lograr combinando la función cbind(), que une columnas, y rownames(), que devuelve los nombre de las filas de un data frame Luego, analizar las primeras seis filas de “df” df &lt;- cbind(modelos = rownames(df), df) head(df) ## modelos mpg cyl disp hp drat wt qsec vs ## Mazda RX4 Mazda RX4 21.0 6 160 110 3.90 2.620 16.46 0 ## Mazda RX4 Wag Mazda RX4 Wag 21.0 6 160 110 3.90 2.875 17.02 0 ## Datsun 710 Datsun 710 22.8 4 108 93 3.85 2.320 18.61 1 ## Hornet 4 Drive Hornet 4 Drive 21.4 6 258 110 3.08 3.215 19.44 1 ## Hornet Sportabout Hornet Sportabout 18.7 8 360 175 3.15 3.440 17.02 0 ## Valiant Valiant 18.1 6 225 105 2.76 3.460 20.22 1 ## am gear carb ## Mazda RX4 1 4 4 ## Mazda RX4 Wag 1 4 4 ## Datsun 710 1 4 1 ## Hornet 4 Drive 0 3 1 ## Hornet Sportabout 0 3 2 ## Valiant 0 3 1 9.3 Crear el modelo lineal (regresión lineal) Generar un modelo de una regresión lineal, utilizando la función lm(), y asignar el resultado del modelo a una variable (objeto) “lin.mod” Generar el modelo con las siguientes variables de entrada: cyl + wt + hp Investigar primero sobre esta función “lm” (con F1) antes de utilizarla. Finalmente, mostrar el contenido de lin.mod (del modelo construido) en la pantalla, utilizando la función print() lin.mod &lt;- lm(mpg ~ cyl + wt + hp, data = df) print(lin.mod) ## ## Call: ## lm(formula = mpg ~ cyl + wt + hp, data = df) ## ## Coefficients: ## (Intercept) cyl wt hp ## 38.75179 -0.94162 -3.16697 -0.01804 9.4 Realizar una predicción Realizar una predicción, utilizando el modelo generado (“lin.mod”) y la función predict() y asignar el resultado a una variable “mpgScore” como columna adicional del data frame “df”. Donde mpg = miles per galón. Esta función predict () requiere dos parámetros: Un modelo (aquí: lin.mod) y datos (aquí: “df”“) Nota: El resultado de la predicción se refiere a un puntaje (score) que refleja la cantidad de millas que corre un carro con un galón de gasolina. Es decir, el score se refiere a la eficiencia de un carro con respecto al consumo de gasolina. Luego, analizar las primeras seis filas del data frame df, y en particular los valores de la nueva columna “mpgScore” df$mpgScore &lt;- predict(lin.mod, df) head(df) ## modelos mpg cyl disp hp drat wt qsec vs ## Mazda RX4 Mazda RX4 21.0 6 160 110 3.90 2.620 16.46 0 ## Mazda RX4 Wag Mazda RX4 Wag 21.0 6 160 110 3.90 2.875 17.02 0 ## Datsun 710 Datsun 710 22.8 4 108 93 3.85 2.320 18.61 1 ## Hornet 4 Drive Hornet 4 Drive 21.4 6 258 110 3.08 3.215 19.44 1 ## Hornet Sportabout Hornet Sportabout 18.7 8 360 175 3.15 3.440 17.02 0 ## Valiant Valiant 18.1 6 225 105 2.76 3.460 20.22 1 ## am gear carb mpgScore ## Mazda RX4 1 4 4 22.82043 ## Mazda RX4 Wag 1 4 4 22.01285 ## Datsun 710 1 4 1 25.96040 ## Hornet 4 Drive 0 3 1 20.93608 ## Hornet Sportabout 0 3 2 17.16780 ## Valiant 0 3 1 20.25036 "],
["electre1.html", "Sección 10 MCDA: Outranking - sobre calificación 10.1 Objetivo y contextualización 10.2 Datos 10.3 Leer los datos desde un archivo de Excel 10.4 Analizar el paquete Outranking Tools y la función electre_1() 10.5 Transformar los datos al formato requerido", " Sección 10 MCDA: Outranking - sobre calificación 10.1 Objetivo y contextualización Uno de los riesgos que enfrentan las instituciones financieras y demás organizaciones tiene que ver con las personas. Una parte de este riesgo se refiere al proceso de la contratación del personal y como las organizaciones toman esas decisiones de la selección del personal. La selección de personal, en este caso para el área de la gestión de riesgos, requiere de la toma de decisiones, en la cual intervienen múltiples criterios. En el siguiente caso hipotético sencillo tenemos tres candidatos (alternativas) para el puesto del CRO (chief risk officer) en una entidad financiera, con sus respectivas características, ya evaluadas por expertos de la empresa. La siguiente tabla muestra, en las columnas, los tres candidatos para el cargo / puesto. En las filas se muestran los criterios de evaluación para los candidatos (personal). Para cada candidato se muestran los datos (valores numéricos) correspondientes que lo caracterizan. Donde: 1 = “no tan bueno”; 10 = “mejor calificación posible”. En la columna “MiniMax” se indica para cada uno de los criterios, si este se debe minimizar o maximizar. En el presente ejemplo, los valores de todos los criterios se deben maximizar. La columna “Peso” indica el peso (la ponderación) para cada criterio. Para seleccionar la mejor alternativa, basado en estos criterios, la institución financiera pide su ayuda. La institución quiere que usted aplique el método ELECTRE_1() para evaluar las alternativas (candidatos). Usted debe aplicar ELECTRE basado en el paquete “OutrankingTools” de R, que implementa los algoritmos de sobre clasificación (outranking), que se pueden aplicar a estos problemas de MCDA (multiple criteria decision analysis). ¿Cuál candidato se debe seleccionar? Es decir, ¿cuál candidato sobre califica (outranks) a otro? 10.2 Datos Primero, generar manualmente un archivo en MS-Excel (xlsx) con los siguientes datos: Alternativa1 Alternativa2 Alternativa3 MinMax Peso Criterio Daniela Jaime Alejandro Referencias 5 8 5 max 0.10 Experiencia 2 10 5 max 0.35 Educacion 8 6 8 max 0.35 Liderazgo 1 6 6 max 0.20 Determinar su directorio de trabajo para R, utilizando la función getwd() Pegar los datos, que se muestran en la tabla anterior, a la primera hoja del Excel Guardar los datos como archivo de Excel (xlsx), bajo el nombre “electre_datos.xlsx”, en su directorio de trabajo de R 10.3 Leer los datos desde un archivo de Excel Para leer los datos desde Excel, utilizar el paquete readxl de R library(readxl) mis.datos &lt;- read_excel(&#39;electre_datos.xlsx&#39;) # del working directory ## New names: ## * `` -&gt; ...1 View(mis.datos) 10.4 Analizar el paquete Outranking Tools y la función electre_1() Analizar el paquete Outranking Tools y la función Electre_1() mediante el comando “?Electre_1” (después de haber ejecutado el comando library(OutrankingTools)) library(OutrankingTools) ## Warning: package &#39;OutrankingTools&#39; was built under R version 3.5.3 ## Loading required package: igraph ## Warning: package &#39;igraph&#39; was built under R version 3.5.3 ## ## Attaching package: &#39;igraph&#39; ## The following object is masked from &#39;package:DescTools&#39;: ## ## %c% ## The following objects are masked from &#39;package:lubridate&#39;: ## ## %--%, union ## The following objects are masked from &#39;package:dplyr&#39;: ## ## as_data_frame, groups, union ## The following objects are masked from &#39;package:purrr&#39;: ## ## compose, simplify ## The following object is masked from &#39;package:tidyr&#39;: ## ## crossing ## The following object is masked from &#39;package:tibble&#39;: ## ## as_data_frame ## The following objects are masked from &#39;package:stats&#39;: ## ## decompose, spectrum ## The following object is masked from &#39;package:base&#39;: ## ## union ?Electre_1 10.5 Transformar los datos al formato requerido Vamos a transformar a continuación algunos datos al formato requerido por la función electre_1(). Asignar los valores de los datos, leídos desde Excel, para los siguientes dos parámetros: -alternativas y -criterios alternatives &lt;- as.character(mis.datos[1,c(2:4)]) class(alternatives) ## [1] &quot;character&quot; print(alternatives) ## [1] &quot;Daniela&quot; &quot;Jaime&quot; &quot;Alejandro&quot; criteria &lt;- as.character(mis.datos[-1,1]) class(criteria) ## [1] &quot;character&quot; print(criteria) ## [1] &quot;c(\\&quot;Referencias\\&quot;, \\&quot;Experiencia\\&quot;, \\&quot;Educacion\\&quot;, \\&quot;Liderazgo\\&quot;)&quot; Eliminar la primera fila, ya que esta no contiene números / valores relevantes mis.datos1 &lt;- mis.datos[-1, ] print(mis.datos1) ## # A tibble: 4 x 6 ## ...1 Alternativa1 Alternativa2 Alternativa3 MinMax Peso ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 Referencias 5 8 5 max 0.1 ## 2 Experiencia 2 10 5 max 0.35 ## 3 Educacion 8 6 8 max 0.35 ## 4 Liderazgo 1 6 6 max 0.2 Crear la matriz de desempeño (performance matrix) performanceMatrix &lt;- mis.datos1[, c(2:4)] print(performanceMatrix) ## # A tibble: 4 x 3 ## Alternativa1 Alternativa2 Alternativa3 ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 5 8 5 ## 2 2 10 5 ## 3 8 6 8 ## 4 1 6 6 Convertir los números a tipo de dato “numeric” performanceMatrix$Alternativa1 &lt;- as.numeric(performanceMatrix$Alternativa1) performanceMatrix$Alternativa2 &lt;- as.numeric(performanceMatrix$Alternativa2) performanceMatrix$Alternativa3 &lt;- as.numeric(performanceMatrix$Alternativa3) print(performanceMatrix) ## # A tibble: 4 x 3 ## Alternativa1 Alternativa2 Alternativa3 ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 5 8 5 ## 2 2 10 5 ## 3 8 6 8 ## 4 1 6 6 Transponer esta matriz performanceMatrix &lt;- t(performanceMatrix) print(performanceMatrix) ## [,1] [,2] [,3] [,4] ## Alternativa1 5 2 8 1 ## Alternativa2 8 10 6 6 ## Alternativa3 5 5 8 6 Asignar al parámetro “criteriaweights” los datos correspondientes, leídos del archivo de Excel criteriaWeights &lt;- as.numeric(mis.datos1$Peso) print(criteriaWeights) ## [1] 0.10 0.35 0.35 0.20 Asignar los datos correspondientes al parámetro “minimaxcriteria”, leídos de del archivo de Excel minmaxcriteria &lt;- mis.datos1$MinMax print(minmaxcriteria) ## [1] &quot;max&quot; &quot;max&quot; &quot;max&quot; &quot;max&quot; Corregir el tipo de dato de la variable “criteria” para que realmente haya un vector de criteria… Esto se puede lograr mediante: as.character(unlist(mis.datos[-1,1])) print(criteria) # criteria como está actualmente ## [1] &quot;c(\\&quot;Referencias\\&quot;, \\&quot;Experiencia\\&quot;, \\&quot;Educacion\\&quot;, \\&quot;Liderazgo\\&quot;)&quot; print(mis.datos) ## # A tibble: 5 x 6 ## ...1 Alternativa1 Alternativa2 Alternativa3 MinMax Peso ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 Criterio Daniela Jaime Alejandro &lt;NA&gt; NA ## 2 Referencias 5 8 5 max 0.1 ## 3 Experiencia 2 10 5 max 0.35 ## 4 Educacion 8 6 8 max 0.35 ## 5 Liderazgo 1 6 6 max 0.2 #corrección: #criteria &lt;- mis.datos1$..1 #usar notación &quot;...$...&quot; con mis.datos1 o unlist con mis.datos: criteria &lt;- as.character(unlist(mis.datos[-1,1])) # mejor para no utilizar $..1 print(criteria) ## [1] &quot;Referencias&quot; &quot;Experiencia&quot; &quot;Educacion&quot; &quot;Liderazgo&quot; Ejecutar la función Electre_1() y asignar el resultado a una variable “overall” Utilizar, para los últimos dos parámetros que requiere Electre_1, lo siguiente: concordance_threshold = 0.6, discordance_threshold = 0.4 Observar el resultado, en particular la gráfica del “outranking” de los candidatos overall &lt;-Electre_1(performanceMatrix, alternatives, criteria, criteriaWeights, minmaxcriteria, concordance_threshold = 0.6, discordance_threshold = 0.4) Utilizando la variable “overall”, imprimir a la pantalla la “Performance Matrix”. Es decir, el contenido de la matriz de desempeño #performanceMatrix overall$`Performance Matrix` # o print(overall[[1]]) ## Referencias Experiencia Educacion Liderazgo ## Daniela 5 2 8 1 ## Jaime 8 10 6 6 ## Alejandro 5 5 8 6 #ConcordanceMatrix overall$`Concordance Matrix` ## Daniela Jaime Alejandro ## Daniela 1.00 0.35 0.45 ## Jaime 0.65 1.00 0.65 ## Alejandro 1.00 0.55 1.00 #DiscordanceMatrix overall$`Discordance Matrix` ## Daniela Jaime Alejandro ## Daniela 0.00 1.000 0.625 ## Jaime 0.25 0.000 0.250 ## Alejandro 0.00 0.625 0.000 "],
["ahp.html", "Sección 11 Modelo AHP (Analytical Hierarchy Process) 11.1 Objetivo 11.2 Cargar los paquetes ahp y data.tree 11.3 Mostrar los archivos (ejemplos), que vienen con este paquete ahp y cargar uno de estos 11.4 Aplicar ahp, utilizando la función calculate() 11.5 Mostrar el problema de decisión gráficamente (como árbol) 11.6 Analizar los resultados de ahp", " Sección 11 Modelo AHP (Analytical Hierarchy Process) 11.1 Objetivo El objetivo aquí es parecido al tema anterior (electre) y consiste en tomar una decisión multicriterio (MCDA - multiple criteria decision analysis). De acuerdo con lo anterior, esta sección es para el “problema” de seleccionar entre Tom, Dick, &amp; Harry como líder (problema de selección de personal): https://en.wikipedia.org/wiki/Analytic_hierarchy_process_%E2%80%93_leader_example El ejemplo concreto aquí es de Nicole Radziwill: http://qualityandinnovation.com/2016/01/04/analytic-hierarchy-process-ahp-with-the-ahp-package/ 11.2 Cargar los paquetes ahp y data.tree AHP significa ‘analytical hierarchy process’ y es para la toma de decisiones “multicriterio” (MCDA, multiple criteria decision analysis). Cuando se carga el paquete ahp (library(ahp)), se carga automáticamente también el paquete data.tree (y otros, como p.ej. el paquete DiagrammeR, que a su vez requiere del paquete influenceR…) library(ahp) ## Warning: package &#39;ahp&#39; was built under R version 3.5.3 Consultar el manual para el paquete ahp ?ahp 11.3 Mostrar los archivos (ejemplos), que vienen con este paquete ahp y cargar uno de estos list.files(system.file(“extdata”, package=“ahp”)) list.files(system.file(&quot;extdata&quot;, package=&quot;ahp&quot;)) ## [1] &quot;car.ahp&quot; &quot;tom_dick_harry.ahp&quot; &quot;vacation.ahp&quot; Aquí, seleccionar el archivo Tom, Dick and Harry y asignar su contenido a una variable ahpFile: ahpFile &lt;- system.file(“extdata”, “tom_dick_harry.ahp”, package=“ahp”) Este archivo tiene formulado el problema, como se muestra a continuación ahpFile &lt;- system.file(&quot;extdata&quot;, &quot;tom_dick_harry.ahp&quot;, package=&quot;ahp&quot;) Mostrar el contenido de este archivo de texto (formato Yaml): cat(readChar(ahpFile, file.info(ahpFile)$size)) cat(readChar(ahpFile, file.info(ahpFile)$size)) ## Version: 2.0 ## ######################### ## # Alternatives Section ## # THIS IS FOR The Tom, Dick, &amp; Harry problem at ## # https://en.wikipedia.org/wiki/Analytic_hierarchy_process_%E2%80%93_leader_example ## # ## # This example is provided by Nicole Radziwill, see ## # http://qualityandinnovation.com/2016/01/04/analytic-hierarchy-process-ahp-with-the-ahp-package/ ## # ## Alternatives: &amp;alternatives ## # 1= not well; 10 = best possible ## # Your assessment based on the paragraph descriptions may be different. ## Tom: ## age: 50 ## experience: 7 ## education: 4 ## leadership: 10 ## Dick: ## age: 60 ## experience: 10 ## education: 6 ## leadership: 6 ## Harry: ## age: 30 ## experience: 5 ## education: 8 ## leadership: 6 ## # ## # End of Alternatives Section ## ##################################### ## # Goal Section ## # ## Goal: ## # A Goal HAS preferences (within-level comparison) and HAS Children (items in level) ## name: Choose the Most Suitable Leader ## preferences: ## pairwise: ## # preferences are defined pairwise ## # 1 means: A is equal to B ## # 9 means: A is highly preferrable to B ## # 1/9 means: B is highly preferrable to A ## - [Experience, Education, 4] ## - [Experience, Charisma, 3] ## - [Experience, Age, 7] ## - [Education, Charisma, 1/3] ## - [Education, Age, 3] ## - [Age, Charisma, 1/5] ## children: ## Experience: ## preferences: ## pairwiseFunction: &gt; ## ExperiencePreference &lt;- function(a1, a2) { ## if (a1$experience &lt; a2$experience) return (1/ExperiencePreference(a2, a1)) ## ratio &lt;- a1$experience / a2$experience ## if (ratio &lt; 1.05) return (1) ## if (ratio &lt; 1.2) return (2) ## if (ratio &lt; 1.5) return (3) ## if (ratio &lt; 1.8) return (4) ## if (ratio &lt; 2.1) return (5) ## return (6) ## } ## children: *alternatives ## Education: ## preferences: ## scoreFunction: function(a) a$education ## children: *alternatives ## Charisma: ## preferences: ## pairwise: ## - [Tom, Dick, 5] ## - [Tom, Harry, 9] ## - [Dick, Harry, 4] ## children: *alternatives ## Age: ## preferences: ## pairwise: ## - [Tom, Dick, 1/3] ## - [Tom, Harry, 5] ## - [Dick, Harry, 9] ## children: *alternatives ## # ## # End of Goal Section ## ##################################### Cargar el archivo: tomdickharryAhp &lt;- Load(ahpFile) Observar la clase del objeto tomdickharryAhp &lt;- Load(ahpFile) #class(tomdickharryAhp) Mostrar los criterios de decisión y las alternativas en la pantalla, utilizando la función print(): print(tomdickharryAhp) print(tomdickharryAhp) ## levelName ## 1 Choose the Most Suitable Leader ## 2 ¦--Experience ## 3 ¦ ¦--Tom ## 4 ¦ ¦--Dick ## 5 ¦ °--Harry ## 6 ¦--Education ## 7 ¦ ¦--Tom ## 8 ¦ ¦--Dick ## 9 ¦ °--Harry ## 10 ¦--Charisma ## 11 ¦ ¦--Tom ## 12 ¦ ¦--Dick ## 13 ¦ °--Harry ## 14 °--Age ## 15 ¦--Tom ## 16 ¦--Dick ## 17 °--Harry 11.4 Aplicar ahp, utilizando la función calculate() ?Calculate Calculate(tomdickharryAhp) 11.5 Mostrar el problema de decisión gráficamente (como árbol) Visualizar el problema: Visualize(tomdickharryAhp) Visualize(tomdickharryAhp) 11.6 Analizar los resultados de ahp Mostrar los resultados en una tabla, utilizando la función Analyze() y AnalyzeTable() Analyze(tomdickharryAhp) ## Weight Dick Tom Harry Inconsistency ## 1 Choose the Most Suitable Leader 100.0% 48.1% 38.5% 13.4% 4.5% ## 2 ¦--Experience 54.8% 34.9% 14.1% 5.7% 3.7% ## 3 ¦--Charisma 27.0% 5.2% 20.1% 1.7% 6.8% ## 4 ¦--Education 12.7% 4.2% 2.8% 5.6% NA ## 5 °--Age 5.6% 3.8% 1.5% 0.4% 2.8% # una forma para mostrar la tabla de una forma más bonita # AnalyzeTable(tomdickharryAhp) Conclusión: Se debe seleccionar Dick, ya que es la persona que obtuvo el mayor “puntaje” (48,1%), tomando en cuenta todos los criterios de selección. 11.6.1 Nota: solución alternativa Una forma alternativa para cargar los datos consiste en utilizar un archivo yaml (archivo de texto), donde se formula el problema, en términos de las matrices disponibles en: https://en.wikipedia.org/wiki/Analytic_hierarchy_process_%E2%80%93_leader_example getwd() Cambiar al directorio de trabajo, donde se encuentra el archivo de texto con el problema formulado, incluyendo dos secciones con sus datos principalmente: Goal Section setwd(‘C:\\Users\\xyz\\Documents\\directorioR’) ahpFile2 &lt;- Load(‘tom_dick_harry.txt’) Calculate(ahpFile2) Mostrar el problema de decisión gráficamente (como árbol) Visualize(ahpFile2) Mostrar los resultados en una tabla Analyze(ahpFile2) "],
["fuzzy.html", "Sección 12 Modelo fuzzy (borroso) 12.1 Objetivo y contextualización 12.2 Definir el universo (universe) 12.3 Definir las variables 12.4 Fuzzy rules - reglas borrosas 12.5 Definir el modelo borroso 12.6 Dos ejemplos fuzzy 12.7 Finalmente se debe “resetear” el universo", " Sección 12 Modelo fuzzy (borroso) 12.1 Objetivo y contextualización El objetivo consiste en presentar una solución para un problema “borroso”, donde “borroso” significa que los valores de las variables no representan un número exacto (“crisp value”), sino un rango, en términos de un ‘conjunto borroso’ (fuzzy set). Este ejemplo se adaptó de: Juan De Dios Santos: https://github.com/juandes/FuzzyLogic-R y https://github.com/juandes/FuzzyLogic-R/blob/master/fuzzy_script.R El problema a solucionar se refiere a la selección de personal basado en la aptitud de las personas, que a su vez depende de tres variables (de entrada). Todas las variables son cualitativas y borrosas (“fuzzy”) como se muestra a continuación. Los valores (tres) de cada variable de entrada determinan, siguiendo las reglas que se muestran a continuación, el valor de la variable de salida (aptitud). Se utiliza el paquete de R “sets”: library(sets) Más detalles para el paquete sets se pueden consultar aquí: https://cran.r-project.org/web/packages/sets/index.html library(sets) ## Warning: package &#39;sets&#39; was built under R version 3.5.3 ## ## Attaching package: &#39;sets&#39; ## The following object is masked from &#39;package:igraph&#39;: ## ## %&gt;% ## The following object is masked from &#39;package:tidyquant&#39;: ## ## %&gt;% ## The following objects are masked from &#39;package:lubridate&#39;: ## ## as.interval, interval, is.interval ## The following object is masked from &#39;package:rvest&#39;: ## ## %&gt;% ## The following object is masked from &#39;package:forcats&#39;: ## ## %&gt;% ## The following object is masked from &#39;package:stringr&#39;: ## ## %&gt;% ## The following object is masked from &#39;package:dplyr&#39;: ## ## %&gt;% ## The following object is masked from &#39;package:purrr&#39;: ## ## %&gt;% ## The following object is masked from &#39;package:tidyr&#39;: ## ## %&gt;% 12.2 Definir el universo (universe) Definir el universo, utilizando las funciones sets_options() y seq(), donde esta última genera una secuencia (sequence) de 1000 números entre 1 y 100 con un paso entre estos de 0.1 sets_options(“universe”, seq(1, 100, 0.1)) sets_options(&quot;universe&quot;, seq(1, 100, 0.1)) 12.3 Definir las variables Aquí, se definene tres variables lingüísticas de entrada y una variable de salida (aquí aptitud). Definir las siguientes tres variables de entrada, de forma borrosa (“fuzzy”): -experiencia -educación y -carisma La variable de salida, que se debe definir también de forma borrosa, es la “aptitud”. De acuerdo con lo anterior, “borroso” significa aquí, que los valores de las variables no representan un número exacto (“crisp value”), sino un rango que define una variable cualitativa (“lingüística”) por un ‘conjunto borroso’ (fuzzy set). Por ejemplo, en el siguiente caso la variable (de entrada) “experiencia”, que caracteriza una persona (empleado potencial), está definida por un rango que va desde 30 hasta 90, donde 30 significa “poca” experiencia, el valor 90 significa “mucha” experiencia y un tercer valor 70 en este caso, significa experiencia “aceptable”. Para las demás variables, incluyendo la variable de salida, aplica esta misma “lógica”, definiendolas como variables borrosas de la siguiente forma en R: variables &lt;- set( experiencia = fuzzy_partition(varnames = c(poca = 30, aceptable = 70, mucha = 90), sd = 5.0), educacion = fuzzy_partition(varnames = c(baja = 30, media = 60, alta = 80), sd = 3.0), carisma = fuzzy_partition(varnames = c(poco = 30, medio = 60, alto = 90), sd = 7.5), aptitud = fuzzy_partition(varnames = c(poca = 40, ok = 65, perfecta = 80), FUN = fuzzy_cone, radius = 10) ) variables &lt;- set( experiencia = fuzzy_partition(varnames = c(poca = 30, aceptable = 70, mucha = 90), sd = 5.0), educacion = fuzzy_partition(varnames = c(baja = 30, media = 60, alta = 80), sd = 3.0), carisma = fuzzy_partition(varnames = c(poco = 30, medio = 60, alto = 90), sd = 7.5), aptitud = fuzzy_partition(varnames = c(poca = 40, ok = 65, perfecta = 80), FUN = fuzzy_cone, radius = 10) ) 12.4 Fuzzy rules - reglas borrosas Además, se tienen que definir reglas borrosas (fuzzy rules) de tipo “si-entonces”&quot; (“if-then”): Por ejemplo, la siguiente regla: Si la experiencia es “aceptable” y la educación es “baja” y el carisma es “poco”, entonces la aptitud es “perfecta”. …y así se definen sucesivamente un conjunto de reglas borrosas: rules &lt;- set( fuzzy_rule(experiencia %is% aceptable &amp;&amp; educacion %is% baja &amp;&amp; carisma %is% poco, aptitud %is% perfecta), fuzzy_rule(experiencia %is% mucha &amp;&amp; educacion %is% alta &amp;&amp; carisma %is% alto, aptitud %is% poca), fuzzy_rule(experiencia %is% poca, aptitud %is% poca), fuzzy_rule(experiencia %is% aceptable || educacion %is% media || carisma %is% medio, aptitud %is% ok), fuzzy_rule(experiencia %is% mucha &amp;&amp; carisma %is% medio, aptitud %is% ok), fuzzy_rule(experiencia %is% mucha &amp;&amp; educacion %is% baja &amp;&amp; carisma %is% medio, aptitud %is% ok) ) rules &lt;- set( fuzzy_rule(experiencia %is% aceptable &amp;&amp; educacion %is% baja &amp;&amp; carisma %is% poco, aptitud %is% perfecta), fuzzy_rule(experiencia %is% mucha &amp;&amp; educacion %is% alta &amp;&amp; carisma %is% alto, aptitud %is% poca), fuzzy_rule(experiencia %is% poca, aptitud %is% poca), fuzzy_rule(experiencia %is% aceptable || educacion %is% media || carisma %is% medio, aptitud %is% ok), fuzzy_rule(experiencia %is% mucha &amp;&amp; carisma %is% medio, aptitud %is% ok), fuzzy_rule(experiencia %is% mucha &amp;&amp; educacion %is% baja &amp;&amp; carisma %is% medio, aptitud %is% ok) ) 12.5 Definir el modelo borroso Como tercer paso se define un modelo borroso de la siguiente forma, utilizando las variables “variables” y “rules”, previamente definidas: model &lt;- fuzzy_system(variables, rules) Esto modelo, con sus conjuntos borrosos, se puede mostrar en la pantalla: plot(model) Observe los diagramas generados para cada una de las variables. En particular, para la variable de entrada “experiencia” se sobrelapan las curvas, que representan los conjuntos borrosos, en el valor “80”. Este sobrelapamiento caracteriza la borrosidad de la variable. ?fuzzy_system model &lt;- fuzzy_system(variables, rules) print(model) # imprime las variables y las reglas a la pantalla ## A fuzzy system consisting of 4 variables and 6 rules. ## ## Variables: ## ## aptitud(poca, ok, perfecta) ## educacion(baja, media, alta) ## experiencia(poca, aceptable, mucha) ## carisma(poco, medio, alto) ## ## Rules: ## ## experiencia %is% mucha &amp;&amp; carisma %is% medio =&gt; aptitud %is% ok ## experiencia %is% mucha &amp;&amp; educacion %is% alta &amp;&amp; carisma %is% =&gt; aptitud %is% poca ## alto =&gt; aptitud %is% poca ## experiencia %is% mucha &amp;&amp; educacion %is% baja &amp;&amp; carisma %is% =&gt; aptitud %is% ok ## medio =&gt; aptitud %is% ok ## experiencia %is% aceptable &amp;&amp; educacion %is% baja &amp;&amp; carisma %is% =&gt; aptitud %is% perfecta ## poco =&gt; aptitud %is% perfecta ## experiencia %is% aceptable || educacion %is% media || carisma %is% =&gt; aptitud %is% ok ## medio =&gt; aptitud %is% ok ## experiencia %is% poca =&gt; aptitud %is% poca plot(model) # imprime los conjuntos borrosos Nota: En la figura de la “experiencia” la calificación es “aceptable” (70) y “mucha” (90). Si el nivel (de experiencia) es 80, entonces este nivel de experiencia es aproximadamente 0.15 ‘aceptable’, 0.15 ‘mucha’ y 0.0 ‘poca’. 12.6 Dos ejemplos fuzzy example.1 &lt;- fuzzy_inference(model, list(experiencia = 75, educacion = 0, carisma = 70)) plot(example.1) example.1 &lt;- fuzzy_inference(model, list(experiencia = 75, educacion = 0, carisma = 70)) plot(example.1) Ahora, “defuzzificamos” el ejemplo para transformar los parámetros en un número: gset_defuzzify(example.1, “centroid”) # 65 gset_defuzzify(example.1, &quot;centroid&quot;) # 65 ## [1] 65 Según el sistema, la aptitud es 0.65 “ok” (ver el diagrama de la aptitud). ¿Qué pasa, si el nivel de experiencia baja a 30 (75 en el ejemplo anterior)? example.2 &lt;- fuzzy_inference(model, list(experiencia = 30, educacion = 0, carisma = 70)) plot(example.2) example.2 &lt;- fuzzy_inference(model, list(experiencia = 30, educacion = 0, carisma = 70)) plot(example.2) …y se realiza la ‘defuzzificación’: gset_defuzzify(example.2, “largestofmax”) gset_defuzzify(example.2, &quot;largestofmax&quot;) ## [1] 40 Respuesta: Si la experiencia baja a 30, el modelo disminuye la aptitud de “ok” a 0.4 (40), ver la figura, lo que significa, que la aptitud es 1.0 “poca” (es decir, la aptitud cambió de “ok” a “poca”). 12.7 Finalmente se debe “resetear” el universo Reseteando el universo (Reset universe), que se generó al principio, se hace en R de la siguiente forma: sets_options(“universe”, NULL) sets_options(&quot;universe&quot;, NULL) "],
["muestreo.html", "Sección 13 Muestreo - sampling 13.1 Objetivo 13.2 Muestreo aleatorio simple - Simple Random Sampling 13.3 Proceso de muestreo para realizar una encuesta 13.4 Muestreo para un problema de datos masivos (big data) 13.5 Muestreo estratificado - Stratified sampling 13.6 Trabajar con potencia (power analysis) 13.7 Ejercicio 8", " Sección 13 Muestreo - sampling 13.1 Objetivo El objetivo consiste en presentar diferentes formas de construir una muestra, que representa una población, p.ej. para diseñar un “experimento”. 13.2 Muestreo aleatorio simple - Simple Random Sampling Fuente: https://dzone.com/articles/data-sampling-methods-in-r El contexto. Planeamos diseñar un experimento para una encuesta donde queremos saber, si a las personas les gustan nuestros productos. Las dos respuestas permitidas son “Sí” o “No”. Antes de enviar las encuestas a 500 personas, preparamos un análisis (ejemplo) para el que es necesario generar una muestra con una relación de respuesta de 9 : 1. Para simular esto podemos utilizar la función sample() de R de la siguiente forma: sample(0:1, 500, replace = TRUE, prob = c(0.90, 0.10)) Es decir, se generan aleatoriamente 500 números de 0 (No) y 1 (Sí), tomando en cuenta las probabilidades (pesos) dados para cada uno de estos dos números (0.9 y 0.1). sample(0:1, 500, replace = TRUE, prob = c(0.90, 0.10)) # nota: replace = TRUE ## [1] 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 ## [36] 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 1 1 0 1 ## [71] 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ## [106] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 ## [141] 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 ## [176] 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 ## [211] 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 ## [246] 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ## [281] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 ## [316] 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 ## [351] 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ## [386] 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 ## [421] 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 ## [456] 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 1 0 0 0 0 1 1 0 0 ## [491] 0 1 0 0 0 0 0 0 0 0 13.3 Proceso de muestreo para realizar una encuesta En mercadeo, a menudo se genera nuevo conocimiento a través de encuestas. Dado que es “costoso” preguntar a toda una población numerosa, generalmente se trabaja con una muestra. Si la población es menor que 100.000 (personas), se puede proceder de la siguiente forma. Fuente: http://www.marketing-xxi.com/proceso-de-la-investigacion-de-mercados-i-24.htm 13.3.1 Creamos “nuestra propia función” en R Según: https://www.tutorialspoint.com/r/r_functions.htm, una función permite realizar una operación, como un cálculo, que se puede reutilizar de forma fácil. function_name &lt;- function(arg_1, arg_2, …) { Function body } En nuestro caso se trata de crear la función (llamémosla “muestra.n”) para calcular la muestra para una población con menos de 100.000 individuos: Donde: n = Número de elementos de la muestra. N = Número de elementos del universo (población). P/Q = Probabilidades con las que se presenta el fenómeno. Q = 1-P. Si P es desconocido el valor es 0,5 (50%). Z^2 = Valor crítico correspondiente al nivel de confianza elegido. E = Margen de error permitido (a determinar por el director del estudio). Típicamente 5% o 6%. muestra.n &lt;- function(N, P, Q, Z, E){ ((Z^2)*P*Q*N) / ((E^2)*(N-1)+(Z^2)*P*Q) } 13.3.2 Definir los valores para los parámetros de la función “muestra.n” Con: Z &lt;- 1.96 # 1.96 = 95% nivel de confianza P &lt;- 0.5 #0.5 Q &lt;- 1-P N &lt;- 1300 #1300 E &lt;- 0.05 #5% o 0.05 13.3.3 Llamar la función “muestra.n” y observar el resultado Se puede observar el resultado del cálculo del tamaño de la muestra, utilizando estos valores: muestra.n(N, P, Q, Z, E) Z &lt;- 1.96 # 1.96 = 95% nivel de confianza P &lt;- 0.5 # 0.5 Q &lt;- 0.5 # 1-P N &lt;- 1300 #1300 E &lt;- 0.05 #5% o 0.05 muestra.n(N, P, Q, Z, E) #296.7086 = 297 = n ## [1] 296.7086 13.3.4 Para poblaciones mayor que 100.000 personas Para poblaciones mayor que 100.000 la función es: muestra.n.2 &lt;- function(P, Q, Z, E){ ((Z^2) P*Q) / (E^2) } muestra.n.2 &lt;- function(P1, Q1, Z1, E1){ ((Z1^2)*P1*Q1) / (E1^2) } 13.3.5 Definir los valores para los parámetros de la función “muestra.n.2” Z1 &lt;- 1.96 # 1.96 = 95% nivel de confianza P1 &lt;- 0.5 # 0.5 Q1 &lt;- 1-P N1 &lt;- 48000000 # 48000000 , p.ej. cantidad de habitantes de Colombia en el año 2018. Nota: N no se usa en la función. E1 &lt;- 0.05 # 5% o 0.05 13.3.6 Llamar (usar) la función muestra.n.2(P1, Q1, Z1, E1) con estos valores. Z1 &lt;- 1.96 # 1.96 = 95% nivel de confianza P1 &lt;- 0.5 # 0.5 Q1 &lt;- 0.5 # 1-P N1 &lt;- 48000000 # 48000000 , p.ej. cantidad de habitantes de Colombia en el año 2018. Nota: N no se usa en la función. E1 &lt;- 0.05 # 5% o 0.05 muestra.n.2(P1, Q1, Z1, E1) # 384.16 = 385 = n ## [1] 384.16 13.4 Muestreo para un problema de datos masivos (big data) El siguiente ejemplo se tomó de la siguiente fuente: https://medium.com/data-science-journal/how-to-correctly-select-a-sample-from-a-huge-dataset-in-machine-learning-24327650372c Lo que vamos a hacer es, considerar cada variable independientemente de las demás. Si cada uno de los histogramas únicos y univariados de las columnas de muestra es comparable con el histograma correspondiente de las columnas de población, podemos suponer que la muestra no está sesgada. Algunos de ustedes podrían pensar que estamos olvidando la correlación entre las variables. Esto no es del todo cierto si seleccionamos nuestra muestra de manera uniforme. Es ampliamente conocido que seleccionar una submuestra de manera uniforme producirá, con grandes números, la misma distribución de probabilidad de la población original. Potentes métodos de remuestreo como bootstrap se basan en este concepto. El histograma para variables categóricas se puede comparar utilizando un Pearson’s chi-square test, mientras la función de la distribución cumulativa de variables numéricas se puede comparar utilizando un Kolmogorov-Smirnov test. Ambas pruebas estadísticas funcionan bajo la hipótesis nula de que la muestra tiene la misma distribución como la población. Dado que una muestra está compuesta por muchas columnas y queremos que todas sean significativas, podemos rechazar la hipótesis nula si el valor p de al menos una de las pruebas es inferior al nivel de confianza, habitualmente del 5%. En otras palabras, queremos que cada columna pase la prueba de significancia para aceptar la muestra como válida. Simulemos algunos datos (masivos). Crearemos una dataset con 1 millón de registros y 2 columnas. -El primero tiene 500,000 registros tomados de una distribución normal, mientras que los otros 500,000 registros se toman de una distribución uniforme. Esta variable está claramente sesgada y me ayudará a explicar los conceptos de significancia estadística más adelante. -El otro campo es una variable de factor creada usando las primeras 10 letras del alfabeto distribuidas uniformemente. set.seed(100), N = 1000000 # = 1e06, dataset = data.frame( # La variable x1 tiene un sesgo. Se toman los primeros 500 mil valores, # de una distribución normal, mientras que los 500 mil restantes, # se toman de una distribución uniforme, x1 = c( rnorm(N/2,0,1) , runif(N/2,0,1) ), # Variable categórica construida por las primeras 10 letras del alfabeto, x2 = sample(LETTERS[1:10],N,replace=TRUE) ) set.seed(100) N = 1000000 # = 1e06 dataset = data.frame( x1 = c( rnorm(N/2,0,1) , runif(N/2,0,1) ), x2 = sample(LETTERS[1:10],N,replace=TRUE) ) # La variable x1 tiene un sesgo. Se toman los primeros 500 mil valores # de una distribución normal, mientras que los 500 mil restantes # se toman de una distribución uniforme # X2: Variable categórica construida por las primeras 10 letras del alfabeto head(dataset) ## x1 x2 ## 1 -0.50219235 F ## 2 0.13153117 A ## 3 -0.07891709 F ## 4 0.88678481 J ## 5 0.11697127 G ## 6 0.31863009 A Ahora podemos intentar de crear una muestra compuesta por 10.000 registros del conjunto de datos original y verificar su significancia. Para cada prueba, almacenaremos su valor p en una lista con nombre para la verificación final. Si todos los valores p son superiores al 5%, podemos decir que la muestra no está sesgada. sample_size = 10000 set.seed(1) idxs = sample(1:nrow(dataset), sample_size, replace=F) subsample = dataset[idxs, ] pvalues = list() for (col in names(dataset)) { if (class(dataset[,col]) %in% c(“numeric”,“integer”)) { # Variable númerico. Utilizando Kolmogorov-Smirnov test pvalues[[col]] = ks.test(subsample[[col]],dataset[[col]])\\(p.value \\} else \\{ # Variable categórica. Utilizando Pearson&#39;s Chi-square test probs = table(dataset[[col]])/nrow(dataset) pvalues[[col]] = chisq.test(table(subsample[[col]]),p=probs)\\)p.value } } pvalues sample_size = 10000 set.seed(1) idxs = sample(1:nrow(dataset), sample_size, replace=F) subsample = dataset[idxs, ] pvalues = list() for (col in names(dataset)) { if (class(dataset[,col]) %in% c(&quot;numeric&quot;,&quot;integer&quot;)) { pvalues[[col]] = ks.test(subsample[[col]],dataset[[col]])$p.value } else { probs = table(dataset[[col]])/nrow(dataset) pvalues[[col]] = chisq.test(table(subsample[[col]]),p=probs)$p.value } } ## Warning in ks.test(subsample[[col]], dataset[[col]]): p-value will be ## approximate in the presence of ties pvalues ## $x1 ## [1] 0.4569533 ## ## $x2 ## [1] 0.6144188 # ks.test: Variable númerica. Utilizando Kolmogorov-Smirnov test # probs: Variable categórica. Utilizando Pearson&#39;s Chi-square test Cada uno de los valores p es superior al 5%, por lo que podemos decir, que la muestra es estadísticamente significativa. 13.5 Muestreo estratificado - Stratified sampling Fuente: https://dzone.com/articles/data-sampling-methods-in-r En el muestreo estratificado, la población de datos se divide en grupos y se toman muestras de cada grupo. La división de la población en grupos se llama “strate”, y la muestra aleatoria simple para cada grupo se llama “stratum”. Utilizamos el paquete “dplyr” (parte del tidyversee) y los datos iris, que vienen con la instalación de R. Agrupamos por especie. sample_iris &lt;- iris %&gt;% group_by(Species) %&gt;% sample_n(2) Nota: los datos iris tienen 150 observaciones y 5 variables Resultado: 6 observaciones de 5 variables = 2 de cada especie 13.6 Trabajar con potencia (power analysis) library(pwr) # Power analysis Ejemplo: Queremos medir el cambio de la productividad con respecto a una población (empresas de un determinado sector en una región). Conocemos o suponemos que el crecimiento de la productividad tiene una desviación estándar (SD) de 4.0% (anual) y que una diferencia de 3% en la variación de la productividad (anual) se puede considerar una variación importante (el tamaño del efecto “d” sería d=3/4=0.75 - la diferencia de medias dividido la SD -). Para una potencia del 80% (el valor que típicamente se usa) y un nivel de confianza del 95%, ¿cuántos participantes necesitamos en nuestro estudio? 13.6.1 Utilziar la función pwr.t.test() - Power calculations for t-tests of means ?pwr.t.test pwr.t.test(d=.75, sig.level=.05, power=.8, type=“two.sample”, alternative=“two.sided”) two.sample es para dos grupos. Un grupo de que se va a “intervenir” o otro que sirve como grupo de control (control group). library(pwr) ## Warning: package &#39;pwr&#39; was built under R version 3.5.3 ?pwr.t.test pwr.t.test(d=.75, sig.level=.05, power=.8, type=&quot;two.sample&quot;, alternative=&quot;two.sided&quot;) ## ## Two-sample t test power calculation ## ## n = 28.89959 ## d = 0.75 ## sig.level = 0.05 ## power = 0.8 ## alternative = two.sided ## ## NOTE: n is number in *each* group Nota: Si podemos asumir para el presente caso, que solo hay crecimiento y no hay decrecimiento, p.ej. por la situación coyuntural durante el estudio, se puede definir “single.sided” (solo un lado de la distribución). 13.7 Ejercicio 8 Si se requiere saber, cuántas personas de una región estan dispuestas de trabajar en el extranjero, y si se puede asumir que la población de la región que trabaja o puede trabajar es de 50 mil personas, ¿qué tan grande debe ser la muestra para una encuesta que busca determinar esta disposición para trabajar en otro país? Asumimos para la generación de esta muestra que el margen de error es de 5% y el nivel de confianza requerido es de 95%. P y Q son 0.5 "],
["arbolDec.html", "Sección 14 Árbol de decisión - Decision Tree 14.1 Objetivo 14.2 Cargar los datos 14.3 Explorar los datos 14.4 Mejorar los nombres (etiquetas) de las columnas del dataset 14.5 Transformar algunos datos 14.6 Particionar los datos 14.7 Construir el modelo (árbol de decisión, AD) 14.8 Realizar la predicción con base en el modelo 14.9 Evaluar el desempeño del modelo (árbol de decisión) 14.10 Ejercicio 9", " Sección 14 Árbol de decisión - Decision Tree 14.1 Objetivo El objetivo en este ejemplo consiste en clasificar datos de créditos (credit data), utilizando un modelo de árbol de decisión (AD) Vamos a utilizar los datos de crédito que están disponibles en línea como archivo csv, en la siguiente dirección (url), para clasificarlos en dos grupos (clases): “buena paga” y “mala paga” 14.2 Cargar los datos Bajar el archivo de los datos de la internet y leer los datos del archivo y asignarlos a una variable “dataset” url &lt;- “http://freakonometrics.free.fr/german_credit.csv” dataset &lt;- read.csv(url, header = TRUE, sep = “,”) url &lt;- &quot;http://freakonometrics.free.fr/german_credit.csv&quot; dataset &lt;- read.csv(url, header = TRUE, sep = &quot;,&quot;) # Estos mismos datos también se pueden bajar de la siguiente dirección: # url &lt;- &quot;https://newonlinecourses.science.psu.edu/onlinecourses/sites/stat508/files/german_credit.csv&quot; # credit &lt;- read.csv(url(direccion)) 14.3 Explorar los datos Mostrar las primeras seis filas de los datos (dataset) en la pantalla Analizar la estructura de los datos Determinar la clase de los datos (class()) Realizar una estadística descriptiva de los datos, utilizando la función summary() Observe: Todos los datos son “numéricos” ¿Cuál es la variable de salida, cuáles son variables de entrada para el modelo (aquí: árbol de decisión)? print(head(dataset)) ## Creditability Account.Balance Duration.of.Credit..month. ## 1 1 1 18 ## 2 1 1 9 ## 3 1 2 12 ## 4 1 1 12 ## 5 1 1 12 ## 6 1 1 10 ## Payment.Status.of.Previous.Credit Purpose Credit.Amount ## 1 4 2 1049 ## 2 4 0 2799 ## 3 2 9 841 ## 4 4 0 2122 ## 5 4 0 2171 ## 6 4 0 2241 ## Value.Savings.Stocks Length.of.current.employment Instalment.per.cent ## 1 1 2 4 ## 2 1 3 2 ## 3 2 4 2 ## 4 1 3 3 ## 5 1 3 4 ## 6 1 2 1 ## Sex...Marital.Status Guarantors Duration.in.Current.address ## 1 2 1 4 ## 2 3 1 2 ## 3 2 1 4 ## 4 3 1 2 ## 5 3 1 4 ## 6 3 1 3 ## Most.valuable.available.asset Age..years. Concurrent.Credits ## 1 2 21 3 ## 2 1 36 3 ## 3 1 23 3 ## 4 1 39 3 ## 5 2 38 1 ## 6 1 48 3 ## Type.of.apartment No.of.Credits.at.this.Bank Occupation No.of.dependents ## 1 1 1 3 1 ## 2 1 2 3 2 ## 3 1 1 2 1 ## 4 1 2 2 2 ## 5 2 2 2 1 ## 6 1 2 2 2 ## Telephone Foreign.Worker ## 1 1 1 ## 2 1 1 ## 3 1 1 ## 4 1 2 ## 5 1 2 ## 6 1 2 str(dataset) ## &#39;data.frame&#39;: 1000 obs. of 21 variables: ## $ Creditability : int 1 1 1 1 1 1 1 1 1 1 ... ## $ Account.Balance : int 1 1 2 1 1 1 1 1 4 2 ... ## $ Duration.of.Credit..month. : int 18 9 12 12 12 10 8 6 18 24 ... ## $ Payment.Status.of.Previous.Credit: int 4 4 2 4 4 4 4 4 4 2 ... ## $ Purpose : int 2 0 9 0 0 0 0 0 3 3 ... ## $ Credit.Amount : int 1049 2799 841 2122 2171 2241 3398 1361 1098 3758 ... ## $ Value.Savings.Stocks : int 1 1 2 1 1 1 1 1 1 3 ... ## $ Length.of.current.employment : int 2 3 4 3 3 2 4 2 1 1 ... ## $ Instalment.per.cent : int 4 2 2 3 4 1 1 2 4 1 ... ## $ Sex...Marital.Status : int 2 3 2 3 3 3 3 3 2 2 ... ## $ Guarantors : int 1 1 1 1 1 1 1 1 1 1 ... ## $ Duration.in.Current.address : int 4 2 4 2 4 3 4 4 4 4 ... ## $ Most.valuable.available.asset : int 2 1 1 1 2 1 1 1 3 4 ... ## $ Age..years. : int 21 36 23 39 38 48 39 40 65 23 ... ## $ Concurrent.Credits : int 3 3 3 3 1 3 3 3 3 3 ... ## $ Type.of.apartment : int 1 1 1 1 2 1 2 2 2 1 ... ## $ No.of.Credits.at.this.Bank : int 1 2 1 2 2 2 2 1 2 1 ... ## $ Occupation : int 3 3 2 2 2 2 2 2 1 1 ... ## $ No.of.dependents : int 1 2 1 2 1 2 1 2 1 1 ... ## $ Telephone : int 1 1 1 1 1 1 1 1 1 1 ... ## $ Foreign.Worker : int 1 1 1 2 2 2 2 2 1 1 ... class(dataset) # data.frame ## [1] &quot;data.frame&quot; summary(dataset) ## Creditability Account.Balance Duration.of.Credit..month. ## Min. :0.0 Min. :1.000 Min. : 4.0 ## 1st Qu.:0.0 1st Qu.:1.000 1st Qu.:12.0 ## Median :1.0 Median :2.000 Median :18.0 ## Mean :0.7 Mean :2.577 Mean :20.9 ## 3rd Qu.:1.0 3rd Qu.:4.000 3rd Qu.:24.0 ## Max. :1.0 Max. :4.000 Max. :72.0 ## Payment.Status.of.Previous.Credit Purpose Credit.Amount ## Min. :0.000 Min. : 0.000 Min. : 250 ## 1st Qu.:2.000 1st Qu.: 1.000 1st Qu.: 1366 ## Median :2.000 Median : 2.000 Median : 2320 ## Mean :2.545 Mean : 2.828 Mean : 3271 ## 3rd Qu.:4.000 3rd Qu.: 3.000 3rd Qu.: 3972 ## Max. :4.000 Max. :10.000 Max. :18424 ## Value.Savings.Stocks Length.of.current.employment Instalment.per.cent ## Min. :1.000 Min. :1.000 Min. :1.000 ## 1st Qu.:1.000 1st Qu.:3.000 1st Qu.:2.000 ## Median :1.000 Median :3.000 Median :3.000 ## Mean :2.105 Mean :3.384 Mean :2.973 ## 3rd Qu.:3.000 3rd Qu.:5.000 3rd Qu.:4.000 ## Max. :5.000 Max. :5.000 Max. :4.000 ## Sex...Marital.Status Guarantors Duration.in.Current.address ## Min. :1.000 Min. :1.000 Min. :1.000 ## 1st Qu.:2.000 1st Qu.:1.000 1st Qu.:2.000 ## Median :3.000 Median :1.000 Median :3.000 ## Mean :2.682 Mean :1.145 Mean :2.845 ## 3rd Qu.:3.000 3rd Qu.:1.000 3rd Qu.:4.000 ## Max. :4.000 Max. :3.000 Max. :4.000 ## Most.valuable.available.asset Age..years. Concurrent.Credits ## Min. :1.000 Min. :19.00 Min. :1.000 ## 1st Qu.:1.000 1st Qu.:27.00 1st Qu.:3.000 ## Median :2.000 Median :33.00 Median :3.000 ## Mean :2.358 Mean :35.54 Mean :2.675 ## 3rd Qu.:3.000 3rd Qu.:42.00 3rd Qu.:3.000 ## Max. :4.000 Max. :75.00 Max. :3.000 ## Type.of.apartment No.of.Credits.at.this.Bank Occupation ## Min. :1.000 Min. :1.000 Min. :1.000 ## 1st Qu.:2.000 1st Qu.:1.000 1st Qu.:3.000 ## Median :2.000 Median :1.000 Median :3.000 ## Mean :1.928 Mean :1.407 Mean :2.904 ## 3rd Qu.:2.000 3rd Qu.:2.000 3rd Qu.:3.000 ## Max. :3.000 Max. :4.000 Max. :4.000 ## No.of.dependents Telephone Foreign.Worker ## Min. :1.000 Min. :1.000 Min. :1.000 ## 1st Qu.:1.000 1st Qu.:1.000 1st Qu.:1.000 ## Median :1.000 Median :1.000 Median :1.000 ## Mean :1.155 Mean :1.404 Mean :1.037 ## 3rd Qu.:1.000 3rd Qu.:2.000 3rd Qu.:1.000 ## Max. :2.000 Max. :2.000 Max. :2.000 14.4 Mejorar los nombres (etiquetas) de las columnas del dataset Mostrar primero estos nombres. Es decir, los nombres de las columnas del dataset colnames(dataset) ## [1] &quot;Creditability&quot; ## [2] &quot;Account.Balance&quot; ## [3] &quot;Duration.of.Credit..month.&quot; ## [4] &quot;Payment.Status.of.Previous.Credit&quot; ## [5] &quot;Purpose&quot; ## [6] &quot;Credit.Amount&quot; ## [7] &quot;Value.Savings.Stocks&quot; ## [8] &quot;Length.of.current.employment&quot; ## [9] &quot;Instalment.per.cent&quot; ## [10] &quot;Sex...Marital.Status&quot; ## [11] &quot;Guarantors&quot; ## [12] &quot;Duration.in.Current.address&quot; ## [13] &quot;Most.valuable.available.asset&quot; ## [14] &quot;Age..years.&quot; ## [15] &quot;Concurrent.Credits&quot; ## [16] &quot;Type.of.apartment&quot; ## [17] &quot;No.of.Credits.at.this.Bank&quot; ## [18] &quot;Occupation&quot; ## [19] &quot;No.of.dependents&quot; ## [20] &quot;Telephone&quot; ## [21] &quot;Foreign.Worker&quot; 14.5 Transformar algunos datos Asignar los siguientes nombres nuevos para las columnas del dataset. newColNames &lt;- c(“Creditability_Default”, “Account_Balance”, “Duration_Credit_Month”, “Pmt_Status_Prev_Cred”, “Purpose”, “Credit_Amount”, “Value_Savings_Stocks”, “Length_current_employment”, “Instalment_per_cent”, “Sex_Marital_Status”, “Guarantors”, “Duration_current_address”, “Most_value_avail_asset”, “Age_years”, “Concurrent_Credits”, “Type_of_apartment”, “No_of_Credits_at_this_Bank”, “Occupation”, “No.of.dependents”, “Telephone”, “Foreign_Worker” ) newColNames &lt;- c(&quot;Creditability_Default&quot;, &quot;Account_Balance&quot;, &quot;Duration_Credit_Month&quot;, &quot;Pmt_Status_Prev_Cred&quot;, &quot;Purpose&quot;, &quot;Credit_Amount&quot;, &quot;Value_Savings_Stocks&quot;, &quot;Length_current_employment&quot;, &quot;Instalment_per_cent&quot;, &quot;Sex_Marital_Status&quot;, &quot;Guarantors&quot;, &quot;Duration_current_address&quot;, &quot;Most_value_avail_asset&quot;, &quot;Age_years&quot;, &quot;Concurrent_Credits&quot;, &quot;Type_of_apartment&quot;, &quot;No_of_Credits_at_this_Bank&quot;, &quot;Occupation&quot;, &quot;No.of.dependents&quot;, &quot;Telephone&quot;, &quot;Foreign_Worker&quot; ) #Asignar estos nombres para utilizarlos a partir de ahora names(dataset) &lt;- newColNames colnames(dataset) ## [1] &quot;Creditability_Default&quot; &quot;Account_Balance&quot; ## [3] &quot;Duration_Credit_Month&quot; &quot;Pmt_Status_Prev_Cred&quot; ## [5] &quot;Purpose&quot; &quot;Credit_Amount&quot; ## [7] &quot;Value_Savings_Stocks&quot; &quot;Length_current_employment&quot; ## [9] &quot;Instalment_per_cent&quot; &quot;Sex_Marital_Status&quot; ## [11] &quot;Guarantors&quot; &quot;Duration_current_address&quot; ## [13] &quot;Most_value_avail_asset&quot; &quot;Age_years&quot; ## [15] &quot;Concurrent_Credits&quot; &quot;Type_of_apartment&quot; ## [17] &quot;No_of_Credits_at_this_Bank&quot; &quot;Occupation&quot; ## [19] &quot;No.of.dependents&quot; &quot;Telephone&quot; ## [21] &quot;Foreign_Worker&quot; Analizar la variable dependiente (variable de salida): Creditability_Default, en términos de una tabla que muestra las frecuencias para los valores “0” y “1” ¿Cuál es el valor para “buena paga”? ¿“0” o “1”? table(dataset$Creditability_Default) ## ## 0 1 ## 300 700 prop.table(table(dataset$Creditability_Default)) # lo mismo pero como porcentajes ## ## 0 1 ## 0.3 0.7 Determinar la clase de la variable (columna) “Creditability_Default” class(dataset$Creditability_Default) # integer ## [1] &quot;integer&quot; Transformar esta variable (dependiente) en una variable categórica (factor) dataset$Creditability_Default &lt;- as.factor(dataset$Creditability_Default) str(dataset$Creditability_Default) ## Factor w/ 2 levels &quot;0&quot;,&quot;1&quot;: 2 2 2 2 2 2 2 2 2 2 ... 14.6 Particionar los datos Particionar (dividir) los datos en dos partes, de forma aleatoria. En una parte (un grupo) de entrenamiento (credit_train) y otra de prueba (credit_test), utilizando una relación 66% (nombre: credit_train) y 34% (nombre: credit_test) Utilizar la función sample() y la semilla 123 para hacer los resultados reproducibles (set.seed()) Nota: La cantidad de los datos se puede determinar con: nrow(dataset) set.seed(123) d = sort(sample(nrow(dataset),nrow(dataset)*0.66, replace=FALSE)) # dividir en una conjunto de training y test set credit_train &lt;- dataset[d, ] credit_test &lt;- dataset[-d, ] Luego, verificar las proporciones entre estos dos grupos con respecto a la variable de salida (variable de predicción) prop.table(table(credit_train$Creditability_Default)) ## ## 0 1 ## 0.2787879 0.7212121 prop.table(table(credit_test$Creditability_Default)) ## ## 0 1 ## 0.3411765 0.6588235 Como se puede observar a través del resultado, las proporciones no se conservaron exactamente, pero aproximadamente 14.7 Construir el modelo (árbol de decisión, AD) Analizar el paquete “C50”, que permite construir un árbol de decisión Construir un árbol de decisión sencillo con el nombre “credit_DT_model”, utilizando el paquete C50 (con “C” mayúscula), la función C50() y los datos de entrenamiento Excluir de los datos la columna “Telephone” (porque no explica si un cliente es de “buena o de mala paga”) y adicionalmente la variable de salida (variable de predicción) Mostrar los resultados (output), utilizando la función summary() y analizarlos ¿Cuál es la variable más importante para estimar, si un cliente es de “buena paga” o “mala paga”? library(C50) ## Warning: package &#39;C50&#39; was built under R version 3.5.3 ?C5.0 # create the DT credit_DT_model &lt;- C5.0(credit_train[ , -c(1,20)], credit_train$Creditability_Default) # -1 excluye la columna Creditability_Default y -20 la columna del Telephone summary(credit_DT_model) ## ## Call: ## C5.0.default(x = credit_train[, -c(1, 20)], y ## = credit_train$Creditability_Default) ## ## ## C5.0 [Release 2.07 GPL Edition] Sat Feb 01 16:04:26 2020 ## ------------------------------- ## ## Class specified by attribute `outcome&#39; ## ## Read 660 cases (20 attributes) from undefined.data ## ## Decision tree: ## ## Account_Balance &gt; 2: ## :...Concurrent_Credits &lt;= 2: ## : :...No_of_Credits_at_this_Bank &lt;= 1: ## : : :...Most_value_avail_asset &gt; 1: 1 (18/1) ## : : : Most_value_avail_asset &lt;= 1: ## : : : :...Length_current_employment &lt;= 2: 0 (2) ## : : : Length_current_employment &gt; 2: 1 (2) ## : : No_of_Credits_at_this_Bank &gt; 1: ## : : :...Pmt_Status_Prev_Cred &lt;= 1: 0 (3) ## : : Pmt_Status_Prev_Cred &gt; 1: ## : : :...Credit_Amount &lt;= 6527: 1 (15/2) ## : : Credit_Amount &gt; 6527: 0 (4/1) ## : Concurrent_Credits &gt; 2: ## : :...Age_years &gt; 34: 1 (127/4) ## : Age_years &lt;= 34: ## : :...Credit_Amount &lt;= 7511: 1 (129/19) ## : Credit_Amount &gt; 7511: ## : :...Duration_Credit_Month &lt;= 54: 0 (4) ## : Duration_Credit_Month &gt; 54: 1 (2) ## Account_Balance &lt;= 2: ## :...Duration_Credit_Month &lt;= 11: ## :...Pmt_Status_Prev_Cred &lt;= 1: 0 (5/1) ## : Pmt_Status_Prev_Cred &gt; 1: 1 (49/4) ## Duration_Credit_Month &gt; 11: ## :...Value_Savings_Stocks &gt; 1: ## :...Pmt_Status_Prev_Cred &gt; 2: 1 (27/3) ## : Pmt_Status_Prev_Cred &lt;= 2: ## : :...Type_of_apartment &lt;= 1: ## : :...Instalment_per_cent &lt;= 1: 1 (2) ## : : Instalment_per_cent &gt; 1: ## : : :...Account_Balance &gt; 1: 0 (8) ## : : Account_Balance &lt;= 1: ## : : :...Most_value_avail_asset &lt;= 2: 1 (2) ## : : Most_value_avail_asset &gt; 2: 0 (3/1) ## : Type_of_apartment &gt; 1: ## : :...Occupation &gt; 3: ## : :...Length_current_employment &gt; 4: 0 (3) ## : : Length_current_employment &lt;= 4: ## : : :...Age_years &lt;= 35: 0 (4/1) ## : : Age_years &gt; 35: 1 (3) ## : Occupation &lt;= 3: ## : :...Type_of_apartment &lt;= 2: 1 (38/6) ## : Type_of_apartment &gt; 2: ## : :...Concurrent_Credits &lt;= 2: 1 (2) ## : Concurrent_Credits &gt; 2: ## : :...Account_Balance &lt;= 1: 0 (3) ## : Account_Balance &gt; 1: 1 (3/1) ## Value_Savings_Stocks &lt;= 1: ## :...Guarantors &gt; 2: ## :...Purpose &lt;= 0: 0 (4) ## : Purpose &gt; 0: 1 (14/1) ## Guarantors &lt;= 2: ## :...Duration_Credit_Month &lt;= 22: ## :...Pmt_Status_Prev_Cred &gt; 2: ## : :...Most_value_avail_asset &gt; 1: 1 (22/3) ## : : Most_value_avail_asset &lt;= 1: ## : : :...Age_years &lt;= 38: 0 (3) ## : : Age_years &gt; 38: 1 (4) ## : Pmt_Status_Prev_Cred &lt;= 2: ## : :...Guarantors &gt; 1: 1 (3) ## : Guarantors &lt;= 1: ## : :...No_of_Credits_at_this_Bank &gt; 1: ## : :...Account_Balance &lt;= 1: 0 (6) ## : : Account_Balance &gt; 1: ## : : :...Type_of_apartment &lt;= 1: 0 (3) ## : : Type_of_apartment &gt; 1: 1 (2) ## : No_of_Credits_at_this_Bank &lt;= 1: ## : :...Account_Balance &gt; 1: ## : :...Credit_Amount &lt;= 1546: 0 (5/1) ## : : Credit_Amount &gt; 1546: 1 (8) ## : Account_Balance &lt;= 1: ## : :...Type_of_apartment &gt; 2: 0 (2) ## : Type_of_apartment &lt;= 2: ## : :...Type_of_apartment &lt;= 1: ## : :...Instalment_per_cent &lt;= 3: 1 (6/1) ## : : Instalment_per_cent &gt; 3: 0 (3) ## : Type_of_apartment &gt; 1: ## : :...Purpose &gt; 6: 1 (3) ## : Purpose &lt;= 6: [S1] ## Duration_Credit_Month &gt; 22: ## :...Type_of_apartment &lt;= 1: 0 (19/2) ## Type_of_apartment &gt; 1: ## :...Purpose &lt;= 0: 0 (17/2) ## Purpose &gt; 0: ## :...Concurrent_Credits &lt;= 2: ## :...Duration_current_address &lt;= 1: 1 (3/1) ## : Duration_current_address &gt; 1: ## : :...Age_years &lt;= 42: 0 (11) ## : Age_years &gt; 42: 1 (3/1) ## Concurrent_Credits &gt; 2: ## :...Pmt_Status_Prev_Cred &lt;= 1: 0 (5/1) ## Pmt_Status_Prev_Cred &gt; 1: ## :...Purpose &gt; 6: 0 (3) ## Purpose &lt;= 6: ## :...Duration_current_address &lt;= 1: 1 (4) ## Duration_current_address &gt; 1: ## :...Type_of_apartment &gt; 2: ## :...Occupation &lt;= 3: 0 (3) ## : Occupation &gt; 3: 1 (3/1) ## Type_of_apartment &lt;= 2: [S2] ## ## SubTree [S1] ## ## Sex_Marital_Status &gt; 3: 1 (4/1) ## Sex_Marital_Status &lt;= 3: ## :...Occupation &lt;= 2: 0 (5) ## Occupation &gt; 2: ## :...Duration_current_address &lt;= 1: 1 (2) ## Duration_current_address &gt; 1: 0 (8/1) ## ## SubTree [S2] ## ## Length_current_employment &gt; 4: 1 (5) ## Length_current_employment &lt;= 4: ## :...No_of_Credits_at_this_Bank &gt; 1: 1 (4/1) ## No_of_Credits_at_this_Bank &lt;= 1: ## :...Occupation &gt; 3: ## :...Account_Balance &lt;= 1: 1 (3) ## : Account_Balance &gt; 1: 0 (2) ## Occupation &lt;= 3: ## :...Age_years &gt; 33: 0 (5) ## Age_years &lt;= 33: ## :...Most_value_avail_asset &lt;= 2: 0 (3/1) ## Most_value_avail_asset &gt; 2: 1 (2) ## ## ## Evaluation on training data (660 cases): ## ## Decision Tree ## ---------------- ## Size Errors ## ## 60 62( 9.4%) &lt;&lt; ## ## ## (a) (b) &lt;-classified as ## ---- ---- ## 134 50 (a): class 0 ## 12 464 (b): class 1 ## ## ## Attribute usage: ## ## 100.00% Account_Balance ## 56.52% Concurrent_Credits ## 54.55% Duration_Credit_Month ## 46.21% Pmt_Status_Prev_Cred ## 45.45% Value_Savings_Stocks ## 45.45% Age_years ## 30.91% Type_of_apartment ## 30.61% Guarantors ## 25.30% Credit_Amount ## 18.18% No_of_Credits_at_this_Bank ## 17.58% Purpose ## 13.94% Occupation ## 9.24% Duration_current_address ## 9.24% Most_value_avail_asset ## 5.76% Length_current_employment ## 3.64% Instalment_per_cent ## 2.88% Sex_Marital_Status ## ## ## Time: 0.0 secs 14.8 Realizar la predicción con base en el modelo Utilizar el modelo anteriormente generado para hacer una predicción (prediction vector), utilizando la función predict() y los datos de prueba (credit_test) Asignar el resultado de la predicción a la variable “credit_pred” credit_pred &lt;- predict(credit_DT_model, credit_test) 14.9 Evaluar el desempeño del modelo (árbol de decisión) Evaluar el desempeño del modelo, generando una matriz de error (matriz de confusión o matriz de clasificación) con respecto a la variable de predicción (variable de salida), utilizando los datos de prueba Esta matriz se puede crear, utilizando el paquete “gmodels” y la función CrossTable() o simplemente usando la función table(), que genera una tabla más sencilla, pero con la misma cantidad de observaciones Explicar, cómo se debe interpretar el contenido de la tabla ¿Cuántos “0” clasificó bien el modelo? library(gmodels) ## Warning: package &#39;gmodels&#39; was built under R version 3.5.3 CrossTable(credit_test$Creditability_Default, credit_pred) ## ## ## Cell Contents ## |-------------------------| ## | N | ## | Chi-square contribution | ## | N / Row Total | ## | N / Col Total | ## | N / Table Total | ## |-------------------------| ## ## ## Total Observations in Table: 340 ## ## ## | credit_pred ## credit_test$Creditability_Default | 0 | 1 | Row Total | ## ----------------------------------|-----------|-----------|-----------| ## 0 | 43 | 73 | 116 | ## | 15.304 | 3.968 | | ## | 0.371 | 0.629 | 0.341 | ## | 0.614 | 0.270 | | ## | 0.126 | 0.215 | | ## ----------------------------------|-----------|-----------|-----------| ## 1 | 27 | 197 | 224 | ## | 7.925 | 2.055 | | ## | 0.121 | 0.879 | 0.659 | ## | 0.386 | 0.730 | | ## | 0.079 | 0.579 | | ## ----------------------------------|-----------|-----------|-----------| ## Column Total | 70 | 270 | 340 | ## | 0.206 | 0.794 | | ## ----------------------------------|-----------|-----------|-----------| ## ## #Alternativa table(credit_test$Creditability_Default, credit_pred) ## credit_pred ## 0 1 ## 0 43 73 ## 1 27 197 14.10 Ejercicio 9 Realizar un árbol decisión en R, utilizando el paquete “ISLR” y el dataset “Smarket”, que viene con este paquete, para clasificar los datos del dataset con el objetivo de determinar, si el mercado (índice S&amp;P500) va a subir o bajar. Mostrar las primeras 3 filas de este dataset “Smarket” y analizar de esta forma las columnas (variables) del dataset. Nota: Las variables “Lag..” se refieren a precios determinados en el mercado de capitales (S&amp;P Stock Market Data) y refleja rendimientos diarios de este índice búrsatil, expresado como porcentaje. Utilizar el comando “?Smarket” para consultar las páginas de ayuda al respecto Mostrar, la estructura de este dataset, utilizando la función str() Utilizando la semilla 123 (set.seed(123)), dividir los datos en una parte de entrenamiento (train_data) y otra parte de pruebas (test_data). 66% del total de los datos se deben utilizar para el entrenamiento y el resto para las pruebas (test_data) Analizar el paquete “C50”, que permite construir un árbol de decisión Construir un árbol de decisión sencillo con el nombre “modelo.AD”, utilizando el paquete C50 (con “C” mayúscula), la función C50() y los datos de entrenamiento Mostrar los resultados (output), utilizando la función summary() y analizarlos Realizar la predicción, utilzando el modelo construido y los datos de prueba (test_data), asignando el resultado a una variable “pred” Mostrar el resultado de la clasificación en una tabla, utilizando p.ej. la función table() Interpretar el resultado obtenido "],
["regrLog.html", "Sección 15 Regresión logística (modelo logit) 15.1 Objetivo 15.2 Cargar los datos históricos de un archivo csv 15.3 Explorar los datos 15.4 Mejorar los nombres (etiquetas) de las columnas del dataset 15.5 Transformar algunos datos 15.6 Particionar los datos 15.7 Construir el modelo logit (regresión logística) 15.8 Generar el modelo “mejorado” 15.9 Realizar una predicción con el modelo logit mejorado 15.10 Convertir estas probabilidades en dos clases: 1 y 0 (“buena paga” y “mala paga”) 15.11 Ejercicio 10", " Sección 15 Regresión logística (modelo logit) 15.1 Objetivo El objetivo en este ejemplo consiste en clasificar datos de créditos (credit data), utilizando un modelo de regresión logística Para este modelo de la regresión logística véase p.ej. también las definiciones en: https://en.wikipedia.org/wiki/Logit 15.2 Cargar los datos históricos de un archivo csv Vamos a utilizar un conjunto de datos de créditos de la web. El objetivo consiste en construir un clasificador, utilizando una regresión logística, para clasificar los registros en dos grupos (clases): “buena paga” y “mala paga”. Bajar el archivo de los datos de la internet y leer los datos del archivo y asignarlos a una variable “mis.datos” url &lt;- “http://freakonometrics.free.fr/german_credit.csv” mis.datos &lt;- read.csv(url, header = TRUE, sep = “,”) url &lt;- &quot;http://freakonometrics.free.fr/german_credit.csv&quot; mis.datos &lt;- read.csv(url, header = TRUE, sep = &quot;,&quot;) # Estos mismos datos también se pueden bajar de la siguiente dirección: # url &lt;- &quot;https://newonlinecourses.science.psu.edu/onlinecourses/sites/stat508/files/german_credit.csv&quot; # mis.datos &lt;- read.csv(url(direccion)) 15.3 Explorar los datos Mostrar las primeras seis filas de los datos (dataset) en la pantalla Analizar la estructura de los datos Determinar la clase de los datos (class()) Realizar una estadística descriptiva de los datos, utilizando la función summary() Observe: Todos los datos son “numéricos” ¿Cuál es la variable de salida y cuáles son variables de entrada para el modelo a construir (aquí: regresión logística)? print(head(mis.datos)) ## Creditability Account.Balance Duration.of.Credit..month. ## 1 1 1 18 ## 2 1 1 9 ## 3 1 2 12 ## 4 1 1 12 ## 5 1 1 12 ## 6 1 1 10 ## Payment.Status.of.Previous.Credit Purpose Credit.Amount ## 1 4 2 1049 ## 2 4 0 2799 ## 3 2 9 841 ## 4 4 0 2122 ## 5 4 0 2171 ## 6 4 0 2241 ## Value.Savings.Stocks Length.of.current.employment Instalment.per.cent ## 1 1 2 4 ## 2 1 3 2 ## 3 2 4 2 ## 4 1 3 3 ## 5 1 3 4 ## 6 1 2 1 ## Sex...Marital.Status Guarantors Duration.in.Current.address ## 1 2 1 4 ## 2 3 1 2 ## 3 2 1 4 ## 4 3 1 2 ## 5 3 1 4 ## 6 3 1 3 ## Most.valuable.available.asset Age..years. Concurrent.Credits ## 1 2 21 3 ## 2 1 36 3 ## 3 1 23 3 ## 4 1 39 3 ## 5 2 38 1 ## 6 1 48 3 ## Type.of.apartment No.of.Credits.at.this.Bank Occupation No.of.dependents ## 1 1 1 3 1 ## 2 1 2 3 2 ## 3 1 1 2 1 ## 4 1 2 2 2 ## 5 2 2 2 1 ## 6 1 2 2 2 ## Telephone Foreign.Worker ## 1 1 1 ## 2 1 1 ## 3 1 1 ## 4 1 2 ## 5 1 2 ## 6 1 2 str(mis.datos) ## &#39;data.frame&#39;: 1000 obs. of 21 variables: ## $ Creditability : int 1 1 1 1 1 1 1 1 1 1 ... ## $ Account.Balance : int 1 1 2 1 1 1 1 1 4 2 ... ## $ Duration.of.Credit..month. : int 18 9 12 12 12 10 8 6 18 24 ... ## $ Payment.Status.of.Previous.Credit: int 4 4 2 4 4 4 4 4 4 2 ... ## $ Purpose : int 2 0 9 0 0 0 0 0 3 3 ... ## $ Credit.Amount : int 1049 2799 841 2122 2171 2241 3398 1361 1098 3758 ... ## $ Value.Savings.Stocks : int 1 1 2 1 1 1 1 1 1 3 ... ## $ Length.of.current.employment : int 2 3 4 3 3 2 4 2 1 1 ... ## $ Instalment.per.cent : int 4 2 2 3 4 1 1 2 4 1 ... ## $ Sex...Marital.Status : int 2 3 2 3 3 3 3 3 2 2 ... ## $ Guarantors : int 1 1 1 1 1 1 1 1 1 1 ... ## $ Duration.in.Current.address : int 4 2 4 2 4 3 4 4 4 4 ... ## $ Most.valuable.available.asset : int 2 1 1 1 2 1 1 1 3 4 ... ## $ Age..years. : int 21 36 23 39 38 48 39 40 65 23 ... ## $ Concurrent.Credits : int 3 3 3 3 1 3 3 3 3 3 ... ## $ Type.of.apartment : int 1 1 1 1 2 1 2 2 2 1 ... ## $ No.of.Credits.at.this.Bank : int 1 2 1 2 2 2 2 1 2 1 ... ## $ Occupation : int 3 3 2 2 2 2 2 2 1 1 ... ## $ No.of.dependents : int 1 2 1 2 1 2 1 2 1 1 ... ## $ Telephone : int 1 1 1 1 1 1 1 1 1 1 ... ## $ Foreign.Worker : int 1 1 1 2 2 2 2 2 1 1 ... class(mis.datos) # data.frame ## [1] &quot;data.frame&quot; summary(mis.datos) ## Creditability Account.Balance Duration.of.Credit..month. ## Min. :0.0 Min. :1.000 Min. : 4.0 ## 1st Qu.:0.0 1st Qu.:1.000 1st Qu.:12.0 ## Median :1.0 Median :2.000 Median :18.0 ## Mean :0.7 Mean :2.577 Mean :20.9 ## 3rd Qu.:1.0 3rd Qu.:4.000 3rd Qu.:24.0 ## Max. :1.0 Max. :4.000 Max. :72.0 ## Payment.Status.of.Previous.Credit Purpose Credit.Amount ## Min. :0.000 Min. : 0.000 Min. : 250 ## 1st Qu.:2.000 1st Qu.: 1.000 1st Qu.: 1366 ## Median :2.000 Median : 2.000 Median : 2320 ## Mean :2.545 Mean : 2.828 Mean : 3271 ## 3rd Qu.:4.000 3rd Qu.: 3.000 3rd Qu.: 3972 ## Max. :4.000 Max. :10.000 Max. :18424 ## Value.Savings.Stocks Length.of.current.employment Instalment.per.cent ## Min. :1.000 Min. :1.000 Min. :1.000 ## 1st Qu.:1.000 1st Qu.:3.000 1st Qu.:2.000 ## Median :1.000 Median :3.000 Median :3.000 ## Mean :2.105 Mean :3.384 Mean :2.973 ## 3rd Qu.:3.000 3rd Qu.:5.000 3rd Qu.:4.000 ## Max. :5.000 Max. :5.000 Max. :4.000 ## Sex...Marital.Status Guarantors Duration.in.Current.address ## Min. :1.000 Min. :1.000 Min. :1.000 ## 1st Qu.:2.000 1st Qu.:1.000 1st Qu.:2.000 ## Median :3.000 Median :1.000 Median :3.000 ## Mean :2.682 Mean :1.145 Mean :2.845 ## 3rd Qu.:3.000 3rd Qu.:1.000 3rd Qu.:4.000 ## Max. :4.000 Max. :3.000 Max. :4.000 ## Most.valuable.available.asset Age..years. Concurrent.Credits ## Min. :1.000 Min. :19.00 Min. :1.000 ## 1st Qu.:1.000 1st Qu.:27.00 1st Qu.:3.000 ## Median :2.000 Median :33.00 Median :3.000 ## Mean :2.358 Mean :35.54 Mean :2.675 ## 3rd Qu.:3.000 3rd Qu.:42.00 3rd Qu.:3.000 ## Max. :4.000 Max. :75.00 Max. :3.000 ## Type.of.apartment No.of.Credits.at.this.Bank Occupation ## Min. :1.000 Min. :1.000 Min. :1.000 ## 1st Qu.:2.000 1st Qu.:1.000 1st Qu.:3.000 ## Median :2.000 Median :1.000 Median :3.000 ## Mean :1.928 Mean :1.407 Mean :2.904 ## 3rd Qu.:2.000 3rd Qu.:2.000 3rd Qu.:3.000 ## Max. :3.000 Max. :4.000 Max. :4.000 ## No.of.dependents Telephone Foreign.Worker ## Min. :1.000 Min. :1.000 Min. :1.000 ## 1st Qu.:1.000 1st Qu.:1.000 1st Qu.:1.000 ## Median :1.000 Median :1.000 Median :1.000 ## Mean :1.155 Mean :1.404 Mean :1.037 ## 3rd Qu.:1.000 3rd Qu.:2.000 3rd Qu.:1.000 ## Max. :2.000 Max. :2.000 Max. :2.000 15.4 Mejorar los nombres (etiquetas) de las columnas del dataset Primero, mostrar estos nombres, utilizando la función colnames() colnames(mis.datos) ## [1] &quot;Creditability&quot; ## [2] &quot;Account.Balance&quot; ## [3] &quot;Duration.of.Credit..month.&quot; ## [4] &quot;Payment.Status.of.Previous.Credit&quot; ## [5] &quot;Purpose&quot; ## [6] &quot;Credit.Amount&quot; ## [7] &quot;Value.Savings.Stocks&quot; ## [8] &quot;Length.of.current.employment&quot; ## [9] &quot;Instalment.per.cent&quot; ## [10] &quot;Sex...Marital.Status&quot; ## [11] &quot;Guarantors&quot; ## [12] &quot;Duration.in.Current.address&quot; ## [13] &quot;Most.valuable.available.asset&quot; ## [14] &quot;Age..years.&quot; ## [15] &quot;Concurrent.Credits&quot; ## [16] &quot;Type.of.apartment&quot; ## [17] &quot;No.of.Credits.at.this.Bank&quot; ## [18] &quot;Occupation&quot; ## [19] &quot;No.of.dependents&quot; ## [20] &quot;Telephone&quot; ## [21] &quot;Foreign.Worker&quot; 15.5 Transformar algunos datos Asignar los siguientes nombres nuevos para las columnas del dataset “mis.datos” newColNames &lt;- c(“Creditability_Default”, “Account_Balance”, “Duration_Credit_Month”, “Pmt_Status_Prev_Cred”, “Purpose”, “Credit_Amount”, “Value_Savings_Stocks”, “Length_current_employment”, “Instalment_per_cent”, “Sex_Marital_Status”, “Guarantors”, “Duration_current_address”, “Most_value_avail_asset”, “Age_years”, “Concurrent_Credits”, “Type_of_apartment”, “No_of_Credits_at_this_Bank”, “Occupation”, “No.of.dependents”, “Telephone”, “Foreign_Worker” ) newColNames &lt;- c(&quot;Creditability_Default&quot;, &quot;Account_Balance&quot;, &quot;Duration_Credit_Month&quot;, &quot;Pmt_Status_Prev_Cred&quot;, &quot;Purpose&quot;, &quot;Credit_Amount&quot;, &quot;Value_Savings_Stocks&quot;, &quot;Length_current_employment&quot;, &quot;Instalment_per_cent&quot;, &quot;Sex_Marital_Status&quot;, &quot;Guarantors&quot;, &quot;Duration_current_address&quot;, &quot;Most_value_avail_asset&quot;, &quot;Age_years&quot;, &quot;Concurrent_Credits&quot;, &quot;Type_of_apartment&quot;, &quot;No_of_Credits_at_this_Bank&quot;, &quot;Occupation&quot;, &quot;No.of.dependents&quot;, &quot;Telephone&quot;, &quot;Foreign_Worker&quot; ) #Asignar estos nombres nuevos para utilizarlos en adelante names(mis.datos) &lt;- newColNames colnames(mis.datos) ## [1] &quot;Creditability_Default&quot; &quot;Account_Balance&quot; ## [3] &quot;Duration_Credit_Month&quot; &quot;Pmt_Status_Prev_Cred&quot; ## [5] &quot;Purpose&quot; &quot;Credit_Amount&quot; ## [7] &quot;Value_Savings_Stocks&quot; &quot;Length_current_employment&quot; ## [9] &quot;Instalment_per_cent&quot; &quot;Sex_Marital_Status&quot; ## [11] &quot;Guarantors&quot; &quot;Duration_current_address&quot; ## [13] &quot;Most_value_avail_asset&quot; &quot;Age_years&quot; ## [15] &quot;Concurrent_Credits&quot; &quot;Type_of_apartment&quot; ## [17] &quot;No_of_Credits_at_this_Bank&quot; &quot;Occupation&quot; ## [19] &quot;No.of.dependents&quot; &quot;Telephone&quot; ## [21] &quot;Foreign_Worker&quot; Analizar la variable dependiente (variable de salida): Creditability_Default, en términos de una tabla que muestra las frecuencias para los valores “0” y “1” ¿Cuál es el valor para “buena paga”? ¿“0” o “1”? ?table table(mis.datos$Creditability_Default) ## ## 0 1 ## 300 700 prop.table(table(mis.datos$Creditability_Default)) ## ## 0 1 ## 0.3 0.7 # lo mismo, pero como porcentajes Transformar la variable (dependiente) en una variable categórica (factor) mis.datos$Creditability_Default &lt;- as.factor(mis.datos$Creditability_Default) str(mis.datos$Creditability_Default) ## Factor w/ 2 levels &quot;0&quot;,&quot;1&quot;: 2 2 2 2 2 2 2 2 2 2 ... 15.6 Particionar los datos Particionar (dividir) los datos en dos partes, de forma aleatoria. En una parte (un grupo) de entrenamiento (credit_train) y otra de pruebas (credit_test), utilizando una relación 66% (nombre: credit_train) y 34% (nombre: credit_test) Utlizar la función sample() y la semilla 123 para hacer los resultados reproducibles (set.seed()) Nota: La cantidad de los datos se puede determinar con: nrow(dataset) set.seed(123) d = sort(sample(nrow(mis.datos),nrow(mis.datos)*0.66, replace=FALSE)) # dividir en una conjunto de training y test set train_data &lt;- mis.datos[d, ] test_data &lt;- mis.datos[-d, ] Luego, verificar las proporciones entre estos dos grupos con respecto a la variable de salida (variable de predicción) prop.table(table(train_data$Creditability_Default)) ## ## 0 1 ## 0.2787879 0.7212121 prop.table(table(test_data$Creditability_Default)) ## ## 0 1 ## 0.3411765 0.6588235 Como se puede observar a través del resultado, las proporciones no se conservaron exactamente, pero aproximadamente 15.7 Construir el modelo logit (regresión logística) Generar el modelo logit con los datos de entrenamiento (“train_data”), utilizando la función glm(), “generalized linear models”, y asignar el resultado a una variable “modelo.logit”. Donde el parámetro family de la función glm debe tener el valor “binomial(”logit“)” Mostrar el resultado (del modelo), utilizando la función summary() Observar, cuáles de las variables de entrada son estadísticamente significativas ?glm modelo.logit &lt;- glm(Creditability_Default ~ ., family = binomial(&quot;logit&quot;), data = train_data) summary(modelo.logit) ## ## Call: ## glm(formula = Creditability_Default ~ ., family = binomial(&quot;logit&quot;), ## data = train_data) ## ## Deviance Residuals: ## Min 1Q Median 3Q Max ## -2.5567 -0.6795 0.4411 0.7091 1.7835 ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) -3.40801249 1.19368744 -2.855 0.00430 ## Account_Balance 0.57171919 0.08707565 6.566 0.0000000000518 ## Duration_Credit_Month -0.01107795 0.01179393 -0.939 0.34758 ## Pmt_Status_Prev_Cred 0.42410831 0.10677678 3.972 0.0000712970927 ## Purpose 0.03130086 0.03725092 0.840 0.40076 ## Credit_Amount -0.00015276 0.00005478 -2.788 0.00530 ## Value_Savings_Stocks 0.24587168 0.07483525 3.286 0.00102 ## Length_current_employment 0.08025072 0.09009471 0.891 0.37307 ## Instalment_per_cent -0.31912826 0.10533161 -3.030 0.00245 ## Sex_Marital_Status 0.28839526 0.14500392 1.989 0.04671 ## Guarantors 0.24821280 0.22619219 1.097 0.27249 ## Duration_current_address -0.05409286 0.09728100 -0.556 0.57818 ## Most_value_avail_asset -0.20674802 0.11354492 -1.821 0.06863 ## Age_years 0.01284533 0.01025314 1.253 0.21027 ## Concurrent_Credits 0.20727669 0.13658227 1.518 0.12912 ## Type_of_apartment 0.50904998 0.20566104 2.475 0.01332 ## No_of_Credits_at_this_Bank -0.17452665 0.20397168 -0.856 0.39220 ## Occupation -0.00386714 0.17309109 -0.022 0.98218 ## No.of.dependents -0.33349136 0.29472050 -1.132 0.25782 ## Telephone 0.34179847 0.23564223 1.450 0.14692 ## Foreign_Worker 0.65528327 0.64998796 1.008 0.31338 ## ## (Intercept) ** ## Account_Balance *** ## Duration_Credit_Month ## Pmt_Status_Prev_Cred *** ## Purpose ## Credit_Amount ** ## Value_Savings_Stocks ** ## Length_current_employment ## Instalment_per_cent ** ## Sex_Marital_Status * ## Guarantors ## Duration_current_address ## Most_value_avail_asset . ## Age_years ## Concurrent_Credits ## Type_of_apartment * ## No_of_Credits_at_this_Bank ## Occupation ## No.of.dependents ## Telephone ## Foreign_Worker ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 781.18 on 659 degrees of freedom ## Residual deviance: 612.14 on 639 degrees of freedom ## AIC: 654.14 ## ## Number of Fisher Scoring iterations: 5 Eliminar las variables que estadísticamente no son significativas, generando un conjunto de datos train_data2 y test_data2 y generamos el modelo nuevamente con estas variables Esta eliminación se puede realizar de la siguiente forma: train_data[ ,!(colnames(train_data) %in% c(“Duration_Credit_Month”, “Purpose”,…)) ] train_data2 &lt;- train_data[ ,!(colnames(train_data) %in% c(&quot;Duration_Credit_Month&quot;, &quot;Purpose&quot;, &quot;Length_current_employment&quot;, &quot;Guarantors&quot;, &quot;Duration_current_address&quot;, &quot;Age_years&quot;, &quot;Concurrent_Credits&quot;, &quot;No_of_Credits_at_this_Bank&quot;, &quot;Occupation&quot;, &quot;No.of.dependents&quot;, &quot;Telephone&quot;, &quot;Foreign_Worker&quot;)) ] head(train_data2) ## Creditability_Default Account_Balance Pmt_Status_Prev_Cred Credit_Amount ## 1 1 1 4 1049 ## 5 1 1 4 2171 ## 6 1 1 4 2241 ## 7 1 1 4 3398 ## 8 1 1 4 1361 ## 9 1 4 4 1098 ## Value_Savings_Stocks Instalment_per_cent Sex_Marital_Status ## 1 1 4 2 ## 5 1 4 3 ## 6 1 1 3 ## 7 1 1 3 ## 8 1 2 3 ## 9 1 4 2 ## Most_value_avail_asset Type_of_apartment ## 1 2 1 ## 5 2 2 ## 6 1 1 ## 7 1 2 ## 8 1 2 ## 9 3 2 test_data2 &lt;- test_data [ ,!(colnames(test_data) %in% c(&quot;Duration_Credit_Month&quot;, &quot;Purpose&quot;, &quot;Length_current_employment&quot;, &quot;Guarantors&quot;, &quot;Duration_current_address&quot;, &quot;Age_years&quot;, &quot;Concurrent_Credits&quot;, &quot;No_of_Credits_at_this_Bank&quot;, &quot;Occupation&quot;, &quot;No.of.dependents&quot;, &quot;Telephone&quot;, &quot;Foreign_Worker&quot;)) ] head(test_data2) ## Creditability_Default Account_Balance Pmt_Status_Prev_Cred ## 2 1 1 4 ## 3 1 2 2 ## 4 1 1 4 ## 10 1 2 2 ## 11 1 1 4 ## 14 1 2 3 ## Credit_Amount Value_Savings_Stocks Instalment_per_cent ## 2 2799 1 2 ## 3 841 2 2 ## 4 2122 1 3 ## 10 3758 3 1 ## 11 3905 1 2 ## 14 7582 2 2 ## Sex_Marital_Status Most_value_avail_asset Type_of_apartment ## 2 3 1 1 ## 3 2 1 1 ## 4 3 1 1 ## 10 2 4 1 ## 11 3 1 1 ## 14 3 4 2 También es posible lograr lo mismo con pipes: library(dplyr) train_data2 &lt;- train_data %&gt;% select(-Duration_Credit_Month, -Purpose, -Length_current_employment, -Guarantors, -Duration_current_address, -Age_years, -Concurrent_Credits, -No_of_Credits_at_this_Bank, -Occupation, -No.of.dependents, -Telephone, -Foreign_Worker) head(train_data2) test_data2 &lt;- test_data %&gt;% select(-Duration_Credit_Month, -Purpose, -Length_current_employment, -Guarantors, -Duration_current_address, -Age_years, -Concurrent_Credits, -No_of_Credits_at_this_Bank, -Occupation, -No.of.dependents, -Telephone, -Foreign_Worker) head(test_data2) 15.8 Generar el modelo “mejorado” Generar el modelo “mejorado” significa que se utilizan únicamente las variables de “train_data2” Nombrar el nuevo modelo (mejorado): “modelo.logit2” Mostrar el resultado (del nuevo modelo), utilizando la función summary() Observar, cuáles de las variables de entrada son estadísticamente significativas modelo.logit2 &lt;- glm(Creditability_Default ~ ., family = binomial(&quot;logit&quot;), data = train_data2) summary(modelo.logit2) ## ## Call: ## glm(formula = Creditability_Default ~ ., family = binomial(&quot;logit&quot;), ## data = train_data2) ## ## Deviance Residuals: ## Min 1Q Median 3Q Max ## -2.6394 -0.7639 0.4531 0.7399 1.6532 ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) -1.64092574 0.61302869 -2.677 0.007434 ** ## Account_Balance 0.57535672 0.08465007 6.797 0.0000000000107 *** ## Pmt_Status_Prev_Cred 0.43565319 0.09409388 4.630 0.0000036569334 *** ## Credit_Amount -0.00016829 0.00004133 -4.072 0.0000466758251 *** ## Value_Savings_Stocks 0.24777611 0.07251672 3.417 0.000634 *** ## Instalment_per_cent -0.30587299 0.09859356 -3.102 0.001920 ** ## Sex_Marital_Status 0.27629647 0.14051580 1.966 0.049264 * ## Most_value_avail_asset -0.23718647 0.10608768 -2.236 0.025368 * ## Type_of_apartment 0.54474188 0.18993701 2.868 0.004131 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 781.18 on 659 degrees of freedom ## Residual deviance: 626.78 on 651 degrees of freedom ## AIC: 644.78 ## ## Number of Fisher Scoring iterations: 5 15.9 Realizar una predicción con el modelo logit mejorado Realizar esta predicción, utilizando la función predict() y los datos de prueba “test_data2” y asignar el resultado a una variable “probs”, ya que el resultado representa probabilidades. Nota: el parámetro “type” debe ser “response” Observar el resultado, utilizando la función head() # probabilidades: probs &lt;- predict(modelo.logit2, test_data2, type = &quot;response&quot;) head(probs) ## 2 3 4 10 11 14 ## 0.7268033 0.7278048 0.6870849 0.5828999 0.6883315 0.5972874 15.10 Convertir estas probabilidades en dos clases: 1 y 0 (“buena paga” y “mala paga”) Convertir estas probabilidades en dos clases: 1 y 0, utilizando la función ifelse(), que funciona parecida a la función Si() en MS-Excel Generar una matriz de error (matriz de clasificación), utilizando la función table() con respecto a la variable de salida (variable de predicción) Interpretar los valores de esta matriz prediccion &lt;- ifelse(probs &gt; 0.5, 1, 0) table(prediccion, test_data2$Creditability_Default) ## ## prediccion 0 1 ## 0 41 22 ## 1 75 202 15.11 Ejercicio 10 Realizar una regresión logística en R, utilizando el paquete “ISLR” y el dataset “Smarket”, que viene con este paquete, para clasificar los datos del dataset con el objetivo de determinar, si el mercado (índice S&amp;P500) va a subir o bajar. Mostrar las primeras 3 filas de este dataset “Smarket” y analizar de esta forma las columnas (variables) del dataset. Nota: Las variables “Lag..” se refieren a precios determinados en el mercado de capitales (S&amp;P Stock Market Data) y refleja rendimientos diarios de este índice bursátil, expresado como porcentaje. Utilizar el comando “?Smarket” para consultar las páginas de ayuda al respecto Mostrar, la estructura de este dataset, utilizando la función str() Utilizando la semilla 123 (set.seed(123)), dividir los datos en una parte de entrenamiento (train_data) y otra parte de pruebas (test_data). 66% del total de los datos se deben utilizar para el entrenamiento y el resto para las pruebas Realizar un modelo de regresión logística con los datos de entrenamiento, utilizando como variables de entrada únicamente las variables “Lag1”, “Lag2” y “Lag3”. Asignar el resultado a una variable “modelo.logit”, Nota: En este caso no se preocupe de los valores p (p-values) obtenidos para las tres variables de entrada Mostrar el resultado de la regresión en la pantalla, utilizando la función summary() para el modelo de la regresión generada Luego, realizar la predicción para el S&amp;P500, utilizando el modelo generado y los datos de prueba (test_data) y asignar el resultado (probabilidades) a una variable “probs” Si las probabilidades son mayor que 0.5, asigna el valor “1”, en el caso contrario el valor “0” Mostrar el resultado de la clasificación en una tabla, utilizando p.ej. la función table() Interpretar el resultado obtenido "],
["normalizar.html", "Sección 16 Escalar y normalizar (estandarizar datos) 16.1 Objetivo 16.2 Cargar los datos históricos de un archivo csv 16.3 Analizar los datos de la columna “Credit.Amount” (monto del crédito) 16.4 Escalar los datos 16.5 La normalización de los datos 16.6 Escala logarítmica 16.7 Creando variables dummy (one-hot encoding) 16.8 Ejercicio 11", " Sección 16 Escalar y normalizar (estandarizar datos) 16.1 Objetivo El objetivo de esta sección consiste en explicar, cómo se pueden “escalar” y/o “normalizar” datos en R, para evitar sesgos en el análisis de estos. Además, cómo se puede crear una variable “dummy” en R (one-hot encoding). 16.2 Cargar los datos históricos de un archivo csv Vamos a utilizar un conjunto de datos de créditos de la web. Bajar el archivo de los datos de la internet y leer los datos del archivo y asignarlos a una variable “mis.datos”. url &lt;- “http://freakonometrics.free.fr/german_credit.csv” datos &lt;- read.csv(url, header = TRUE, sep = “,”) url &lt;- &quot;http://freakonometrics.free.fr/german_credit.csv&quot; datos &lt;- read.csv(url, header = TRUE, sep = &quot;,&quot;) # Estos mismos datos también se pueden bajar de la siguiente dirección: # url &lt;- &quot;https://newonlinecourses.science.psu.edu/onlinecourses/sites/stat508/files/german_credit.csv&quot; # datos &lt;- read.csv(url(direccion)) 16.3 Analizar los datos de la columna “Credit.Amount” (monto del crédito) Analizar los datos de la columna “Credit.Amount”, utilizando las funciones summary() y sd(). Esta última para determinar también la desviación estándar (standard deviation) de los datos de esta columna summary(datos$Credit.Amount) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 250 1366 2320 3271 3972 18424 sd(datos$Credit.Amount) ## [1] 2822.752 Como se puede observar en el resultado, los valores de la variable (Credit.Amount) son “dispersos”, ya que existe una diferencia “grande” entre el monto mínimo y máximo y la desviación estándar también es “alta”, lo que puede dificultar la implementación de técnicas de analítica de datos y Machine Learning. Recordar, la variable Credit.Amount se refiere a valores que representan dinero, p.ej. dólares. 16.4 Escalar los datos Escalar datos significa colocar los datos en la misma escala, generalmente, entre 0 y 1. Realizar un escalado de la variable “Credit.Amount” en un rango [0,1] de la siguiente forma y asignar el resultado a la variable datos$Credit.Amount2: x.escalada = (x - min(x)) / (max(x) - min(x)) Esto se puede lograr más facil, utilizando la función rescale() del paquete scales de R. (Nota: Esto de pronto requiere también de la instalación del paquete “lifecycle” en su equipo de cómputo) Observar las primeras seis filas de los datos de la columna Credit.Amount. Todos los valores ahora deben estar entre 0 y 1 library(scales) ## Warning: package &#39;scales&#39; was built under R version 3.5.3 ## ## Attaching package: &#39;scales&#39; ## The following object is masked from &#39;package:purrr&#39;: ## ## discard ## The following object is masked from &#39;package:readr&#39;: ## ## col_factor ?scales datos$Credit.Amount2 &lt;- rescale(datos$Credit.Amount) head(datos$Credit.Amount2) ## [1] 0.04396390 0.14025531 0.03251898 0.10300429 0.10570045 0.10955211 16.5 La normalización de los datos La normalización significa ajustar los valores medidos en diferentes escalas respecto a una escala común. El objetivo de la normalización es “eliminar” variaciones sistemáticas, conservando la señal en los datos. Se pueden normalizar únicamente columnas con datos numéricos. Realizar esta normalización para todos los datos del data frame “datos”, menos la viable de salida (aquí: Creditability) y asignar el resultado a una variable “datos2” Utilizar el paquete tidyverse (dplyr) y la función mutate_if() para realizar una prueba, si los datos son “númericos” Recordar, en “datos” solo existen datos “numéricos”, pero se debe utilizar mutate_if(). Esta función aplica de forma condicional una función. En el presente caso se trata de is.numeric(), que actúa como un filtro condicional Mostrar las primeras seis filas de “datos2” Reflexionar, si es realmente “adecuado” normalizar todas las variables de entrada, tomando en cuenta la naturaleza de los datos de este ejemplo ind &lt;- sapply(datos[,-1], is.numeric) datos[ind] &lt;- lapply(datos[ind], scale) head(datos[ind]) ## Creditability Account.Balance Duration.of.Credit..month. ## 1 0.6543263 -1.2539382 -0.2407368 ## 2 0.6543263 -1.2539382 -0.9870788 ## 3 0.6543263 -0.4587967 -0.7382981 ## 4 0.6543263 -1.2539382 -0.7382981 ## 5 0.6543263 -1.2539382 -0.7382981 ## 6 0.6543263 -1.2539382 -0.9041519 ## Payment.Status.of.Previous.Credit Purpose Credit.Amount ## 1 1.3433419 -0.301701 -0.7872630 ## 2 1.3433419 -1.030447 -0.1673006 ## 3 -0.5031762 2.248911 -0.8609500 ## 4 1.3433419 -1.030447 -0.4071375 ## 5 1.3433419 -1.030447 -0.3897785 ## 6 1.3433419 -1.030447 -0.3649800 ## Value.Savings.Stocks Length.of.current.employment Instalment.per.cent ## 1 -0.69935708 -1.1454050 0.91801781 ## 2 -0.69935708 -0.3178002 -0.86974813 ## 3 -0.06645474 0.5098045 -0.86974813 ## 4 -0.69935708 -0.3178002 0.02413484 ## 5 -0.69935708 -0.3178002 0.91801781 ## 6 -0.69935708 -1.1454050 -1.76363111 ## Sex...Marital.Status Guarantors Duration.in.Current.address ## 1 -0.9631679 -0.3035339 1.0464631 ## 2 0.4491018 -0.3035339 -0.7655942 ## 3 -0.9631679 -0.3035339 1.0464631 ## 4 0.4491018 -0.3035339 -0.7655942 ## 5 0.4491018 -0.3035339 1.0464631 ## 6 0.4491018 -0.3035339 0.1404344 ## Most.valuable.available.asset Age..years. Concurrent.Credits ## 1 -0.3408845 -1.28093214 0.4606002 ## 2 -1.2930760 0.04034293 0.4606002 ## 3 -1.2930760 -1.10476213 0.4606002 ## 4 -1.2930760 0.30459795 0.4606002 ## 5 -0.3408845 0.21651294 -2.3738626 ## 6 -1.2930760 1.09736299 0.4606002 ## Type.of.apartment No.of.Credits.at.this.Bank Occupation No.of.dependents ## 1 -1.7503294 -0.7045734 0.1468757 -0.4280754 ## 2 -1.7503294 1.0265652 0.1468757 2.3337012 ## 3 -1.7503294 -0.7045734 -1.3830794 -0.4280754 ## 4 -1.7503294 1.0265652 -1.3830794 2.3337012 ## 5 0.1358014 1.0265652 -1.3830794 -0.4280754 ## 6 -1.7503294 1.0265652 -1.3830794 2.3337012 ## Telephone Foreign.Worker Credit.Amount2 ## 1 -0.8229061 -0.1959163 -0.7872630 ## 2 -0.8229061 -0.1959163 -0.1673006 ## 3 -0.8229061 -0.1959163 -0.8609500 ## 4 -0.8229061 5.0991176 -0.4071375 ## 5 -0.8229061 5.0991176 -0.3897785 ## 6 -0.8229061 5.0991176 -0.3649800 Con tidyverse: library(tidyverse) datos.normalizados &lt;- datos[,-1] %&gt;% mutate_if(is.numeric, scale) head(datos.normalizados) 16.5.1 Comprobar el resultado Queremos comprobar, si el resultado tiene una media de 0 y una desviación estándar (sd) de 1. Utilizar la función colMeans() y sd() Observar: La media esta “cerca” de “0” y la desviación estándar es “1” para las variables Reflexionar sobre lo siguiente: Algunas variables son categóricas, aunque estas tienen valores numéricos. Sin embargo, estos valores númericos representan una categoría. ¿Este hecho afecta la normalización? colMeans(datos[ind]) # version más rápida de apply(datos[ind], 2, mean) ## Creditability Account.Balance ## 0.0000000000000001110223025 0.0000000000000000818789481 ## Duration.of.Credit..month. Payment.Status.of.Previous.Credit ## 0.0000000000000001262670524 0.0000000000000000577315973 ## Purpose Credit.Amount ## 0.0000000000000000576205750 -0.0000000000000000002445960 ## Value.Savings.Stocks Length.of.current.employment ## -0.0000000000000000052319260 0.0000000000000001142419492 ## Instalment.per.cent Sex...Marital.Status ## 0.0000000000000001482078349 0.0000000000000000872635297 ## Guarantors Duration.in.Current.address ## -0.0000000000000000522359933 -0.0000000000000001909861158 ## Most.valuable.available.asset Age..years. ## -0.0000000000000000746069873 -0.0000000000000001331712518 ## Concurrent.Credits Type.of.apartment ## 0.0000000000000002771116669 0.0000000000000001056377208 ## No.of.Credits.at.this.Bank Occupation ## -0.0000000000000000009992007 0.0000000000000001604827382 ## No.of.dependents Telephone ## -0.0000000000000001126876370 0.0000000000000001989519660 ## Foreign.Worker Credit.Amount2 ## 0.0000000000000004306832668 0.0000000000000000821183399 apply(datos[ind], 2, sd) ## Creditability Account.Balance ## 1 1 ## Duration.of.Credit..month. Payment.Status.of.Previous.Credit ## 1 1 ## Purpose Credit.Amount ## 1 1 ## Value.Savings.Stocks Length.of.current.employment ## 1 1 ## Instalment.per.cent Sex...Marital.Status ## 1 1 ## Guarantors Duration.in.Current.address ## 1 1 ## Most.valuable.available.asset Age..years. ## 1 1 ## Concurrent.Credits Type.of.apartment ## 1 1 ## No.of.Credits.at.this.Bank Occupation ## 1 1 ## No.of.dependents Telephone ## 1 1 ## Foreign.Worker Credit.Amount2 ## 1 1 16.6 Escala logarítmica La escala logarítmica informa sobre los cambios relativos (multiplicativos), mientras que la escala lineal informa sobre los cambios absolutos (aditivos). ¿Cuándo se usa cada uno? Debes usar una escala logarítmica cuando el porcentaje cambia, o el cambio, en órdenes de magnitud, es más importante que cambios en unidades absolutas. Es de resaltar, lo que constituye una “diferencia significativa” depende del orden de magnitud de los valores, p.ej. ingresos, que se analizan. En una población donde algunas personas tienen ingresos muy altos, estos datos (observaciones) se compriman en una zona relativamente pequeña de la distribución de ingresos. Es decir, si la distribución es sesgada, es una buena idea utilizar una escala logarítmica (Zumel, N., &amp; Mount, J. (2014). Practical data science with R. Manning Publications Co., véase Anexo B). Ejemplo - Bolsa de Valores. La acción A cotiza en el día 1: $ 100. En el día 2: $ 101. Normalmente, se informa este cambio de dos maneras: (1) + $ 1. (2) + 1%. El primero es una medida de cambio absoluto y aditivo, el segundo una medida de cambio relativo. (Fuente: https://stats.stackexchange.com/questions/18844/when-and-why-should-you-take-the-log-of-a-distribution-of-numbers) Ejemplo: La acción A sube de $ 1 a $ 1.10. La acción B de $ 100 a $ 110. La acción A ganó 10%, la acción B ganó 10% (escala relativa, igual), pero la acción A ganó 10 centavos, mientras que la acción B ganó $ 10 (B ganó más cantidad absoluta en dólares). Si tomamos el log, los cambios relativos aparecen como cambios absolutos. La acción A aumenta de log10 ($ 1) a log10 ($ 1.10) = 0 a .0413 La acción B aumenta de log10 ($ 100) a log10 ($ 110) = 2 a 2.0413 Ahora, tomando la diferencia absoluta en el espacio logarítmico, encontramos que ambos cambiaron en .0413. El cálculo en R para la situación A y B: # A log10(1.10) - log10(1) # 0.04139269 ## [1] 0.04139269 # B log10(110) - log10(100) # 0.04139269 ## [1] 0.04139269 16.6.1 Un ejemplo - retornos logarítmicos Bajando datos bursátiles desde yahoo con el paquete quantmod. Cargar el paquete “quantmod” Este paquete requiere que se defina un entorno (environment): new.env() library(quantmod) ?quantmod stockData &lt;- new.env() #Generar un entorno nuevo para que quantmod pueda guardar los datos en este entorno Definir una fecha de inicio y final para bajar los datos. - Utilizar como fecha final la fecha actual y como fecha de inicio la fecha final menos 30 días. startDate = Sys.Date() - 30 # o as.Date(&quot;2019-07-01&quot;) endDate = Sys.Date() Definir una lista de los tickers (empresas) para las cuales se requieren los datos. P.ej. Amazon: ticker - AMZN Descargar los datos históricos de la/s acción/es (para todos los tickers), utilizando la función getsymbols() de quantmod tickers &lt;- c(&quot;AMZN&quot;) getSymbols(tickers, env = stockData, src = &quot;yahoo&quot;, from = startDate, to = endDate) ## [1] &quot;AMZN&quot; Analizar las primeras 6 filas de estos datos ya descargados Observar la clase de los datos (class()) head(stockData$AMZN) ## AMZN.Open AMZN.High AMZN.Low AMZN.Close AMZN.Volume ## 2020-01-02 1875.00 1898.01 1864.15 1898.01 4029000 ## 2020-01-03 1864.50 1886.20 1864.50 1874.97 3764400 ## 2020-01-06 1860.00 1903.69 1860.00 1902.88 4061800 ## 2020-01-07 1904.50 1913.89 1892.04 1906.86 4044900 ## 2020-01-08 1898.04 1911.00 1886.44 1891.97 3508000 ## 2020-01-09 1909.89 1917.82 1895.80 1901.05 3167300 ## AMZN.Adjusted ## 2020-01-02 1898.01 ## 2020-01-03 1874.97 ## 2020-01-06 1902.88 ## 2020-01-07 1906.86 ## 2020-01-08 1891.97 ## 2020-01-09 1901.05 class(stockData) # environment ## [1] &quot;environment&quot; Determinar los retornos logarítmicos con base en los precios de la columna “AMZN.Close” y asignar el resultado a una variable “prices” Imprimir a la pantalla las primeras seis filas de los retornos logarítmicos calculados prices &lt;- stockData$AMZN$AMZN.Close log_returns &lt;- diff(log(prices), lag=1) head(log_returns) ## AMZN.Close ## 2020-01-02 NA ## 2020-01-03 -0.012213330 ## 2020-01-06 0.014775887 ## 2020-01-07 0.002089372 ## 2020-01-08 -0.007839303 ## 2020-01-09 0.004787792 En las finanzas es común trabajar con retornos logarítmicos. 16.7 Creando variables dummy (one-hot encoding) En situaciones, donde tenemos variables categóricas (factores), pero necesitamos usarlas en métodos analíticos que requieren números, como por ejemplo en k vecinos más cercanos (KNN) o regresión lineal, necesitamos crear variables “dummy”. Utilizar el paquete “dummies” y la función dummy() para generar una variable dummy para los datos de la columna “Type.of.apartment” del data frame “datos”, que trabajamos al inicio de esta sección, y asignar el resultado a una variable “datos$Dummy.Apartment.Type” Mostrar en la pantalla los datos para las primeras 10 filas de “datos$Dummy.Apartment.Type” Interpretar este resultado library(dummies) ## dummies-1.5.6 provided by Decision Patterns datos$Dummy.Apartment.Type &lt;- dummy(datos$Type.of.apartment) head(datos$Dummy.Apartment.Type, n = 10) ## bookdown::gitbook-1.75032943332907 ## [1,] 1 ## [2,] 1 ## [3,] 1 ## [4,] 1 ## [5,] 0 ## [6,] 1 ## [7,] 0 ## [8,] 0 ## [9,] 0 ## [10,] 1 ## bookdown::gitbook0.135801421551393 bookdown::gitbook2.02193227643185 ## [1,] 0 0 ## [2,] 0 0 ## [3,] 0 0 ## [4,] 0 0 ## [5,] 1 0 ## [6,] 0 0 ## [7,] 1 0 ## [8,] 1 0 ## [9,] 1 0 ## [10,] 0 0 Otro ejemplo: Fuente: https://stackoverflow.com/questions/11952706/generate-a-dummy-variable. Crear un data frame “df1” con 4 años: 2016 hasta 2019, que tiene una columna id: 1-4 y luego una columna con los años mencionados, utilizando la función cbind() Luego, generar las columnas con las variables dummy y sus valores, utilizando la función dummy() del paquete dummies Mostrar el resultado (de df1) en la pantalla, utilizando la función print() Es decir, el resultado se debe presentar de la siguiente forma: id year df1_2016 df1_2017 df1_2018 df1_2019 1 2016 1 0 0 0 2 2017 0 1 0 0 3 2018 0 0 1 0 4 2019 0 0 0 1 library(dummies) df1 &lt;- data.frame(id = 1:4, year = 2016:2019) df1 &lt;- cbind(df1, dummy(df1$year, sep = &quot;&quot;)) print(df1) ## id year bookdown::gitbook2016 bookdown::gitbook2017 ## 1 1 2016 1 0 ## 2 2 2017 0 1 ## 3 3 2018 0 0 ## 4 4 2019 0 0 ## bookdown::gitbook2018 bookdown::gitbook2019 ## 1 0 0 ## 2 0 0 ## 3 1 0 ## 4 0 1 16.8 Ejercicio 11 Utilizar el paquete “ISLR” y el dataset “Smarket”, que viene con este paquete, y “escalar” los datos de la columna “Lag1” de este dataset, utilizando el paquete “scales”, y asignar el resultado a una variable “Lag1.scaled” Mostrar las últimas 10 filas del resultado en la pantalla "],
["posibles-soluciones.html", "Sección 17 Posibles soluciones 17.1 Ejercicio 1 17.2 Ejercicio 2 17.3 Ejercicio 3 17.4 Ejercicio 4 17.5 Ejercicio 5 17.6 Ejercicio 6 17.7 Ejercicio 7 17.8 Ejercicio 8 17.9 Ejercicio 9 17.10 Ejercicio 10 17.11 Ejercicio 11", " Sección 17 Posibles soluciones 17.1 Ejercicio 1 17.1.1 Enunciado Utilizando R, calcular el valor presente de los siguientes flujos de caja: Año 1: -300 Año 2: +100 Año 3: +250 Tasa de descuento: 7.0% anual. 17.1.2 Posible solución a &lt;- -300 b &lt;- +100 c &lt;- +250 d &lt;- 7.0/100 # 7.0% e &lt;- (a/(1+d)^1) + (b/(1+d)^2) + (c/(1+d)^3) e # 11.04 ## [1] 11.04451 También es posible solucionar este ejercicio utilizando p.ej. el paquete “FinCal” de R, de la siguiente forma: library(FinCal) ## Warning: package &#39;FinCal&#39; was built under R version 3.5.3 ## ## Attaching package: &#39;FinCal&#39; ## The following object is masked from &#39;package:quantmod&#39;: ## ## lineChart ?npv # net present value tasa &lt;- d flujo.de.caja &lt;- c(0, a, b, c) # 0 para el año 0 f &lt;- npv(r = tasa, cf = flujo.de.caja) f ## [1] 11.04451 17.2 Ejercicio 2 17.2.1 Enunciado - parte a Crear un vector “vector1” con los números “3” y “4” y convertirlo a un data frame y asignar el resultado a una variable “data1” Mostrar el nombre de las columnas del data frame “data1” Acceder al primer elemento de este data frame (3) y mostrarlo en la pantalla 17.2.2 Posible solución vector1 &lt;- c(3,4) vector1 ## [1] 3 4 class(vector1) ## [1] &quot;numeric&quot; data1 &lt;- as.data.frame(vector1) # convierte a un data frame data1 # observe el título de la primera columna del data frame ## vector1 ## 1 3 ## 2 4 class(data1) ## [1] &quot;data.frame&quot; colnames(data1) ## [1] &quot;vector1&quot; data1[1, ] ## [1] 3 17.2.3 Enunciado - parte b Crear un vector “vector2” con los siguientes tres caracteres “3”, “4” y “5” y convertir este vector a un data frame y asignar el resultado a una variable “data2” Mostrar el resultado de la conversión, utilizando la función class() 17.2.4 Posible solución vector2 &lt;- c(&quot;3&quot;, &quot;4&quot;, &quot;5&quot;) class(vector2) ## [1] &quot;character&quot; data2 &lt;- as.data.frame(vector2) class(data2) ## [1] &quot;data.frame&quot; 17.2.5 Enunciado - parte c Ahora, convertir el contenido de este data frame “data2” (caracteres) al tipo de dato “numeric”. Es decir, convertir el contenido a tres números y asignar el resultado a una variable “data3” Mostrar el resultado de la conversión, utilizando la función class() 17.2.6 Posible solución data3 &lt;- as.numeric(data2[,1]) class(data3) ## [1] &quot;numeric&quot; data3 ## [1] 1 2 3 17.2.7 Enunciado - parte d Crear un vector “vector3” con los 6 estratos (seis categorías: 1 a 6), como se utilizan p.ej. en Colombia. Es decir, crear este vector3 de tipo de dato “factor” Convertir el contenido de este vector al tipo de dato “numeric”. Es decir, convertir el contenido a seis números y asignar el resultado a una variable “data4” Mostrar el resultado de la conversión, utilizando la función class() 17.2.8 Posible solución vector3 &lt;- as.factor(c(1:6)) class(vector3) ## [1] &quot;factor&quot; vector3 ## [1] 1 2 3 4 5 6 ## Levels: 1 2 3 4 5 6 data4 &lt;- as.numeric(vector3) class(data4) ## [1] &quot;numeric&quot; data4 ## [1] 1 2 3 4 5 6 17.2.9 Enunciado - parte e Crear un data frame “df10” con dos columnas. La primera columna “x” debe contener los datos 1, 2 y 3 y la segunda “y” los datos 4, 5 y 6. Sin embargo, los tres datos de la primera columna deben ser del tipo de dato “numeric” (numérico). Mientras los tres datos de la segunda columna deben ser del tipo de dato “factor” (categórica) Ahora convertir los valores de la segunda columna (y), del tipo de dato “factor” a “numeric” Mostrar que los valores de la segunda columna “y” ahora realmente son del tipo de dato “numeric” 17.2.10 Posible solución x &lt;- 1:3 y &lt;- as.factor(c(4:6)) df10 &lt;- data.frame(x,y) class(df10) ## [1] &quot;data.frame&quot; df10 ## x y ## 1 1 4 ## 2 2 5 ## 3 3 6 #conversión de factor a númerico #df10$y &lt;- as.numeric(df10$y) #df10 #Ojo: ¿Qué pasó aquí? # Respuesta: Si se utiliza la función as.numeric para un factor, esto convertirá los niveles a numéricos, no a los valores reales. Por lo tanto, se necesita adicionalmente la función as.character para convertir primero el factor a character y luego as.numeric df10$y &lt;- as.numeric(as.character(df10$y)) class(df10$y) ## [1] &quot;numeric&quot; df10$y ## [1] 4 5 6 17.3 Ejercicio 3 17.3.1 Enunciado Crear un archivo de tipo CSV con los siguientes datos, distribuidos en cinco filas y 4 columnas, y seperados por punto y coma (;): #;Estrato;Ingresos;Nombre 1;1;100.0;Jaime 2;2;150;María 3;2;140;Paula 4;5;90;Cristina Cargar estos datos desde el archivo csv a una variable “dataset10” en R / RStudio. Los datos de las primeras tres columnas deben ser numéricos (int o num) y de la última de tipo “character” (chr) Mostrar la estructura del “dataset10” en la pantalla Cambiar el nombre de la primera columna al texto “numero” 17.3.2 Posible solución dataset10 &lt;- read.csv(&#39;ejercicio3.csv&#39;, sep = &quot;;&quot;, header = TRUE, stringsAsFactors = FALSE) str(dataset10) ## &#39;data.frame&#39;: 4 obs. of 4 variables: ## $ X. : int 1 2 3 4 ## $ Estrato : int 1 2 2 5 ## $ Ingresos: num 100 150 140 90 ## $ Nombre : chr &quot;Jaime&quot; &quot;María&quot; &quot;Paula&quot; &quot;Cristina&quot; names(dataset10)[1] &lt;- &quot;numero&quot; str(dataset10) ## &#39;data.frame&#39;: 4 obs. of 4 variables: ## $ numero : int 1 2 3 4 ## $ Estrato : int 1 2 2 5 ## $ Ingresos: num 100 150 140 90 ## $ Nombre : chr &quot;Jaime&quot; &quot;María&quot; &quot;Paula&quot; &quot;Cristina&quot; 17.4 Ejercicio 4 17.4.1 Enunciado Analizar el paquete “DataExplorer” de R para explorar datos Cargar los datos de la siguiente forma: url=“http://freakonometrics.free.fr/german_credit.csv” dataset &lt;- read.csv(url, header = TRUE, sep = “,”) Luego, utilizar el paquete “DataExplorer”, utilizando la función “plot_str()” Visualizar los valores faltantes, utilizando una función adecuada del paquete “DataExplorer” Crear histogramas para (las variables continúas d)el “dataset”, utilizando una función adecuada del paquete “DataExplorer” Crear un data frame “dataset2”, que contiene los valores de las columnas “Age..years.” y “Credit.Amount” del dataset Visualizar las correlaciones entre los valores de las columnas “Age..years.” y “Credit.Amount” del dataset2 Aplciar la función plot_bar del paquete “DataExplorer” al dataset 17.4.2 Posible solución url=&quot;http://freakonometrics.free.fr/german_credit.csv&quot; dataset &lt;- read.csv(url, header = TRUE, sep = &quot;,&quot;) library(DataExplorer) ## Warning: package &#39;DataExplorer&#39; was built under R version 3.5.3 plot_str(dataset) plot_missing(dataset) plot_histogram(dataset) col &lt;- c(&quot;Credit.Amount&quot;, &quot;Age..years.&quot;) dataset2 &lt;- dataset[col] plot_correlation(dataset2) plot_bar(dataset) 17.5 Ejercicio 5 17.5.1 Enunciado Cargar el paquete “tidyverse” Utilizar el conjunto de datos “iris”, que se instaló con R: data(iris) Ver la siguiente descripción al respecto: https://es.wikipedia.org/wiki/Conjunto_de_datos_flor_iris Mostrar las primeras 5 filas de “iris” en la pantalla Agrupar los datos de iris por la columna “Species” y asignar el resultado a una variable “iris.por.species”, utilizando tidyverse Mostrar las últimas 3 filas de “iris.por.species” Agregar una columna a “iris.por.species”, donde se muestra el valor promedio para los valores de la columna “Sepal.Length”, utilizando tidyverse 17.5.2 Posible solución library(tidyverse) data(iris) head(iris, 5) iris.por.species &lt;- iris %&gt;% group_by(Species) tail(iris.por.species, 3) iris.por.species &lt;- iris.por.species %&gt;% summarize(promedio = mean(Sepal.Length)) tail(iris.por.species, 3) 17.6 Ejercicio 6 17.6.1 Enunciado Utilizar el conjunto de datos “iris”, que se instaló con R: data(iris) Ver la siguiente descripción al respecto: https://es.wikipedia.org/wiki/Conjunto_de_datos_flor_iris Mostrar las primeras 5 filas de “iris” en la pantalla Utilizando la función apply, calcular el promedio de cada columna del dataset “iris”, que contiene números Realizar el mismo cálculo, utilizando la función lapply (en lugar de apply()) Con base en los resultados obtenidos, explicar la diferencia entre apply y lapply Ahora bien, realizar el mismo cálculo (promedio de las columnas), pero utilizando un ciclo (bucle), aplicando la función for() 17.6.2 Posible solución data(iris) head(iris, 5) ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 1 5.1 3.5 1.4 0.2 setosa ## 2 4.9 3.0 1.4 0.2 setosa ## 3 4.7 3.2 1.3 0.2 setosa ## 4 4.6 3.1 1.5 0.2 setosa ## 5 5.0 3.6 1.4 0.2 setosa str(iris) ## &#39;data.frame&#39;: 150 obs. of 5 variables: ## $ Sepal.Length: num 5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ... ## $ Sepal.Width : num 3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ... ## $ Petal.Length: num 1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ... ## $ Petal.Width : num 0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ... ## $ Species : Factor w/ 3 levels &quot;setosa&quot;,&quot;versicolor&quot;,..: 1 1 1 1 1 1 1 1 1 1 ... apply(iris[,-5], 2, mean, na.rm=TRUE) ## Sepal.Length Sepal.Width Petal.Length Petal.Width ## 5.843333 3.057333 3.758000 1.199333 lapply(iris[,-5], mean, na.rm=TRUE) ## $Sepal.Length ## [1] 5.843333 ## ## $Sepal.Width ## [1] 3.057333 ## ## $Petal.Length ## [1] 3.758 ## ## $Petal.Width ## [1] 1.199333 Observe: lapply devuelve una lista, mientras apply devuelve un vector con los resultados Utilizando for en lugar de apply(): output &lt;- NULL # un vector vacío n &lt;- ncol(iris) # número de columnas for(i in 1:(n-1)){ output[i] &lt;- mean(iris[,i]) } print(output) ## [1] 5.843333 3.057333 3.758000 1.199333 17.7 Ejercicio 7 17.7.1 Enunciado Generar en R 15 números aleatorios, con base en una distribución uniforme, entre 1 (minimum) y 50 (máximum) y asignar el resultado a una variable “vector.aleatorio1” Luego, generar en R otros 15 numeros aleatorios, con base en una distribución normal, con una media de “0” y una desviación estándar de “1”, y asignar el resultado a una variable “vector.aleatorio2” Cobinar los valores de los 2 vectores en un único vector “vector.aleatorio3” en R / RStudio Realizar el “ajuste a la distribución”, utilizando el paquete “rriskDistributions” 17.7.2 Posible solución vector.aleatorio1 &lt;- runif(15, 1, 50) str(vector.aleatorio1) ## num [1:15] 42.43 40.52 6.75 35.92 12.53 ... vector.aleatorio2 &lt;- rnorm(15, mean = 0, sd = 1) str(vector.aleatorio2) ## num [1:15] 0.221 -0.835 -0.13 0.567 1.208 ... vector.aleatorio3 &lt;- c(vector.aleatorio1, vector.aleatorio2) str(vector.aleatorio3) ## num [1:30] 42.43 40.52 6.75 35.92 12.53 ... library(rriskDistributions) res &lt;- fit.cont(vector.aleatorio3) ## ## Begin fitting distributions --------------------------------------- ## * fitting normal distribution ... OK ## * fitting Cauchy distribution ... OK ## * fitting logistic distribution ... OK ## * fitting beta distribution ... failed ## * fitting exponential distribution ... failed ## * fitting chi-square distribution ... failed ## * fitting uniform distribution ... OK ## * fitting gamma distribution ... failed ## * fitting lognormal distribution ... failed ## * fitting Weibull distribution ... failed ## * fitting F-distribution ... failed ## * fitting Student&#39;s t-distribution ... OK ## * fitting Gompertz distribution ... failed ## * fitting triangular distribution ... failed ## End fitting distributions ----------------------------------------- ## logL AIC BIC Chisq(value) Chisq(p) AD(value) H(AD) ## Normal -123.57 251.15 253.95 86.84 0 3.17 rejected ## Cauchy -117.24 238.49 241.29 32.59 0 7.02 rejected ## Logistic -123.05 250.11 252.91 71.28 0 2.81 rejected ## Uniform NULL NULL NULL 96.09 0 Inf NULL ## Student -114.66 231.33 232.73 16.83 0 7.11 NULL ## KS(value) H(KS) ## Normal 0.24 rejected ## Cauchy 0.30 rejected ## Logistic 0.25 rejected ## Uniform 0.28 rejected ## Student 0.31 rejected ## ## Chosen continuous distribution is: Normal (norm) ## Fitted parameters are: ## mean sd ## 10.28648 14.88267 17.8 Ejercicio 8 17.8.1 Enunciado Si se requiere saber, cuántas personas de una región están dispuestas de trabajar en el extranjero, y si se puede asumir que la población de la región que trabaja o puede trabajar es de 50 mil personas, ¿qué tan grande debe ser la muestra para una encuesta que busca determinar esta disposición para trabajar en otro país? Asumimos para la generación de esta muestra que el margen de error es de 5% y el nivel de confianza requerido es de 95%. P y Q son 0.5 17.8.2 Posible solución # para poblaciones menor a 100000 muestra.n &lt;- function(N, P, Q, Z, E){ ((Z^2)*P*Q*N) / ((E^2)*(N-1)+(Z^2)*P*Q) } muestra.n(50000, 0.5, 0.5, 1.96, 0.05) ## [1] 381.2385 Respuesta: La muestra debe tener 382 personas 17.9 Ejercicio 9 17.9.1 Enunciado Realizar un árbol decisión en R, utilizando el paquete “ISLR” y el dataset “Smarket”, que viene con este paquete, para clasificar los datos del dataset con el objetivo de determinar, si el mercado (índice S&amp;P500) va a subir o bajar. Mostrar las primeras 3 filas de este dataset “Smarket” y analizar de esta forma las columnas (variables) del dataset. Nota: Las variables “Lag..” se refieren a precios determinados en el mercado de capitales (S&amp;P Stock Market Data) y refleja rendimientos diarios de este índice búrsatil, expresado como porcentaje. Utilizar el comando “?Smarket” para consultar las páginas de ayuda al respecto Mostrar, la estructura de este dataset, utilizando la función str() Utilizando la semilla 123 (set.seed(123)), dividir los datos en una parte de entrenamiento (train_data) y otra parte de pruebas (test_data). 66% del total de los datos se deben utilizar para el entrenamiento y el resto para las pruebas Analizar el paquete “C50”, que permite construir un árbol de decisión Construir un árbol de decisión sencillo con el nombre “modelo.AD”, utilizando el paquete C50 (con “C” mayúscula), la función C50() y los datos de entrenamiento Mostrar los resultados (output), utilizando la función summary() y analizarlos Realizar la predicción, utilizando el modelo construido y los datos de prueba (test_data), asignando el resultado a una variable “pred” Mostrar el resultado de la clasificación en una tabla, utilizando p.ej. la función table() Interpretar el resultado obtenido 17.9.2 Posible Solución library(ISLR) ## Warning: package &#39;ISLR&#39; was built under R version 3.5.3 head(Smarket, n=3) ## Year Lag1 Lag2 Lag3 Lag4 Lag5 Volume Today Direction ## 1 2001 0.381 -0.192 -2.624 -1.055 5.010 1.1913 0.959 Up ## 2 2001 0.959 0.381 -0.192 -2.624 -1.055 1.2965 1.032 Up ## 3 2001 1.032 0.959 0.381 -0.192 -2.624 1.4112 -0.623 Down str(Smarket) # 1250 registros y ## &#39;data.frame&#39;: 1250 obs. of 9 variables: ## $ Year : num 2001 2001 2001 2001 2001 ... ## $ Lag1 : num 0.381 0.959 1.032 -0.623 0.614 ... ## $ Lag2 : num -0.192 0.381 0.959 1.032 -0.623 ... ## $ Lag3 : num -2.624 -0.192 0.381 0.959 1.032 ... ## $ Lag4 : num -1.055 -2.624 -0.192 0.381 0.959 ... ## $ Lag5 : num 5.01 -1.055 -2.624 -0.192 0.381 ... ## $ Volume : num 1.19 1.3 1.41 1.28 1.21 ... ## $ Today : num 0.959 1.032 -0.623 0.614 0.213 ... ## $ Direction: Factor w/ 2 levels &quot;Down&quot;,&quot;Up&quot;: 2 2 1 2 2 2 1 2 2 2 ... # nota: la variable de salida (de predicción) es de tipo factor # Particionar los datos en dos partes 66/34 set.seed(123) d = sort(sample(nrow(Smarket),nrow(Smarket)*0.66, replace=FALSE)) # dividir en una conjunto de training y test set train_data &lt;- Smarket[d, ] test_data &lt;- Smarket[-d, ] library(C50) ?C5.0 # crear el árbol de decisión con los datos de entrenamiento modelo.DT &lt;- C5.0(x = train_data[, -9], y = train_data$Direction) # excluye la columna de la variable de predicción summary(modelo.DT) ## ## Call: ## C5.0.default(x = train_data[, -9], y = train_data$Direction) ## ## ## C5.0 [Release 2.07 GPL Edition] Sat Feb 01 16:05:06 2020 ## ------------------------------- ## ## Class specified by attribute `outcome&#39; ## ## Read 825 cases (9 attributes) from undefined.data ## ## Decision tree: ## ## Today &lt;= -0.001: Down (396) ## Today &gt; -0.001: Up (429) ## ## ## Evaluation on training data (825 cases): ## ## Decision Tree ## ---------------- ## Size Errors ## ## 2 0( 0.0%) &lt;&lt; ## ## ## (a) (b) &lt;-classified as ## ---- ---- ## 396 (a): class Down ## 429 (b): class Up ## ## ## Attribute usage: ## ## 100.00% Today ## ## ## Time: 0.0 secs #Realizar la predicción con los datos de prueba pred &lt;- predict(modelo.DT, test_data) # crear la matriz de clasificación library(gmodels) CrossTable(test_data$Direction, pred) ## ## ## Cell Contents ## |-------------------------| ## | N | ## | Chi-square contribution | ## | N / Row Total | ## | N / Col Total | ## | N / Table Total | ## |-------------------------| ## ## ## Total Observations in Table: 425 ## ## ## | pred ## test_data$Direction | Down | Up | Row Total | ## --------------------|-----------|-----------|-----------| ## Down | 206 | 0 | 206 | ## | 112.849 | 106.151 | | ## | 1.000 | 0.000 | 0.485 | ## | 1.000 | 0.000 | | ## | 0.485 | 0.000 | | ## --------------------|-----------|-----------|-----------| ## Up | 0 | 219 | 219 | ## | 106.151 | 99.849 | | ## | 0.000 | 1.000 | 0.515 | ## | 0.000 | 1.000 | | ## | 0.000 | 0.515 | | ## --------------------|-----------|-----------|-----------| ## Column Total | 206 | 219 | 425 | ## | 0.485 | 0.515 | | ## --------------------|-----------|-----------|-----------| ## ## #Alternativa table(test_data$Direction, pred) ## pred ## Down Up ## Down 206 0 ## Up 0 219 Respuesta: Todo el modelo está dominado por la variable “today”. Por favor, revisarlo. 17.10 Ejercicio 10 17.10.1 Enunciado Realizar una regresión logística en R, utilizando el paquete “ISLR” y el dataset “Smarket”, que viene con este paquete, para clasificar los datos del dataset con el objetivo de determinar, si el mercado (índice S&amp;P500) va a subir o bajar. Mostrar las primeras 3 filas de este dataset “Smarket” y analizar de esta forma las columnas (variables) del dataset. Nota: Las variables “Lag..” se refieren a precios determinados en el mercado de capitales (S&amp;P Stock Market Data) y refleja rendimientos diarios de este índice búrsatil, expresado como porcentaje. Utilizar el comando “?Smarket” para consultar las páginas de ayuda al respecto Mostrar, la estructura de este dataset, utilizando la función str() Utilizando la semilla 123 (set.seed(123)), dividir los datos en una parte de entrenamiento (train_data) y otra parte de pruebas (test_data). 66% del total de los datos se deben utilizar para el entrenamiento y el resto para las pruebas Realizar un modelo de regresión logística con los datos de entrenamiento, utilizando como variables de entrada únicamente las variables “Lag1”, “Lag2” y “Lag3”. Asignar el resultado a una variable “modelo.logit”, Nota: En este caso no se preocupe de los valores p (p-values) obtenidos para las tres variables de entrada Mostrar el resultado de la regresión en la pantalla, utilizando la función summary() para el modelo de la regresión generada Luego, realizar la predicción para el S&amp;P500, utilizando el modelo generado y los datos de prueba (test_data) y asignar el resultado (probabilidades) a una variable “probs” Si las probabilidades son mayores que 0.5, asignar el valor “1”, en el caso contrario el valor “0” Mostrar el resultado de la clasificación en una tabla, utilizando p.ej. la función table() Interpretar el resultado obtenido 17.10.2 Posible solución library(ISLR) head(Smarket) ## Year Lag1 Lag2 Lag3 Lag4 Lag5 Volume Today Direction ## 1 2001 0.381 -0.192 -2.624 -1.055 5.010 1.1913 0.959 Up ## 2 2001 0.959 0.381 -0.192 -2.624 -1.055 1.2965 1.032 Up ## 3 2001 1.032 0.959 0.381 -0.192 -2.624 1.4112 -0.623 Down ## 4 2001 -0.623 1.032 0.959 0.381 -0.192 1.2760 0.614 Up ## 5 2001 0.614 -0.623 1.032 0.959 0.381 1.2057 0.213 Up ## 6 2001 0.213 0.614 -0.623 1.032 0.959 1.3491 1.392 Up str(Smarket) # 1250 registros ## &#39;data.frame&#39;: 1250 obs. of 9 variables: ## $ Year : num 2001 2001 2001 2001 2001 ... ## $ Lag1 : num 0.381 0.959 1.032 -0.623 0.614 ... ## $ Lag2 : num -0.192 0.381 0.959 1.032 -0.623 ... ## $ Lag3 : num -2.624 -0.192 0.381 0.959 1.032 ... ## $ Lag4 : num -1.055 -2.624 -0.192 0.381 0.959 ... ## $ Lag5 : num 5.01 -1.055 -2.624 -0.192 0.381 ... ## $ Volume : num 1.19 1.3 1.41 1.28 1.21 ... ## $ Today : num 0.959 1.032 -0.623 0.614 0.213 ... ## $ Direction: Factor w/ 2 levels &quot;Down&quot;,&quot;Up&quot;: 2 2 1 2 2 2 1 2 2 2 ... set.seed(123) d = sort(sample(nrow(Smarket),nrow(Smarket)*0.66, replace=FALSE)) # dividir en una conjunto de training y test set train_data &lt;- Smarket[d, ] test_data &lt;- Smarket[-d, ] modelo.logit &lt;- glm(Direction ~ Lag1 + Lag2 + Lag3, family = binomial(&quot;logit&quot;), data =train_data) summary(modelo.logit) ## ## Call: ## glm(formula = Direction ~ Lag1 + Lag2 + Lag3, family = binomial(&quot;logit&quot;), ## data = train_data) ## ## Deviance Residuals: ## Min 1Q Median 3Q Max ## -1.463 -1.203 1.039 1.140 1.465 ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) 0.08448 0.06997 1.207 0.2273 ## Lag1 -0.12569 0.06256 -2.009 0.0445 * ## Lag2 -0.02529 0.05985 -0.423 0.6726 ## Lag3 0.02817 0.06108 0.461 0.6447 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 1142.4 on 824 degrees of freedom ## Residual deviance: 1137.9 on 821 degrees of freedom ## AIC: 1145.9 ## ## Number of Fisher Scoring iterations: 3 # probabilidades: probs &lt;- predict(modelo.logit, test_data, type = &quot;response&quot;) head(probs) ## 3 5 6 10 11 14 ## 0.4853155 0.5130299 0.5061573 0.4771843 0.5040527 0.4974412 prediccion &lt;- ifelse(probs &gt; 0.5, 1, 0) table(prediccion, test_data$Direction) ## ## prediccion Down Up ## 0 46 53 ## 1 160 166 mean(prediccion) # [1] 0.7670588 ## [1] 0.7670588 Conclusión: El modelo comete muchos errores. 17.11 Ejercicio 11 17.11.1 Enunciado Utilizar el paquete “ISLR” y el dataset “Smarket”, que viene con este paquete, y “escalar” los datos de la columna “Lag1” de este dataset, utilizando el paquete “scales”, y asignar el resultado a una variable “Lag1.scaled” Mostrar las últimas 10 filas del resultado en la pantalla 17.11.2 Posible solución library(ISLR) head(Smarket) ## Year Lag1 Lag2 Lag3 Lag4 Lag5 Volume Today Direction ## 1 2001 0.381 -0.192 -2.624 -1.055 5.010 1.1913 0.959 Up ## 2 2001 0.959 0.381 -0.192 -2.624 -1.055 1.2965 1.032 Up ## 3 2001 1.032 0.959 0.381 -0.192 -2.624 1.4112 -0.623 Down ## 4 2001 -0.623 1.032 0.959 0.381 -0.192 1.2760 0.614 Up ## 5 2001 0.614 -0.623 1.032 0.959 0.381 1.2057 0.213 Up ## 6 2001 0.213 0.614 -0.623 1.032 0.959 1.3491 1.392 Up str(Smarket) # 1250 registros ## &#39;data.frame&#39;: 1250 obs. of 9 variables: ## $ Year : num 2001 2001 2001 2001 2001 ... ## $ Lag1 : num 0.381 0.959 1.032 -0.623 0.614 ... ## $ Lag2 : num -0.192 0.381 0.959 1.032 -0.623 ... ## $ Lag3 : num -2.624 -0.192 0.381 0.959 1.032 ... ## $ Lag4 : num -1.055 -2.624 -0.192 0.381 0.959 ... ## $ Lag5 : num 5.01 -1.055 -2.624 -0.192 0.381 ... ## $ Volume : num 1.19 1.3 1.41 1.28 1.21 ... ## $ Today : num 0.959 1.032 -0.623 0.614 0.213 ... ## $ Direction: Factor w/ 2 levels &quot;Down&quot;,&quot;Up&quot;: 2 2 1 2 2 2 1 2 2 2 ... library(scales) Lag1.scaled &lt;- scale(Smarket$Lag1) tail(Lag1.scaled, n=10) ## [,1] ## [1241,] -0.12746154 ## [1242,] -0.25418877 ## [1243,] -0.51732377 ## [1244,] -0.02449567 ## [1245,] 0.21839818 ## [1246,] 0.36800671 ## [1247,] 0.03446769 ## [1248,] -0.84382238 ## [1249,] 0.11103206 ## [1250,] -0.26562942 `r if (knitr:::is_html_output()) ‘# Bibliografía {-}’ "],
["palabras-finales.html", "Sección 18 Palabras finales", " Sección 18 Palabras finales Terminamos una breve introducción a R con un enfoque financiero y adminstrativo, presentando ejemplos de código al respecto. Ojála, el contenido del librito sea una “ayuada” para aumentar su “productividad”. "]
]
