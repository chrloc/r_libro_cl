[["index.html", "Una breve introducción a R con un enfoque financiero y administrativo Sección 1 Prerequisitos", " Una breve introducción a R con un enfoque financiero y administrativo Christian Lochmuller 2019, actualizado 2022-01-31 Sección 1 Prerequisitos Los prerequisitos incluyen: Conocimientos en términos de los fundamentos de la programación. Bajar e installar el lenguaje de programación R (gratuito): https://www.r-project.org/ Bajar e instalar el IDE RStudio Desktop (gratuito): https://www.rstudio.com/products/rstudio/download/ Motivación para aprender sobre la programación con R y capacidad de aprender a aprender. También es pertinente señalar, que en la nube esta disponible una versión de R / RStudio: https://rstudio.cloud/. Sin embargo, aquí trabaremos con la versión desktop. Según Wikipedia, R es un entorno y lenguaje de programación con un enfoque al análisis estadístico. Según esta misma fuente, R proporciona un amplio abanico de herramientas estadísticas, principalmente en términos de modelos lineales y no lineales, tests estadísticos, análisis de series temporales, algoritmos de clasificación y agrupamiento, etc. R permite también graficar datos en alta calidad. Los usuarios pueden publicar paquetes que extiendan la funcionalidad básica de R. Para mencionar solo un ejemplo, existen paquetes (librerias), que ofrecen funcionalidad avanzada, relacionada con las redes neuronales, ampliando de esta forma la funcionalidad básica disponible. Esto significa, que se puedan desarrollar aplicaciones nuevas basadas en estos paquetes, que faciliten y mejoren estos paquetes de forma libre y continua, literalmente construyendo sobre los hombros de otros gigantes. En la actualidad R no solo ofrece funcionalidad con respecto a operaciones estadísticas, sino también con respecto a nuevos desarrollos como p.ej. el aprendizaje de maquina, la inteligencia artifical y el aprendizaje profundo, también con aplicación financiera. Los paquetes están disponibles, en su gran mayoría, en un repositorio abierto: https://cran.r-project.org/web/packages/, y éstos se pueden bajar libremente a través de la Internet, respetando la licencia de R y RStudio. ¡Bienvenidos a esta breve introducción al lenguaje R con un enfoque y ejemplos financieros y administrativos! "],["intro.html", "Sección 2 Introducción 2.1 Objetivo 2.2 Usar R como calculadora 2.3 Asignar un valor numérico a una variable 2.4 Buscar ayuda 2.5 Organizar el código 2.6 Una opción para explorar: Swirl 2.7 Ejercicio 1", " Sección 2 Introducción 2.1 Objetivo El objetivo de esta sección es introducir al lenguaje R, como utilizarla como calculadora, como organizar el código, etc. 2.2 Usar R como calculadora R, como otros lenguajes de programación, se puede utilizar como una calculadora. Esto se muestra a continuación, utilizando algunas operaciones matemáticas comunes como ejemplo. Nota: Orden de evaluación. PEMDAS mnemonic: Please Excuse My Dear Aunt Sally. Parentheses, Exponents, Multiplication/Division, Addition/Subtraction 1+1 # 2 ## [1] 2 3 * 4 * 2 # 24 ## [1] 24 6 / 2 # 3 ## [1] 3 8 / 3 # 2.666667 ## [1] 2.666667 3 * 4 + 5 # 17 ## [1] 17 3 * (4 + 5) # 27 ## [1] 27 2.3 Asignar un valor numérico a una variable A continuación, se presentan algunos ejemplos al respecto: Asignar el valor 2 a la variable x Imprimir el valor de la variable x a la consola Asignar el valor 5 a la variable b, asignar el valor de b a la variable a Mostrar los valores de b y a Mostrar la clase del objeto (variable) a Observe, el comando para asignar un valor a una variable (objeto) es: &lt;- (ALT + -) x &lt;- 2 x ## [1] 2 a &lt;- b &lt;- 5 b ## [1] 5 a ## [1] 5 class(a) ## [1] &quot;numeric&quot; 2.4 Buscar ayuda F1 ?+ nombre de la función o del paquete help(), p.ej.: help(lm) 2.4.1 Un ejemplo La página de ayuda para el paquete quandmod, que tenemos que cargar pimero. Si faltan otros paquetes, se muestra en la consola un posible mensaje de error, y se deben instalar estos paquetes faltantes antes de realizar este ejemplo. library(quantmod) ## Loading required package: xts ## Loading required package: zoo ## ## Attaching package: &#39;zoo&#39; ## The following objects are masked from &#39;package:base&#39;: ## ## as.Date, as.Date.numeric ## Loading required package: TTR ## Registered S3 method overwritten by &#39;quantmod&#39;: ## method from ## as.zoo.data.frame zoo ?quantmod ## starting httpd help server ... ## done 2.5 Organizar el código Se recomienda, explorar el siguiente contenido (style guides) para aprender sobre como organizar el código para facilitar su lectura y comprensión: Google: https://google.github.io/styleguide/Rguide.html Tidyverse: https://style.tidyverse.org/ 2.6 Una opción para explorar: Swirl Un paquete para ayudar en el proceso de aprender R. https://swirlstats.com/students.html 2.7 Ejercicio 1 Utilizando R, calcular el valor presente de los siguientes flujos de caja: Año 1: -300 Año 2: +100 Año 3: +250 Tasa de descuento: 7.0% anual. "],["tipos.html", "Sección 3 Usar tipos de datos 3.1 Objetivo 3.2 Datos booleanos y operadores de lógica 3.3 Tipo de dato fecha 3.4 Tipo de dato vector 3.5 Vectores de carácteres (strings) 3.6 Acceder a elementos de un vector 3.7 Factors (variables categóricas) 3.8 Funciones matemáticas para vectores 3.9 Usar pipes (un concepto interesante) 3.10 Data frames 3.11 Listas 3.12 Ejercicio 2", " Sección 3 Usar tipos de datos 3.1 Objetivo A continuación, se presenta información sobre diferentes tipos de datos, que ofrece R, y como manipularlos. 3.2 Datos booleanos y operadores de lógica Estos operadores devuelven el valor TRUE (verdadero) o FALSE (falso). A continuación, se muestran algunos ejemplos. Dónde: TRUE = 1 y FALSE = 0. TRUE * 2 ## [1] 2 FALSE * 2 ## [1] 0 d &lt;- TRUE d ## [1] TRUE is.logical(d) ## [1] TRUE class(d) ## [1] &quot;logical&quot; # ¿2 es igual a 3? 2 == 3 ## [1] FALSE # ¿2 no es igual a 3? 2 != 3 ## [1] TRUE 2 &lt;= 3 ## [1] TRUE 2 &gt;= 3 ## [1] FALSE # &quot;¿datos&quot; es igual a &quot;info&quot;? &quot;datos&quot; == &quot;info&quot; ## [1] FALSE &quot;datos&quot; &lt; &quot;info&quot; ## [1] TRUE 3.3 Tipo de dato fecha La función as.Date() vs. la función as.POSIXct(): Convertir el siguiente string 2014-06-08 en una fecha con el nombre (de la variable) fecha1 (notación angloamericana: YYYY-MM-DD) Mostrar esta fecha fecha1 en la pantalla Mostrar la clase de la variable fecha1, utilizando el comando class() Convertir esta variable fecha1 a un número Mostrar este número en la pantalla y dar una interpretación de este número Convertir el siguiente string 2014-06-08 17:42 en una fecha con el nombre (de la variable) fecha2 (notación de tipo time stamp: YYYY-MM-DD hh:mm) Mostrar esta fecha fecha2 en la pantalla Mostrar la clase de la variable fecha2, utilizando el comando class() Convertir esta variable fecha2 a un número Mostrar este número en la pantalla y dar una interpretación de este número fecha1 &lt;- as.Date(&quot;2014-06-08&quot;) fecha1 ## [1] &quot;2014-06-08&quot; class(fecha1) ## [1] &quot;Date&quot; as.numeric(fecha1) # convertir una fecha a tipo de dato &quot;numérico&quot; devuelve la cantidad de días desde 1970 ## [1] 16229 fecha2 &lt;- as.POSIXct(&quot;2014-06-08 17:42&quot;) fecha2 ## [1] &quot;2014-06-08 17:42:00 -05&quot; class(fecha2) ## [1] &quot;POSIXct&quot; &quot;POSIXt&quot; as.numeric(fecha2) # devuelve la cantidad de segundos desde 1970 ## [1] 1402267320 Una manipulación más fácil de las fechas se puede lograr utilizando el paquete lubridate y el paquete chron de R. 3.4 Tipo de dato vector Crear un vector numérico x, que contiene los números 1 hasta 10 Mostrar el contenido del vector x en la pantalla Crear un vector numérico y, que contiene los números 11 hasta 1 Mostrar el contenido del vector y en la pantalla Multiplicar el contenido del vector x por 2 y mostrar el resultado en la pantalla Luego, agregar 2 al contenido del vector x y mostrar el resultado en la pantalla Después, restar 3 del contenido del vector x y mostrar el resultado en la pantalla Dividir el contenido del vector x por 4 y mostrar el resultado en la pantalla Llevar el contenido del vector x a la 2 y mostrar el resultado en la pantalla Calcular la raíz cuadrada del contenido del vector x y mostrar el resultado en la pantalla x &lt;- c (1, 2, 3, 4, 5, 6, 7, 8, 9, 10) x ## [1] 1 2 3 4 5 6 7 8 9 10 y &lt;- 11:1 y ## [1] 11 10 9 8 7 6 5 4 3 2 1 x * 2 ## [1] 2 4 6 8 10 12 14 16 18 20 x + 2 ## [1] 3 4 5 6 7 8 9 10 11 12 x - 3 ## [1] -2 -1 0 1 2 3 4 5 6 7 x / 4 ## [1] 0.25 0.50 0.75 1.00 1.25 1.50 1.75 2.00 2.25 2.50 x^2 ## [1] 1 4 9 16 25 36 49 64 81 100 sqrt(x) ## [1] 1.000000 1.414214 1.732051 2.000000 2.236068 2.449490 2.645751 2.828427 ## [9] 3.000000 3.162278 Crear un vector numérico x con los números 1 a 10 Luego, crear un vector y con números desde -5 hasta +4 Sumar el contenido del vector x con el contenido del vector y Determinar la longitud del vector x Determinar la longitud del vector y ¿Cuál es la longitud de la suma de los vectores x y y? ¿Qué pasa, si se suman vectores de una longitud diferente, p.ej.: x + c(1,2), donde c(1,2) genera un vector con los números 1 y 2? ¿Cuál es la longitud del resultado (length(x + c(1,2)) ? ¿Qué pasa, si un vector no es un múltiple del otro, en términos de su longitud: x + c(1,2,3)? x &lt;- 1:10 y &lt;- -5:4 x + y ## [1] -4 -2 0 2 4 6 8 10 12 14 length(x) ## [1] 10 length(y) ## [1] 10 length(x + y) #10 ## [1] 10 # Ojo: # El vector más corto se recicla. # Esto significa que sus elementos se repiten hasta # existe coincidencia con cada elemento del vector más largo. x + c(1, 2) ## [1] 2 4 4 6 6 8 8 10 10 12 length(x + c(1, 2)) ## [1] 10 x + c(1, 2, 3) # termina con una advertencia (warning) ## Warning in x + c(1, 2, 3): longitud de objeto mayor no es múltiplo de la ## longitud de uno menor ## [1] 2 4 6 5 7 9 8 10 12 11 x &lt;= 5 ## [1] TRUE TRUE TRUE TRUE TRUE FALSE FALSE FALSE FALSE FALSE 3.5 Vectores de carácteres (strings) Un ejemplo con diferentes frutas como elementos de un solo vector q. Crear un vector q con los siguientes 10 elementos: Manzana, Pera, Piña, Naranja, Mandarina, Banano, Durazno, Uva, Fresa, Melocotón. Determinar para q el número de caracteres de cada elemento del vector, utilizando la función nchar() q &lt;- c(&quot;Manzana&quot;, &quot;Pera&quot;, &quot;Piña&quot;, &quot;Naranja&quot;, &quot;Mandarina&quot;, &quot;Banano&quot;, &quot;Durazno&quot;, &quot;Uva&quot;, &quot;Fresa&quot;, &quot;Melocotón&quot;) nchar(q) ## [1] 7 4 4 7 9 6 7 3 5 9 3.6 Acceder a elementos de un vector Utilicaremos el vector x anteriormente creado, que contiene los números 1 hasta 10 Imprimir el contenido del vector x a la pantalla (consola) Acceder al primer elemento del vector x, utilizando la notación de corchetes Acceder a todos los elementos del vector x menos el primero Acceder al primer y cuarto elemento del vector x únicamente Acceder a los primeros tres elementos del vector x únicamente x ## [1] 1 2 3 4 5 6 7 8 9 10 x[1] # primer elemento ## [1] 1 x[-1] # todos los elementos del vector menos el primer elemento ## [1] 2 3 4 5 6 7 8 9 10 x[c(1, 4)] # el primer elemento y el cuarto elemento ## [1] 1 4 x[1:3] # los primeros tres elementos ## [1] 1 2 3 Proveer un nombre para cada elemento del vector, utilizando una pareja de tipo nombre-valor. Crear un vector con las siguientes parejas de tipo nombre-valor: Uno: a; Dos: f; Tres: m Crear un vector v con los números 1 hasta 3 Asignar como nombre a los tres elementos de v las letras a, b y c, utilizando la función names() e Imprimir el contenido de v a la pantalla c(Uno=&quot;a&quot;, Dos=&quot;f&quot;, Tres=&quot;m&quot;) ## Uno Dos Tres ## &quot;a&quot; &quot;f&quot; &quot;m&quot; v &lt;- 1:3 names(v) &lt;-c(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;) v ## a b c ## 1 2 3 3.7 Factors (variables categóricas) Utilicaremos el vector q anteriormente creado, que contiene los 10 nombres de frutas diferentes. Crear un nuevo vector q2 con los siguientes elementos: q (es decir el vector ya creado), Manzana, Piña, Pera, Melocotón, Manzana, Pera Determinar la longitud de q2, utilizando la función length() Convertir q2 al tipo de dato factor (es decir, a una variable categórica) y asignar el resultado a una variable q2Factor Imprimir q2Factor a la pantalla Determinar la clase del objeto q2Factor q2 &lt;-c(q, &quot;Manzana&quot;, &quot;Piña&quot;, &quot;Pera&quot;, &quot;Melocotón&quot;, &quot;Manzana&quot;, &quot;Pera&quot;) length(q2) ## [1] 16 q2Factor &lt;- as.factor(q2) q2Factor ## [1] Manzana Pera Piña Naranja Mandarina Banano Durazno ## [8] Uva Fresa Melocotón Manzana Piña Pera Melocotón ## [15] Manzana Pera ## 10 Levels: Banano Durazno Fresa Mandarina Manzana Melocotón Naranja ... Uva class(q2Factor) ## [1] &quot;factor&quot; 3.8 Funciones matemáticas para vectores Utilicaremos el vector x anteriormente creado, que contiene los números 1 hasta 10 Determinar el promedio de los valores del vector x Consultar todas funciones que contienen la secuencia de letra mea, incluyendo p.ej. mean, utilizando la función apropos() Generar un vector z con los siguientes 7 elementos: 1, 2, NA, 8, 3, NA, 3. Donde NA representa un dato faltante Generar un vector zChar con los siguientes 3 elementos: Manzana, NA, Pera Realizar una prueba (de tipo booleana), si los vectores z y zChar contienen elementos NA, utilizando la función is.na() Determinar el promedio para los valores del vector z Crear el vector p con los siguientes elementos: 1, NULL, 3 Imprimir p a la pantalla Determinar la longitud de p Asignar el valor NULL a una variable d Realizar una prueba (de tipo booleana), si d es nulo, utilizando la función is.null() mean(x) # el promedio ## [1] 5.5 apropos(&quot;mea&quot;) ## [1] &quot;.colMeans&quot; &quot;.rowMeans&quot; &quot;colMeans&quot; ## [4] &quot;influence.measures&quot; &quot;kmeans&quot; &quot;mean&quot; ## [7] &quot;mean.Date&quot; &quot;mean.default&quot; &quot;mean.difftime&quot; ## [10] &quot;mean.POSIXct&quot; &quot;mean.POSIXlt&quot; &quot;rollmean&quot; ## [13] &quot;rollmean.default&quot; &quot;rollmeanr&quot; &quot;rowMeans&quot; ## [16] &quot;runMean&quot; &quot;weighted.mean&quot; z &lt;- c(1, 2, NA, 8, 3, NA, 3) zChar &lt;- c(&quot;Manzana&quot;, NA, &quot;Pera&quot;) is.na(z) ## [1] FALSE FALSE TRUE FALSE FALSE TRUE FALSE is.na(zChar) ## [1] FALSE TRUE FALSE mean(z) ## [1] NA mean(z, na.rm=TRUE) # #remover los datos faltantes primero, utilizando el parametro na.rm=TRUE ## [1] 3.4 p &lt;- c(1, NULL,3) p ## [1] 1 3 length(p) # es decir el valor nulo, NULL, no se almacena en &quot;p&quot; ## [1] 2 d &lt;- NULL is.null(d) ## [1] TRUE 3.9 Usar pipes (un concepto interesante) Nota: Pipe significa then, es decir entonces. Un pipe se lea desde la izquierda hacia la derecha. Instalar y cargar el paquete magrittr, que se requiere para aplicar los pipes, utilizando install.packages(magrittr, dependencies=TRUE) y luego library(magrittr) Determinar el promedio de x, donde x es un vector de números de 1 a 10 (ya hemos hecho este cálculo) Luego, realizar este mismo cálculo utilizando el operador pipe (%&gt;%), que se puede producir in RStudio así: CTRL + SHIFT + m Generar un vector z con los siguientes elementos: 1, 2, NA, 8, 3, NA, 3 Determinar la suma de los elementos NA en z Luego, realizar este mismo cálculo utilizando el operador pipe (%&gt;%) library(tidyverse) # para utilizar p.ej. pipes ## Warning in (function (kind = NULL, normal.kind = NULL, sample.kind = NULL) : ## non-uniform &#39;Rounding&#39; sampler used ## -- Attaching packages --------------------------------------- tidyverse 1.3.1 -- ## v ggplot2 3.3.5 v purrr 0.3.4 ## v tibble 3.1.2 v dplyr 1.0.7 ## v tidyr 1.1.3 v stringr 1.4.0 ## v readr 2.0.0 v forcats 0.5.1 ## Warning in (function (kind = NULL, normal.kind = NULL, sample.kind = NULL) : ## non-uniform &#39;Rounding&#39; sampler used ## -- Conflicts ------------------------------------------ tidyverse_conflicts() -- ## x dplyr::filter() masks stats::filter() ## x dplyr::first() masks xts::first() ## x dplyr::lag() masks stats::lag() ## x dplyr::last() masks xts::last() mean(x) ## [1] 5.5 x %&gt;% mean(.) ## [1] 5.5 z &lt;- c(1, 2, NA, 8, 3, NA, 3) sum(is.na(z)) ## [1] 2 z %&gt;% is.na %&gt;% sum(.) ## [1] 2 3.10 Data frames El data frame es un tipo de dato muy común y además un tipo de dato muy útil, que organiza los datos en filas y columnas. El data frame es parecido a una hoja de cálculo en MS-Excel Crear un vector x con los números de 10 a 1 Crear un vector y con los números de -4 a 5 Crear un vector q con los siguientes elementos (frutas): Manzana, Pera, Piña, Naranja, Mandarina, Banano, Durazno, Uva, Fresa, Melocotón Generar un data frame df, que contiene x, y y q. Es decir, los 3 vectores, donde cada vector conforma una columna en el data frame df Imprimir el contenido del data frame df a la pantalla x &lt;- 10:1 y &lt;- -4:5 q &lt;- c(&quot;Manzana&quot;, &quot;Pera&quot;, &quot;Piña&quot;, &quot;Naranja&quot;, &quot;Mandarina&quot;, &quot;Banano&quot;, &quot;Durazno&quot;, &quot;Uva&quot;, &quot;Fresa&quot;, &quot;Melocotón&quot;) df &lt;- data.frame(x, y, q) df ## x y q ## 1 10 -4 Manzana ## 2 9 -3 Pera ## 3 8 -2 Piña ## 4 7 -1 Naranja ## 5 6 0 Mandarina ## 6 5 1 Banano ## 7 4 2 Durazno ## 8 3 3 Uva ## 9 2 4 Fresa ## 10 1 5 Melocotón También hubiera sido posible, asignar nombres (para las columnas) en el proceso de generar el data frame, lo que normalmente es una buena idea. Primero=x, Segundo=y, Fruta=q df &lt;- data.frame(Primero=x, Segundo=y, Fruta=q) df ## Primero Segundo Fruta ## 1 10 -4 Manzana ## 2 9 -3 Pera ## 3 8 -2 Piña ## 4 7 -1 Naranja ## 5 6 0 Mandarina ## 6 5 1 Banano ## 7 4 2 Durazno ## 8 3 3 Uva ## 9 2 4 Fresa ## 10 1 5 Melocotón Determinar la cantidad de filas, que tiene el data frame df Determinar la cantidad de columnas, que tiene el data frame df Determinar las dimensiones (cantidad de filas y columnes) del data frame df Mostrar los nombres de las filas del data frame df Mostrar los nombres de las columnas del data frame df Asignar como nombres de las filas las siguientes etiquetas (nombres): Uno, Dos, Tres, Cuatro, Cinco, Seis, Siete, Ocho, Nueve, Diez. Mostrar los nombres de las filas del data frame df nrow(df) ## [1] 10 ncol(df) ## [1] 3 dim(df) ## [1] 10 3 names(df) ## [1] &quot;Primero&quot; &quot;Segundo&quot; &quot;Fruta&quot; rownames(df) ## [1] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; &quot;5&quot; &quot;6&quot; &quot;7&quot; &quot;8&quot; &quot;9&quot; &quot;10&quot; colnames(df) ## [1] &quot;Primero&quot; &quot;Segundo&quot; &quot;Fruta&quot; rownames(df) &lt;- c(&quot;Uno&quot;, &quot;Dos&quot;, &quot;Tres&quot;, &quot;Cuatro&quot;, &quot;Cinco&quot;, &quot;Seis&quot;, &quot;Siete&quot;, &quot;Ocho&quot;, &quot;Nueve&quot;, &quot;Diez&quot;) rownames(df) ## [1] &quot;Uno&quot; &quot;Dos&quot; &quot;Tres&quot; &quot;Cuatro&quot; &quot;Cinco&quot; &quot;Seis&quot; &quot;Siete&quot; &quot;Ocho&quot; ## [9] &quot;Nueve&quot; &quot;Diez&quot; Cambiar los nombres de las filas nuevamente a los valores iniciales. Es decir, al indice genérico. Mostrar los nombres de las filas del data frame df Mostrar las primeras 6 filas del data frame df Mostrar las primeras 8 filas del data frame df Mostrar las últimas 6 filas del data frame df Mostrar la clase del objeto (data frame) df rownames(df) &lt;- NULL rownames(df) ## [1] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; &quot;5&quot; &quot;6&quot; &quot;7&quot; &quot;8&quot; &quot;9&quot; &quot;10&quot; head(df) # las primeras 6 filas ## Primero Segundo Fruta ## 1 10 -4 Manzana ## 2 9 -3 Pera ## 3 8 -2 Piña ## 4 7 -1 Naranja ## 5 6 0 Mandarina ## 6 5 1 Banano head(df, 8) # las primeras 8 filas ## Primero Segundo Fruta ## 1 10 -4 Manzana ## 2 9 -3 Pera ## 3 8 -2 Piña ## 4 7 -1 Naranja ## 5 6 0 Mandarina ## 6 5 1 Banano ## 7 4 2 Durazno ## 8 3 3 Uva tail(df) ## Primero Segundo Fruta ## 5 6 0 Mandarina ## 6 5 1 Banano ## 7 4 2 Durazno ## 8 3 3 Uva ## 9 2 4 Fresa ## 10 1 5 Melocotón class(df) ## [1] &quot;data.frame&quot; Acceder a todos los datos de la columna Fruta del data frame df Acceder al elemento en la tercera fila y segunda columna del data frame df Mostrar los elementos en la tercera fila, en la columna 2 y 3 del data frame df Determinar la clase de los elementos (datos) en la columna Fruta del data frame df df$Fruta ## [1] &quot;Manzana&quot; &quot;Pera&quot; &quot;Piña&quot; &quot;Naranja&quot; &quot;Mandarina&quot; &quot;Banano&quot; ## [7] &quot;Durazno&quot; &quot;Uva&quot; &quot;Fresa&quot; &quot;Melocotón&quot; #...entrega el mismo resultado: df[, 3] # todos los datos de la columna 3 ## [1] &quot;Manzana&quot; &quot;Pera&quot; &quot;Piña&quot; &quot;Naranja&quot; &quot;Mandarina&quot; &quot;Banano&quot; ## [7] &quot;Durazno&quot; &quot;Uva&quot; &quot;Fresa&quot; &quot;Melocotón&quot; df[,&quot;Fruta&quot;] ## [1] &quot;Manzana&quot; &quot;Pera&quot; &quot;Piña&quot; &quot;Naranja&quot; &quot;Mandarina&quot; &quot;Banano&quot; ## [7] &quot;Durazno&quot; &quot;Uva&quot; &quot;Fresa&quot; &quot;Melocotón&quot; df[[&quot;Fruta&quot;]] # entrega el mimso resultado ## [1] &quot;Manzana&quot; &quot;Pera&quot; &quot;Piña&quot; &quot;Naranja&quot; &quot;Mandarina&quot; &quot;Banano&quot; ## [7] &quot;Durazno&quot; &quot;Uva&quot; &quot;Fresa&quot; &quot;Melocotón&quot; df[3, 2] # elemento de la tercera fila y segunda columna: -2 ## [1] -2 # row 3, columns 2 through 3 df[3, 2:3] ## Segundo Fruta ## 3 -2 Piña class(df[, &quot;Fruta&quot;]) # factor ## [1] &quot;character&quot; 3.11 Listas Una lista puede contener datos numéricos, carácteres, etc. Es decir, una mezcla de varios tipos de datos. También fotos o listas pueden ser parte de una lista. Crear una lista de tres elementos: 1, 2, 3 Luego, crear una lista de un solo elemento, que es un vector con los números 1 a 3 Después, crear una lista lista3 con dos elementos, uno es una lista (1,2,3) y otro un vector de cinco números (3 a 7) Posteriormente, crear una lista de dos elementos, uno debe ser el data frame df y otro un vector con los números 1 a 10 Luego, crear una lista lista4 con los siguientes 3 elementos: df, números 1 a 10, lista3 Imprimir lista4 a la pantalla Mostrar los nombres de lista4 Asignar los siguientes nombres a la lista4: data.frame, vector, lista Imprimir lista4 a la pantalla Crear una lista lista5 con los elementos, df, números 1 a 10, lista3 con los nombres: ElDataFrame, ElVector, LaLista, utilizando parejas de nombre-valor Mostrar los nombres de lista5 Imprimir lista5 a la pantalla list(1, 2, 3) ## [[1]] ## [1] 1 ## ## [[2]] ## [1] 2 ## ## [[3]] ## [1] 3 list(c(1, 2, 3)) ## [[1]] ## [1] 1 2 3 (lista3 &lt;- list(c(1, 2, 3), 3:7)) # observe, como se colocaron las paréntesis en este caso ## [[1]] ## [1] 1 2 3 ## ## [[2]] ## [1] 3 4 5 6 7 list(df, 1:10) ## [[1]] ## Primero Segundo Fruta ## 1 10 -4 Manzana ## 2 9 -3 Pera ## 3 8 -2 Piña ## 4 7 -1 Naranja ## 5 6 0 Mandarina ## 6 5 1 Banano ## 7 4 2 Durazno ## 8 3 3 Uva ## 9 2 4 Fresa ## 10 1 5 Melocotón ## ## [[2]] ## [1] 1 2 3 4 5 6 7 8 9 10 lista4 &lt;- list(df, 1:10, lista3) lista4 ## [[1]] ## Primero Segundo Fruta ## 1 10 -4 Manzana ## 2 9 -3 Pera ## 3 8 -2 Piña ## 4 7 -1 Naranja ## 5 6 0 Mandarina ## 6 5 1 Banano ## 7 4 2 Durazno ## 8 3 3 Uva ## 9 2 4 Fresa ## 10 1 5 Melocotón ## ## [[2]] ## [1] 1 2 3 4 5 6 7 8 9 10 ## ## [[3]] ## [[3]][[1]] ## [1] 1 2 3 ## ## [[3]][[2]] ## [1] 3 4 5 6 7 names(lista4) # listas pueden también tener nombres como un data frame ## NULL names(lista4) &lt;-c(&quot;data.frame&quot;, &quot;vector&quot;, &quot;lista&quot;) names(lista4) ## [1] &quot;data.frame&quot; &quot;vector&quot; &quot;lista&quot; lista5 &lt;- list(ElDataFrame=df, ElVector=1:10, LaLista=lista3) # parejas de nombre-valor en la creación de una lista names(lista5) ## [1] &quot;ElDataFrame&quot; &quot;ElVector&quot; &quot;LaLista&quot; lista5 ## $ElDataFrame ## Primero Segundo Fruta ## 1 10 -4 Manzana ## 2 9 -3 Pera ## 3 8 -2 Piña ## 4 7 -1 Naranja ## 5 6 0 Mandarina ## 6 5 1 Banano ## 7 4 2 Durazno ## 8 3 3 Uva ## 9 2 4 Fresa ## 10 1 5 Melocotón ## ## $ElVector ## [1] 1 2 3 4 5 6 7 8 9 10 ## ## $LaLista ## $LaLista[[1]] ## [1] 1 2 3 ## ## $LaLista[[2]] ## [1] 3 4 5 6 7 Para acceder a un elemento individual de una lista, utilice corchetes dobles, especificando el número del elemento o el nombre, que se quiere acceder. Tenga en cuenta que esto permite el acceso a un solo elemento a la vez. Ejemplo: Acceder al primer elemento de la lista5 lista5[[1]] ## Primero Segundo Fruta ## 1 10 -4 Manzana ## 2 9 -3 Pera ## 3 8 -2 Piña ## 4 7 -1 Naranja ## 5 6 0 Mandarina ## 6 5 1 Banano ## 7 4 2 Durazno ## 8 3 3 Uva ## 9 2 4 Fresa ## 10 1 5 Melocotón 3.11.1 Una lista de listas Crear 3 listas con números: La lista dataset1 con números 1 a 3 La lista dataset2 con números 4 a 6 La lista dataset3 con números 7 a 9 dataset1 &lt;- list(1:3) # números 1 hasta 3 print(dataset1) ## [[1]] ## [1] 1 2 3 dataset2 &lt;- list(4:6) # números 4 hasta 6 print(dataset2) ## [[1]] ## [1] 4 5 6 dataset3 &lt;- list(7:9) # números 7 hasta 9 print(dataset3) ## [[1]] ## [1] 7 8 9 Unir las 3 listas en una nueva lista con el nombre data.list data.list &lt;- list(dataset1, dataset2, dataset3) data.list ## [[1]] ## [[1]][[1]] ## [1] 1 2 3 ## ## ## [[2]] ## [[2]][[1]] ## [1] 4 5 6 ## ## ## [[3]] ## [[3]][[1]] ## [1] 7 8 9 Acceder en la lista dataset1 al segundo elemento dataset1[[1]][2] #2 ## [1] 2 Ahora de la lista de las 3 listas, acceder al segundo elemento. Es decir, al contenido de la segunda lista (dataset2), que esta parte de la lista data.list data.list[2] # 4 5 6 ## [[1]] ## [[1]][[1]] ## [1] 4 5 6 data.list[2][1] # 4 5 6 ## [[1]] ## [[1]][[1]] ## [1] 4 5 6 Acceder al segundo elemento de la segunda lista (dataset2), que es parte de la lista data.list data.list[[2]][[1]][2] # 5 ## [1] 5 3.12 Ejercicio 2 3.12.1 Parte a Crear un vector vector1 con los números 3 y 4 y convertirlo a un data frame y asignar el resultado a una variable data1 Mostrar el nombre de las columnas del data frame data1 Acceder al primer elemento del data frame (3) y mostrarlo en la pantalla 3.12.2 Parte b Crear un vector vector2 con el texto (string) 3, 4 y 5 y convertirlo a un data frame y asignar el resultado a una variable data2 Mostrar el resultado de la conversión, utilizando la función class() 3.12.3 Parte c Ahora, convertir el contenido de este data frame data2 (caracteres) al tipo de dato numeric. Es decir, convertir el contenido a tres números y asignar el resultado a una variable data3 Mostrar el resultado de la conversión, utilizando la función class() 3.12.4 Parte d Crear un vector vector3 con los 6 estratos (seis categorías: 1 a 6), como se utilizan p.ej. en Colombia. Es decir, crear este vector3 de tipo de dato factor Convertir el contenido de este vector al tipo de dato numeric. Es decir, convertir el contenido a seis números y asignar el resultado a una variable data4 Mostrar el resultado de la conversión, utilizando la función class() 3.12.5 Parte e Crear un data frame df10 con dos columnas. La primera columna x debe contener los datos 1, 2 y 3 y la segunda y los datos 4, 5 y 6. Sin embargo, los tres datos de la primera columna deben ser del tipo de dato numeric (numérico). Mientras los tres datos de la segunda columna deben ser del tipo de dato factor (categórica) -Ahora convertir los valores de la segunda columna (y), del tipo de dato factor a numeric -Mostrar que los valores de la segunda columna y ahora realmente son del tipo de dato numeric Nota: Observar bien lo que hace la función as.numeric() en el presente caso "],["cargar.html", "Sección 4 Cargar datos a R/RStudio 4.1 Objetivo 4.2 Leer datos desde un archivo de tipo csv y xlsx 4.3 Leer datos desde un archivo csv de una página web (url) 4.4 Leer datos de acciones, utilizando el paquete quantmod 4.5 Leer datos de una tabla de una página web: wikipedia 4.6 Cargar un conjunto de datos, que viene con R 4.7 Cargar datos financieros con el paquete tidyquant 4.8 Cargar datos de criptomonedas 4.9 Cargar datos de Eurostat con R 4.10 Ejercicio 3", " Sección 4 Cargar datos a R/RStudio 4.1 Objetivo El objetivo de esta sección consiste en explicar diferentes escenarios para cargar (importar) datos de diferentes fuentes a R / RStudio. Esto como una condición previa para analizar posteriormente estos datos. La explicación incluye fuentes de datos financieros como la cotización de acciones. 4.2 Leer datos desde un archivo de tipo csv y xlsx Primero, vamos a generar manualmente un archivo en MS-Excel con los siguientes datos: id Nombre Apellido Ingresos Egresos Calificación 1 Jimmy Toro 4000000 3500000 80 2 Joe Arango 3500000 4000000 20 3 Diana Ramírez 3000000 3000000 50 4 Cris Mesa 2500000 2000000 70 5 Manuela Meier 2000000 1000000 70 6 Lucia Müller 1500000 1400000 45 7 Andrés Aveláez 1000000 1000000 40 8 Bill Jaramillo 750000 800000 10 9 Gabriel Arias 500000 500000 12 10 Javier Gómez 450000 450000 10 Determinar su directorio de trabajo para R, utilizando la función getwd() Guardar este archivo como csv (comma separated value), bajo el nombre test1csv.csv, en su directorio de trabajo (working directory de R) Guardarlo también como archivo de Excel (xlsx), bajo el nombre test1excel.xlsx, en su directorio de trabajo de R Ahora, leer el contenido del archivo csv, utilizando en RStudio la función read.csv(), tomando en cuenta que los datos tienen un encabezado y asignar el resultado a una variable dataset Visualizar el contenido de la tabla de datos (dataset), utilizando la función View() Determinar la clase del (objeto) dataset Determinar la estructura de dataset, utilizando la función str() Mostrar Meier, que es un elemento en la fila con el id 5, columna #3 del dataset (quinta fila, tercera columna) dataset &lt;- read.csv(&#39;test1csv.csv&#39;, sep = &#39;;&#39;) # si el separador es coma o punto coma, depende como Excel almacena el archivo csv... View(dataset) class(dataset) ## [1] &quot;data.frame&quot; str(dataset) ## &#39;data.frame&#39;: 10 obs. of 6 variables: ## $ id : int 1 2 3 4 5 6 7 8 9 10 ## $ Nombre : chr &quot;Jimmy&quot; &quot;Joe&quot; &quot;Diana&quot; &quot;Cristina&quot; ... ## $ Apellido : chr &quot;Toro&quot; &quot;Arango&quot; &quot;Ramirez&quot; &quot;Mesa&quot; ... ## $ Ingresos : int 4000000 3500000 3000000 2500000 2000000 1500000 1000000 750000 500000 450000 ## $ Egresos : int 3500000 4000000 3000000 2000000 1000000 1400000 1000000 800000 500000 450000 ## $ Calificación: int 80 20 50 70 70 45 40 10 12 10 dataset[5,3] ## [1] &quot;Meier&quot; Ahora, leer el contenido del archivo xlsx, utilizando en RStudio la función read_excel() del paquete readxl, tomando en cuenta que los datos tienen un encabezado y asignar el resultado a la variable dataset2 Visualizar el contenido de la tabla de datos (dataset2), utilizando la función View() Determinar la clase del dataset2 Determinar la estructura de dataset2, utilizando la función str() Mostrar los ingresos de la persona Javier Gómez (observación en la fila #10 y columna #4), que es parte del dataset2 library(readxl) dataset2 &lt;- read_excel(&#39;test1excel.xlsx&#39;, sheet=&#39;Hoja2&#39;) # en el proceso de guardar como xlxs se genera esta hoja 2 View(dataset2) class(dataset2) ## [1] &quot;tbl_df&quot; &quot;tbl&quot; &quot;data.frame&quot; str(dataset2) ## tibble [10 x 6] (S3: tbl_df/tbl/data.frame) ## $ id : num [1:10] 1 2 3 4 5 6 7 8 9 10 ## $ Nombre : chr [1:10] &quot;Jimmy&quot; &quot;Joe&quot; &quot;Diana&quot; &quot;Cristina&quot; ... ## $ Apellido : chr [1:10] &quot;Toro&quot; &quot;Arango&quot; &quot;Ramirez&quot; &quot;Mesa&quot; ... ## $ Ingresos : num [1:10] 4000000 3500000 3000000 2500000 2000000 1500000 1000000 750000 500000 450000 ## $ Egresos : num [1:10] 3500000 4000000 3000000 2000000 1000000 1400000 1000000 800000 500000 450000 ## $ Calificación: num [1:10] 80 20 50 70 70 45 40 10 12 10 dataset[10,4] ## [1] 450000 Explorar la función file.choose() para el archivo csv, utilizando el comando dataset3 &lt;- read.csv(file.choose(), header=TRUE) Explorar la estructura de #dataset3\" Cambiar el código para los parámetros de la función read.csv() de tal forma, que se utiliza stringsAsFactors=FALSE para evitar que los datos de tipo string se convierten en una variable categórica (factor) Solución: dataset3 &lt;- read.csv(file.choose(), header=TRUE) Nota: El comando file.choose() abre una ventana nueva, que permite seleccionar un archivo en cualquier parte del equipo de cómputo o en una memoria externa. 4.3 Leer datos desde un archivo csv de una página web (url) Cargar datos de solicitudes de crédito de la siguiente url, donde se encuentra un archivo german_credit.csv: url=http://freakonometrics.free.fr/german_credit.csv y asignar el resultado a una variable credito. Tomar en cuenta que estos datos tienen un encabezado y que las columnas están separadas por coma. Analizar la estructura de los datos credito url=&quot;http://freakonometrics.free.fr/german_credit.csv&quot; credito &lt;- read.csv(url, header = TRUE, sep = &quot;,&quot;) str(credito) ## &#39;data.frame&#39;: 1000 obs. of 21 variables: ## $ Creditability : int 1 1 1 1 1 1 1 1 1 1 ... ## $ Account.Balance : int 1 1 2 1 1 1 1 1 4 2 ... ## $ Duration.of.Credit..month. : int 18 9 12 12 12 10 8 6 18 24 ... ## $ Payment.Status.of.Previous.Credit: int 4 4 2 4 4 4 4 4 4 2 ... ## $ Purpose : int 2 0 9 0 0 0 0 0 3 3 ... ## $ Credit.Amount : int 1049 2799 841 2122 2171 2241 3398 1361 1098 3758 ... ## $ Value.Savings.Stocks : int 1 1 2 1 1 1 1 1 1 3 ... ## $ Length.of.current.employment : int 2 3 4 3 3 2 4 2 1 1 ... ## $ Instalment.per.cent : int 4 2 2 3 4 1 1 2 4 1 ... ## $ Sex...Marital.Status : int 2 3 2 3 3 3 3 3 2 2 ... ## $ Guarantors : int 1 1 1 1 1 1 1 1 1 1 ... ## $ Duration.in.Current.address : int 4 2 4 2 4 3 4 4 4 4 ... ## $ Most.valuable.available.asset : int 2 1 1 1 2 1 1 1 3 4 ... ## $ Age..years. : int 21 36 23 39 38 48 39 40 65 23 ... ## $ Concurrent.Credits : int 3 3 3 3 1 3 3 3 3 3 ... ## $ Type.of.apartment : int 1 1 1 1 2 1 2 2 2 1 ... ## $ No.of.Credits.at.this.Bank : int 1 2 1 2 2 2 2 1 2 1 ... ## $ Occupation : int 3 3 2 2 2 2 2 2 1 1 ... ## $ No.of.dependents : int 1 2 1 2 1 2 1 2 1 1 ... ## $ Telephone : int 1 1 1 1 1 1 1 1 1 1 ... ## $ Foreign.Worker : int 1 1 1 2 2 2 2 2 1 1 ... 4.4 Leer datos de acciones, utilizando el paquete quantmod Cargar el paquete quantmod Analizar con el comando de help (?) el contenido de este paquete Este paquete requiere que se defina (al principio) un entorno (environment): new.env() que se asigna a una variable, p.ej. con el nombre stockData library(quantmod) ?quantmod stockData &lt;- new.env() #Generar un entorno nuevo # para que quandmod pueda guardar los datos en este entorno Definir una fecha de inicio y final para bajar los datos. Utilizar como fecha final la fecha actual y como fecha de inicio una fecha cercana a la fecha final startDate = as.Date(&quot;2021-12-30&quot;) endDate = Sys.Date() Definir una lista de los tickers (empresas) para las cuales se requieren los datos. P.ej. Amazon: ticker - AMZN tickers &lt;- c(&quot;AMZN&quot;) Descargar los datos históricos de la/s acción/es (para todos los tickers), utilizando la función getsymbols() de quandmod y como fuente yahoo (src = yahoo) getSymbols(tickers, env = stockData, src = &quot;yahoo&quot;, from = startDate, to = endDate) ## &#39;getSymbols&#39; currently uses auto.assign=TRUE by default, but will ## use auto.assign=FALSE in 0.5-0. You will still be able to use ## &#39;loadSymbols&#39; to automatically load data. getOption(&quot;getSymbols.env&quot;) ## and getOption(&quot;getSymbols.auto.assign&quot;) will still be checked for ## alternate defaults. ## ## This message is shown once per session and may be disabled by setting ## options(&quot;getSymbols.warning4.0&quot;=FALSE). See ?getSymbols for details. ## [1] &quot;AMZN&quot; Analizar las primeras 6 filas de estos datos ya descargados Observar la clase de los datos (class()) head(stockData$AMZN) ## AMZN.Open AMZN.High AMZN.Low AMZN.Close AMZN.Volume AMZN.Adjusted ## 2021-12-30 3394.00 3417.76 3370.48 3372.89 1879200 3372.89 ## 2021-12-31 3379.12 3387.00 3331.17 3334.34 2391500 3334.34 ## 2022-01-03 3351.00 3414.07 3323.21 3408.09 3176000 3408.09 ## 2022-01-04 3408.76 3428.00 3326.99 3350.44 3536300 3350.44 ## 2022-01-05 3337.66 3342.53 3287.14 3287.14 3215100 3287.14 ## 2022-01-06 3269.01 3296.00 3238.74 3265.08 2597900 3265.08 class(stockData) # environment ## [1] &quot;environment&quot; 4.5 Leer datos de una tabla de una página web: wikipedia Instalar y cargar los paquetes tidyverse y rvest Leer datos desde la tabla en https://en.wikipedia.org/wiki/List_of_countries_and_dependencies_by_population, utilizando la función read_html() para guardar el resultado en una variable urldata Observar la clase de la varialbe urldata Extraer la/s tabla/s mediante: tab &lt;- urldata %&gt;% html_nodes(table) Observar el contenido de la variable tab Escoger la primera tabla con: tab[[1]] Transformar a un data frame con: tab &lt;- tab[[1]] %&gt;% html_table(header = TRUE, fill = TRUE) Observar la clase de la variable tab\" Mostrar su contenido library(tidyverse) library(rvest) ## ## Attaching package: &#39;rvest&#39; ## The following object is masked from &#39;package:readr&#39;: ## ## guess_encoding url = &quot;https://en.wikipedia.org/wiki/List_of_countries_and_dependencies_by_population&quot; urldata &lt;- read_html(url) class(urldata) ## [1] &quot;xml_document&quot; &quot;xml_node&quot; tab &lt;- urldata %&gt;% html_nodes(&quot;table&quot;) tab ## {xml_nodeset (2)} ## [1] &lt;table class=&quot;wikitable sortable&quot;&gt;&lt;tbody&gt;\\n&lt;tr&gt;\\n&lt;th&gt;Rank&lt;/th&gt;\\n&lt;th&gt;\\n&lt;a ... ## [2] &lt;table class=&quot;nowraplinks hlist mw-collapsible autocollapse navbox-inner&quot; ... tab[[1]] # el primer elemento es la tabla que se quiere cargar... ## {html_node} ## &lt;table class=&quot;wikitable sortable&quot;&gt; ## [1] &lt;tbody&gt;\\n&lt;tr&gt;\\n&lt;th&gt;Rank&lt;/th&gt;\\n&lt;th&gt;\\n&lt;a href=&quot;/wiki/List_of_sovereign_stat ... tab &lt;- tab[[1]] %&gt;% html_table(header = TRUE, fill = TRUE) class(tab) # data frame ## [1] &quot;tbl_df&quot; &quot;tbl&quot; &quot;data.frame&quot; View(tab) # los contenidos se cargaron, más o menos, bien, # en términos del formato ... 4.6 Cargar un conjunto de datos, que viene con R Con la instalación básica de R vienen algunos datasets (pre-loaded datasets in R) Utilizar el paquete (library) datasets y la función data() para imprimir a la pantalla una lista con los conjuntos de datos disponibles library(datasets) data() # abre una pestaña en RStudio donde se muestran todos los datasets disponibles Cargar el dataset con el nombre EuStockMarkets, utilizando la función data() Convertir este datset a un data frame y asignar el resultado a la variable dataset.Eur Mostrar las primeras 10 filas de dataset.Eur Mostrar la estructura de dataset.Eur data(&quot;EuStockMarkets&quot;) dataset.Eur &lt;- as.data.frame(EuStockMarkets) head(dataset.Eur, n=10) ## DAX SMI CAC FTSE ## 1 1628.75 1678.1 1772.8 2443.6 ## 2 1613.63 1688.5 1750.5 2460.2 ## 3 1606.51 1678.6 1718.0 2448.2 ## 4 1621.04 1684.1 1708.1 2470.4 ## 5 1618.16 1686.6 1723.1 2484.7 ## 6 1610.61 1671.6 1714.3 2466.8 ## 7 1630.75 1682.9 1734.5 2487.9 ## 8 1640.17 1703.6 1757.4 2508.4 ## 9 1635.47 1697.5 1754.0 2510.5 ## 10 1645.89 1716.3 1754.3 2497.4 str(dataset.Eur) ## &#39;data.frame&#39;: 1860 obs. of 4 variables: ## $ DAX : num 1629 1614 1607 1621 1618 ... ## $ SMI : num 1678 1688 1679 1684 1687 ... ## $ CAC : num 1773 1750 1718 1708 1723 ... ## $ FTSE: num 2444 2460 2448 2470 2485 ... 4.7 Cargar datos financieros con el paquete tidyquant 4.7.1 Renta variable - precio de acciones Con respecto al paquete tidyquant, ver también el siguiente vínculo: https://rdrr.io/cran/tidyquant/man/tq_get.html Encontrar todas las bolsas disponibles, utilizando la función tq_exchange_options() library(tidyquant) ## Loading required package: lubridate ## ## Attaching package: &#39;lubridate&#39; ## The following objects are masked from &#39;package:base&#39;: ## ## date, intersect, setdiff, union ## Loading required package: PerformanceAnalytics ## ## Attaching package: &#39;PerformanceAnalytics&#39; ## The following object is masked from &#39;package:graphics&#39;: ## ## legend ## == Need to Learn tidyquant? ==================================================== ## Business Science offers a 1-hour course - Learning Lab #9: Performance Analysis &amp; Portfolio Optimization with tidyquant! ## &lt;/&gt; Learn more at: https://university.business-science.io/p/learning-labs-pro &lt;/&gt; tq_exchange_options() ## [1] &quot;AMEX&quot; &quot;NASDAQ&quot; &quot;NYSE&quot; Encontrar todos los indices búrsatiles disponibles, utilizando la función tq_index_options() tq_index_options() ## [1] &quot;DOW&quot; &quot;DOWGLOBAL&quot; &quot;SP400&quot; &quot;SP500&quot; &quot;SP600&quot; Explorar el índice S&amp;P500 (SP500), utilizando la función glimpse(), que es parecida a str(). Se requiere el paquete XLConnect library(XLConnect) ## XLConnect 1.0.5 by Mirai Solutions GmbH [aut], ## Martin Studer [cre], ## The Apache Software Foundation [ctb, cph] (Apache POI), ## Graph Builder [ctb, cph] (Curvesapi Java library), ## Brett Woolridge [ctb, cph] (SparseBitSet Java library) ## https://mirai-solutions.ch ## https://github.com/miraisolutions/xlconnect glimpse(tq_index(&quot;SP500&quot;)) ## Getting holdings for SP500 ## Rows: 505 ## Columns: 8 ## $ symbol &lt;chr&gt; &quot;AAPL&quot;, &quot;MSFT&quot;, &quot;AMZN&quot;, &quot;GOOGL&quot;, &quot;GOOG&quot;, &quot;FB&quot;, &quot;TSLA&quot;, ~ ## $ company &lt;chr&gt; &quot;Apple Inc.&quot;, &quot;Microsoft Corporation&quot;, &quot;Amazon.com Inc.~ ## $ identifier &lt;chr&gt; &quot;03783310&quot;, &quot;59491810&quot;, &quot;02313510&quot;, &quot;02079K30&quot;, &quot;02079K~ ## $ sedol &lt;chr&gt; &quot;2046251&quot;, &quot;2588173&quot;, &quot;2000019&quot;, &quot;BYVY8G0&quot;, &quot;BYY88Y7&quot;, ~ ## $ weight &lt;dbl&gt; 0.070742807, 0.061674925, 0.033466765, 0.021378555, 0.0~ ## $ sector &lt;chr&gt; &quot;Information Technology&quot;, &quot;Information Technology&quot;, &quot;Co~ ## $ shares_held &lt;dbl&gt; 168445170, 81144456, 4713625, 3251019, 3022066, 2557330~ ## $ local_currency &lt;chr&gt; &quot;USD&quot;, &quot;USD&quot;, &quot;USD&quot;, &quot;USD&quot;, &quot;USD&quot;, &quot;USD&quot;, &quot;USD&quot;, &quot;USD&quot;,~ Utilizar la función tq_get_options() para obtener una lista con opciones para obtener (get) datos financieros tq_get_options() # vamos a utilizar opción [1] &quot;stock.prices&quot; ## [1] &quot;stock.prices&quot; &quot;stock.prices.japan&quot; &quot;dividends&quot; ## [4] &quot;splits&quot; &quot;economic.data&quot; &quot;quandl&quot; ## [7] &quot;quandl.datatable&quot; &quot;tiingo&quot; &quot;tiingo.iex&quot; ## [10] &quot;tiingo.crypto&quot; &quot;alphavantager&quot; &quot;alphavantage&quot; ## [13] &quot;rblpapi&quot; Obtener los precios (stock.prices) de los últimos 10 dias de las siguientes acciones: Facebook (FB) y Microsoft (MSFT), utilizando la función tq_get() Mostrar las últimas 6 registros de estas acciones, utilizando la función tail() start &lt;- Sys.Date() - 10 acciones &lt;- tq_get(c(&quot;FB&quot;, &quot;MSFT&quot;), get = c(&quot;stock.prices&quot;), from = start, to = Sys.Date()) # se puede entrar también una fecha específica (entre comillas), como p.ej.: &quot;2020-02-01&quot; tail(acciones) ## # A tibble: 6 x 8 ## symbol date open high low close volume adjusted ## &lt;chr&gt; &lt;date&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 MSFT 2022-01-21 303. 304. 296. 296. 57118300 296. ## 2 MSFT 2022-01-24 292. 297. 276. 296. 86035400 296. ## 3 MSFT 2022-01-25 292. 295. 285. 288. 72848600 288. ## 4 MSFT 2022-01-26 308. 308. 293. 297. 90428900 297. ## 5 MSFT 2022-01-27 303. 307. 298. 300. 53376900 300. ## 6 MSFT 2022-01-28 300. 308. 294. 308. 49717000 308. Extraer (mostrar) los primeros registros de los precios (stock.prices) para el símbolo de MSFT a2 &lt;- acciones[acciones$symbol==&quot;MSFT&quot;, ] head(a2) ## # A tibble: 6 x 8 ## symbol date open high low close volume adjusted ## &lt;chr&gt; &lt;date&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 MSFT 2022-01-21 303. 304. 296. 296. 57118300 296. ## 2 MSFT 2022-01-24 292. 297. 276. 296. 86035400 296. ## 3 MSFT 2022-01-25 292. 295. 285. 288. 72848600 288. ## 4 MSFT 2022-01-26 308. 308. 293. 297. 90428900 297. ## 5 MSFT 2022-01-27 303. 307. 298. 300. 53376900 300. ## 6 MSFT 2022-01-28 300. 308. 294. 308. 49717000 308. 4.7.2 Renta fija Aquí, se trata de cargar 1-Y y 3-M bonos libre de riesgos (EE.UU. treasury bills) utilizando R Utilizar nuevamente el paquete tidyquant y la función tq_get() para bajar los datos de precios para bonos del estado de la página web de FRED, Federal Reserve Bank of St. Louis Economic Data. Se deben bajar los datos para TB1YR y TB3MS. Es decir, treasury bills de un año (1YR) y de tres meses (3MS) Stöckl, S. (21/09/2018). Tidy Portfoliomanagement in R. library(tidyquant) tbills &lt;- tq_get(c(&quot;TB1YR&quot;,&quot;TB3MS&quot;), get = &quot;economic.data&quot;) %&gt;% group_by(symbol) head(tbills) ## # A tibble: 6 x 3 ## # Groups: symbol [1] ## symbol date price ## &lt;chr&gt; &lt;date&gt; &lt;dbl&gt; ## 1 TB1YR 2012-01-01 0.11 ## 2 TB1YR 2012-02-01 0.15 ## 3 TB1YR 2012-03-01 0.18 ## 4 TB1YR 2012-04-01 0.18 ## 5 TB1YR 2012-05-01 0.19 ## 6 TB1YR 2012-06-01 0.18 4.8 Cargar datos de criptomonedas Utilizar el paquete crypto2, que permite descargar datos de criptomonedas (sin necesidad de utilizar el API de CoinMarketCap) Descargar la lista de criptomonedas disponibles, utilizando el comando crypto_list() de este paquete, y asignar el resultado a una variable list_coins Analizar la clase de esta variable Mostrar las primeras 6 filas de esta variable, utilizando la función kable(), aquí (head(list_coins)), la cual es parte del paquete knitr, y analizar estos datos library(crypto2) library(knitr) list_coins&lt;-crypto_list(only_active = TRUE, add_untracked = FALSE) # los parámetros only_active y add_untracked son opcionales class(list_coins) #top_cc es un dataframe ## [1] &quot;tbl_df&quot; &quot;tbl&quot; &quot;data.frame&quot; # kable es un generador de tablas (del paquete knitr) y muestra las primeras filas (head) de los datos kable(head(list_coins)) id name symbol slug rank is_active first_historical_data last_historical_data 1 Bitcoin BTC bitcoin 1 1 2013-04-28 2022-01-31 2 Litecoin LTC litecoin 22 1 2013-04-28 2022-01-31 3 Namecoin NMC namecoin 754 1 2013-04-28 2022-01-31 4 Terracoin TRC terracoin 1866 1 2013-04-28 2022-01-31 5 Peercoin PPC peercoin 835 1 2013-04-28 2022-01-31 6 Novacoin NVC novacoin 2159 1 2013-04-28 2022-01-31 4.8.1 Para cargar datos históricos de criptomonedas Utilizar el paquete crypto2 de R y la función crypto_history() para bajar los datos a partir de cierta fecha. Aquí 01/01/2021 Asignar el resultado a una variable all_coins library(crypto2) # Descargando precios para la lista de de criptomonedas (véase código anterior), mediante &quot;web scrapping&quot; all_coins &lt;- crypto_history(coin_list=list_coins, start_date = &#39;20220101&#39;, limit=10) ## &gt; Scraping historical crypto data ## ## &gt; Processing historical crypto data ## seleccionar las siguientes columnas (atributos): timestamp, symbol y close filtrar los datos por la cripotmoneda Bitcoin (BTC) luego, mostrar los útlimos 10 registros # filtrar los datos por Bitcoin bitc &lt;- all_coins %&gt;% select(timestamp, symbol, close) %&gt;% filter(symbol==&#39;BTC&#39;) #mostrar los últimos 10 precios library(knitr) tail(kable(bitc), 10) ## [1] &quot;|2022-01-21 23:59:59 |BTC | 36457.32|&quot; ## [2] &quot;|2022-01-22 23:59:59 |BTC | 35030.25|&quot; ## [3] &quot;|2022-01-23 23:59:59 |BTC | 36276.80|&quot; ## [4] &quot;|2022-01-24 23:59:59 |BTC | 36654.33|&quot; ## [5] &quot;|2022-01-25 23:59:59 |BTC | 36954.00|&quot; ## [6] &quot;|2022-01-26 23:59:59 |BTC | 36852.12|&quot; ## [7] &quot;|2022-01-27 23:59:59 |BTC | 37138.23|&quot; ## [8] &quot;|2022-01-28 23:59:59 |BTC | 37784.33|&quot; ## [9] &quot;|2022-01-29 23:59:59 |BTC | 38138.18|&quot; ## [10] &quot;|2022-01-30 23:59:59 |BTC | 37917.60|&quot; 4.9 Cargar datos de Eurostat con R Eurostat es la oficina estadística de la Unión Europea. Su misión es proporcionar estadísticas de alta calidad para Europa. Instalar y utilizar el paquete (library) eurostat R Tools for Eurostat open data Explorar el manual para el paquete eurostat, utilizando el comando ?eurostat Véase también: Leo Lahti, Janne Huovari, Markus Kainu, Przemyslaw Biecek. Retrieval and analysis of Eurostat open data with the eurostat package. R Journal 9(1):385-392, 2017. Version 3.7.9 doi: 10.32614/RJ-2017-019 Package URL: http://ropengov.github.io/eurostat Article URL: https://journal.r-project.org/archive/2017/RJ-2017-019/index.html library(dplyr) # parte del tidyverse library(eurostat) # R Tools para Eurostat open data ?eurostat # página de ayuda Cargar los datos desde Eurostat, utilizando la función get_eurostat(), y asignar el resultado a una variable contenido (tabla de contenido). Nota: La carga de estos datos se demora un rato library(eurostat) contenido &lt;- get_eurostat_toc() Mostrar para el contenido las primeras filas en una tabla, utilizando knitr::kable() Esto requiere el paquete knitr library(knitr) kable(head(contenido)) title code type last update of data last table structure change data start data end values Database by themes data folder NA NA NA NA NA General and regional statistics general folder NA NA NA NA NA European and national indicators for short-term analysis euroind folder NA NA NA NA NA Business and consumer surveys (source: DG ECFIN) ei_bcs folder NA NA NA NA NA Consumer surveys (source: DG ECFIN) ei_bcs_cs folder NA NA NA NA NA Consumers - monthly data ei_bsco_m dataset 28.01.2022 28.01.2022 1980M01 2022M01 NA Utilizando la función search_eurostat(), se puede buscar en la tabla de contenido, p.ej. por conjuntos de datos (datasets), que están relacionados con las tasas de intéres (interest rates): kable(head(search_eurostat(interest rates)), n=25) Donde n=5 limita el resultado a 5 filas kable(head(search_eurostat(&quot;interest rates&quot;)), n=5) title code type last update of data last table structure change data start data end values Candidate countries and potential candidates: exchange rates and interest rates cpc_ecexint dataset 17.03.2020 08.02.2021 2005 2019 NA Money market interest rates enpe_irt_st dataset 26.01.2022 26.01.2022 2005 2021 NA ENP countries: exchange rates and interest rates enpr_ecexint dataset 14.01.2020 08.02.2021 2005 2018 NA Money market interest rates - annual data irt_st_a dataset 06.01.2022 06.01.2022 1970 2021 NA Money market interest rates - quarterly data irt_st_q dataset 06.01.2022 06.01.2022 1970Q1 2021Q4 NA Money market interest rates - monthly data irt_st_m dataset 14.01.2022 06.01.2022 1970M01 2021M12 NA Nota: Los códigos para el conjunto de datos se pueden buscar también en la base de datos de Eurostat. Esta base de datos proporciona códigos en forma de un árbol de navegación de datos, entre paréntesis después de cada conjunto de datos: https://ec.europa.eu/eurostat/data/database Para descargar los datos de un conjunto de datos, utilizar la función search_eurostat() de la siguiente forma, donde code[1] es importante para que este id sea el code correspondiente, que se muestra en la tabla anterior id &lt;- search_eurostat(&quot;Money market interest rates - annual data&quot;, type = &quot;dataset&quot;)$code[1] print(id) ## [1] &quot;irt_st_a&quot; Ahora, se puede aprovechar de este id, de la siguiente forma, utilizando la función get_eurostat() y asignando el resultado a una variable datos datos &lt;- get_eurostat(id, time_format = &quot;num&quot;) ## Table irt_st_a cached at C:\\Users\\CHRIST~1\\AppData\\Local\\Temp\\Rtmp8sAfnc/eurostat/irt_st_a_num_code_FF.rds Ver los datos, utilizando la función str() y con head(), los primeros 5 registros de datos str(datos) ## tibble [3,224 x 4] (S3: tbl_df/tbl/data.frame) ## $ int_rt: chr [1:3224] &quot;IRT_DTD&quot; &quot;IRT_DTD&quot; &quot;IRT_DTD&quot; &quot;IRT_DTD&quot; ... ## $ geo : chr [1:3224] &quot;BG&quot; &quot;CZ&quot; &quot;DK&quot; &quot;EA&quot; ... ## $ time : num [1:3224] 2021 2021 2021 2021 2021 ... ## $ values: num [1:3224] NA NA -0.369 -0.483 NA ... head(datos, n=5) ## # A tibble: 5 x 4 ## int_rt geo time values ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 IRT_DTD BG 2021 NA ## 2 IRT_DTD CZ 2021 NA ## 3 IRT_DTD DK 2021 -0.369 ## 4 IRT_DTD EA 2021 -0.483 ## 5 IRT_DTD HR 2021 NA 4.10 Ejercicio 3 Crear un archivo de tipo CSV con los siguientes datos, distribuidos en cinco filas y 4 columnas, y separados por punto y coma (;): Id Estrato Ingresos Nombre 1 1 100.0 Jaime 2 2 150 María 3 2 140 Paula 4 5 90 Cristina Cargar estos datos desde el archivo csv a una variable dataset10 en R / RStudio. Los datos de las primeras tres columnas deben ser numéricos (int o num) y de la última de tipo character (chr) Mostrar la estructura del dataset10 en la pantalla Cambiar el nombre de la primera columna al texto numero "],["explorar.html", "Sección 5 Explorar datos 5.1 Objetivo 5.2 Desarrollar un entendimiento inicial del conjunto de datos 5.3 Comprobar, si existen datos faltantes 5.4 Visualizaciones para explorar datos 5.5 Guardar un histograma 5.6 Apalancarse por el paquete DescTools 5.7 Ejercicio 4", " Sección 5 Explorar datos 5.1 Objetivo El objetivo de esta sección consiste en presentar diferentes formas para realizar EDA - Exploratory Data Analysis. La presentación incluye formas gráficas al respecto. Para empezar con una exploración necesitamos datos. P.ej. algunos datos de la web, desde un archivo csv  véase http://freakonometrics.free.fr/german_credit.csv url=&quot;http://freakonometrics.free.fr/german_credit.csv&quot; dataset &lt;- read.csv(url, header = TRUE, sep = &quot;,&quot;) 5.2 Desarrollar un entendimiento inicial del conjunto de datos Mostrar la clase del dataset Explorar las dimensiones del dataset Ver las primeras 6 filas del dataset Explorar la estructura del dataset Mostrar un resumen estadístico de las variables del dataset class(dataset) ## [1] &quot;data.frame&quot; dim(dataset) ## [1] 1000 21 head(dataset) ## Creditability Account.Balance Duration.of.Credit..month. ## 1 1 1 18 ## 2 1 1 9 ## 3 1 2 12 ## 4 1 1 12 ## 5 1 1 12 ## 6 1 1 10 ## Payment.Status.of.Previous.Credit Purpose Credit.Amount Value.Savings.Stocks ## 1 4 2 1049 1 ## 2 4 0 2799 1 ## 3 2 9 841 2 ## 4 4 0 2122 1 ## 5 4 0 2171 1 ## 6 4 0 2241 1 ## Length.of.current.employment Instalment.per.cent Sex...Marital.Status ## 1 2 4 2 ## 2 3 2 3 ## 3 4 2 2 ## 4 3 3 3 ## 5 3 4 3 ## 6 2 1 3 ## Guarantors Duration.in.Current.address Most.valuable.available.asset ## 1 1 4 2 ## 2 1 2 1 ## 3 1 4 1 ## 4 1 2 1 ## 5 1 4 2 ## 6 1 3 1 ## Age..years. Concurrent.Credits Type.of.apartment No.of.Credits.at.this.Bank ## 1 21 3 1 1 ## 2 36 3 1 2 ## 3 23 3 1 1 ## 4 39 3 1 2 ## 5 38 1 2 2 ## 6 48 3 1 2 ## Occupation No.of.dependents Telephone Foreign.Worker ## 1 3 1 1 1 ## 2 3 2 1 1 ## 3 2 1 1 1 ## 4 2 2 1 2 ## 5 2 1 1 2 ## 6 2 2 1 2 str(dataset) ## &#39;data.frame&#39;: 1000 obs. of 21 variables: ## $ Creditability : int 1 1 1 1 1 1 1 1 1 1 ... ## $ Account.Balance : int 1 1 2 1 1 1 1 1 4 2 ... ## $ Duration.of.Credit..month. : int 18 9 12 12 12 10 8 6 18 24 ... ## $ Payment.Status.of.Previous.Credit: int 4 4 2 4 4 4 4 4 4 2 ... ## $ Purpose : int 2 0 9 0 0 0 0 0 3 3 ... ## $ Credit.Amount : int 1049 2799 841 2122 2171 2241 3398 1361 1098 3758 ... ## $ Value.Savings.Stocks : int 1 1 2 1 1 1 1 1 1 3 ... ## $ Length.of.current.employment : int 2 3 4 3 3 2 4 2 1 1 ... ## $ Instalment.per.cent : int 4 2 2 3 4 1 1 2 4 1 ... ## $ Sex...Marital.Status : int 2 3 2 3 3 3 3 3 2 2 ... ## $ Guarantors : int 1 1 1 1 1 1 1 1 1 1 ... ## $ Duration.in.Current.address : int 4 2 4 2 4 3 4 4 4 4 ... ## $ Most.valuable.available.asset : int 2 1 1 1 2 1 1 1 3 4 ... ## $ Age..years. : int 21 36 23 39 38 48 39 40 65 23 ... ## $ Concurrent.Credits : int 3 3 3 3 1 3 3 3 3 3 ... ## $ Type.of.apartment : int 1 1 1 1 2 1 2 2 2 1 ... ## $ No.of.Credits.at.this.Bank : int 1 2 1 2 2 2 2 1 2 1 ... ## $ Occupation : int 3 3 2 2 2 2 2 2 1 1 ... ## $ No.of.dependents : int 1 2 1 2 1 2 1 2 1 1 ... ## $ Telephone : int 1 1 1 1 1 1 1 1 1 1 ... ## $ Foreign.Worker : int 1 1 1 2 2 2 2 2 1 1 ... summary(dataset) ## Creditability Account.Balance Duration.of.Credit..month. ## Min. :0.0 Min. :1.000 Min. : 4.0 ## 1st Qu.:0.0 1st Qu.:1.000 1st Qu.:12.0 ## Median :1.0 Median :2.000 Median :18.0 ## Mean :0.7 Mean :2.577 Mean :20.9 ## 3rd Qu.:1.0 3rd Qu.:4.000 3rd Qu.:24.0 ## Max. :1.0 Max. :4.000 Max. :72.0 ## Payment.Status.of.Previous.Credit Purpose Credit.Amount ## Min. :0.000 Min. : 0.000 Min. : 250 ## 1st Qu.:2.000 1st Qu.: 1.000 1st Qu.: 1366 ## Median :2.000 Median : 2.000 Median : 2320 ## Mean :2.545 Mean : 2.828 Mean : 3271 ## 3rd Qu.:4.000 3rd Qu.: 3.000 3rd Qu.: 3972 ## Max. :4.000 Max. :10.000 Max. :18424 ## Value.Savings.Stocks Length.of.current.employment Instalment.per.cent ## Min. :1.000 Min. :1.000 Min. :1.000 ## 1st Qu.:1.000 1st Qu.:3.000 1st Qu.:2.000 ## Median :1.000 Median :3.000 Median :3.000 ## Mean :2.105 Mean :3.384 Mean :2.973 ## 3rd Qu.:3.000 3rd Qu.:5.000 3rd Qu.:4.000 ## Max. :5.000 Max. :5.000 Max. :4.000 ## Sex...Marital.Status Guarantors Duration.in.Current.address ## Min. :1.000 Min. :1.000 Min. :1.000 ## 1st Qu.:2.000 1st Qu.:1.000 1st Qu.:2.000 ## Median :3.000 Median :1.000 Median :3.000 ## Mean :2.682 Mean :1.145 Mean :2.845 ## 3rd Qu.:3.000 3rd Qu.:1.000 3rd Qu.:4.000 ## Max. :4.000 Max. :3.000 Max. :4.000 ## Most.valuable.available.asset Age..years. Concurrent.Credits ## Min. :1.000 Min. :19.00 Min. :1.000 ## 1st Qu.:1.000 1st Qu.:27.00 1st Qu.:3.000 ## Median :2.000 Median :33.00 Median :3.000 ## Mean :2.358 Mean :35.54 Mean :2.675 ## 3rd Qu.:3.000 3rd Qu.:42.00 3rd Qu.:3.000 ## Max. :4.000 Max. :75.00 Max. :3.000 ## Type.of.apartment No.of.Credits.at.this.Bank Occupation No.of.dependents ## Min. :1.000 Min. :1.000 Min. :1.000 Min. :1.000 ## 1st Qu.:2.000 1st Qu.:1.000 1st Qu.:3.000 1st Qu.:1.000 ## Median :2.000 Median :1.000 Median :3.000 Median :1.000 ## Mean :1.928 Mean :1.407 Mean :2.904 Mean :1.155 ## 3rd Qu.:2.000 3rd Qu.:2.000 3rd Qu.:3.000 3rd Qu.:1.000 ## Max. :3.000 Max. :4.000 Max. :4.000 Max. :2.000 ## Telephone Foreign.Worker ## Min. :1.000 Min. :1.000 ## 1st Qu.:1.000 1st Qu.:1.000 ## Median :1.000 Median :1.000 ## Mean :1.404 Mean :1.037 ## 3rd Qu.:2.000 3rd Qu.:1.000 ## Max. :2.000 Max. :2.000 5.3 Comprobar, si existen datos faltantes Se debe analizar, si existen datos faltantes en el dataset, ya que la falta de datos afecta la calidad de los datos y puede sesgar el análisis de los mismos 5.3.1 Opción 1 Utilizar la función is.na() para determinar si existen datos faltantes (NAs) y mostrar las primeras 6 filas al respecto head(is.na(dataset)) # muestra el valor True para un dato faltante ## Creditability Account.Balance Duration.of.Credit..month. ## [1,] FALSE FALSE FALSE ## [2,] FALSE FALSE FALSE ## [3,] FALSE FALSE FALSE ## [4,] FALSE FALSE FALSE ## [5,] FALSE FALSE FALSE ## [6,] FALSE FALSE FALSE ## Payment.Status.of.Previous.Credit Purpose Credit.Amount ## [1,] FALSE FALSE FALSE ## [2,] FALSE FALSE FALSE ## [3,] FALSE FALSE FALSE ## [4,] FALSE FALSE FALSE ## [5,] FALSE FALSE FALSE ## [6,] FALSE FALSE FALSE ## Value.Savings.Stocks Length.of.current.employment Instalment.per.cent ## [1,] FALSE FALSE FALSE ## [2,] FALSE FALSE FALSE ## [3,] FALSE FALSE FALSE ## [4,] FALSE FALSE FALSE ## [5,] FALSE FALSE FALSE ## [6,] FALSE FALSE FALSE ## Sex...Marital.Status Guarantors Duration.in.Current.address ## [1,] FALSE FALSE FALSE ## [2,] FALSE FALSE FALSE ## [3,] FALSE FALSE FALSE ## [4,] FALSE FALSE FALSE ## [5,] FALSE FALSE FALSE ## [6,] FALSE FALSE FALSE ## Most.valuable.available.asset Age..years. Concurrent.Credits ## [1,] FALSE FALSE FALSE ## [2,] FALSE FALSE FALSE ## [3,] FALSE FALSE FALSE ## [4,] FALSE FALSE FALSE ## [5,] FALSE FALSE FALSE ## [6,] FALSE FALSE FALSE ## Type.of.apartment No.of.Credits.at.this.Bank Occupation No.of.dependents ## [1,] FALSE FALSE FALSE FALSE ## [2,] FALSE FALSE FALSE FALSE ## [3,] FALSE FALSE FALSE FALSE ## [4,] FALSE FALSE FALSE FALSE ## [5,] FALSE FALSE FALSE FALSE ## [6,] FALSE FALSE FALSE FALSE ## Telephone Foreign.Worker ## [1,] FALSE FALSE ## [2,] FALSE FALSE ## [3,] FALSE FALSE ## [4,] FALSE FALSE ## [5,] FALSE FALSE ## [6,] FALSE FALSE 5.3.2 Opción 2 Si se trata de un conjunto de datos con muchos datos, es mejor analizar los datos faltantes de forma gráfica, utilizando el paquete Amelia y la función missmap(). En este caso de nuestro dataset no existen datos faltantes, como se puede observar en la gráfica abajo arrojada por missmap if(!require(&#39;Amelia&#39;)) install.packages(&#39;Amelia&#39;); library(Amelia) ## Loading required package: Amelia ## Loading required package: Rcpp ## ## ## ## Amelia II: Multiple Imputation ## ## (Version 1.8.0, built: 2021-05-26) ## ## Copyright (C) 2005-2022 James Honaker, Gary King and Matthew Blackwell ## ## Refer to http://gking.harvard.edu/amelia/ for more information ## ## missmap(dataset, main=&quot;Datos faltantes en el conjunto de datos - dataset&quot;, col=c(&quot;red&quot;,&quot;grey&quot;),legend=FALSE) 5.3.3 Opción 3 La función summary() muestra, si hay datos faltantes para una variable del conjunto de datos (dataset). Si existen datos faltantes, esto se indica como NAs. Usar la función summary() es muy útil y común, ya que el resultado muestra una estadística descripitva para cada atributo (coloumna) de los datos de forma resumida. Nota: Como se muestra el resultado depende del tipo de una variable. El resultado de una variable continúa se muestre diferente al resultado de una variable categórica summary(dataset) ## Creditability Account.Balance Duration.of.Credit..month. ## Min. :0.0 Min. :1.000 Min. : 4.0 ## 1st Qu.:0.0 1st Qu.:1.000 1st Qu.:12.0 ## Median :1.0 Median :2.000 Median :18.0 ## Mean :0.7 Mean :2.577 Mean :20.9 ## 3rd Qu.:1.0 3rd Qu.:4.000 3rd Qu.:24.0 ## Max. :1.0 Max. :4.000 Max. :72.0 ## Payment.Status.of.Previous.Credit Purpose Credit.Amount ## Min. :0.000 Min. : 0.000 Min. : 250 ## 1st Qu.:2.000 1st Qu.: 1.000 1st Qu.: 1366 ## Median :2.000 Median : 2.000 Median : 2320 ## Mean :2.545 Mean : 2.828 Mean : 3271 ## 3rd Qu.:4.000 3rd Qu.: 3.000 3rd Qu.: 3972 ## Max. :4.000 Max. :10.000 Max. :18424 ## Value.Savings.Stocks Length.of.current.employment Instalment.per.cent ## Min. :1.000 Min. :1.000 Min. :1.000 ## 1st Qu.:1.000 1st Qu.:3.000 1st Qu.:2.000 ## Median :1.000 Median :3.000 Median :3.000 ## Mean :2.105 Mean :3.384 Mean :2.973 ## 3rd Qu.:3.000 3rd Qu.:5.000 3rd Qu.:4.000 ## Max. :5.000 Max. :5.000 Max. :4.000 ## Sex...Marital.Status Guarantors Duration.in.Current.address ## Min. :1.000 Min. :1.000 Min. :1.000 ## 1st Qu.:2.000 1st Qu.:1.000 1st Qu.:2.000 ## Median :3.000 Median :1.000 Median :3.000 ## Mean :2.682 Mean :1.145 Mean :2.845 ## 3rd Qu.:3.000 3rd Qu.:1.000 3rd Qu.:4.000 ## Max. :4.000 Max. :3.000 Max. :4.000 ## Most.valuable.available.asset Age..years. Concurrent.Credits ## Min. :1.000 Min. :19.00 Min. :1.000 ## 1st Qu.:1.000 1st Qu.:27.00 1st Qu.:3.000 ## Median :2.000 Median :33.00 Median :3.000 ## Mean :2.358 Mean :35.54 Mean :2.675 ## 3rd Qu.:3.000 3rd Qu.:42.00 3rd Qu.:3.000 ## Max. :4.000 Max. :75.00 Max. :3.000 ## Type.of.apartment No.of.Credits.at.this.Bank Occupation No.of.dependents ## Min. :1.000 Min. :1.000 Min. :1.000 Min. :1.000 ## 1st Qu.:2.000 1st Qu.:1.000 1st Qu.:3.000 1st Qu.:1.000 ## Median :2.000 Median :1.000 Median :3.000 Median :1.000 ## Mean :1.928 Mean :1.407 Mean :2.904 Mean :1.155 ## 3rd Qu.:2.000 3rd Qu.:2.000 3rd Qu.:3.000 3rd Qu.:1.000 ## Max. :3.000 Max. :4.000 Max. :4.000 Max. :2.000 ## Telephone Foreign.Worker ## Min. :1.000 Min. :1.000 ## 1st Qu.:1.000 1st Qu.:1.000 ## Median :1.000 Median :1.000 ## Mean :1.404 Mean :1.037 ## 3rd Qu.:2.000 3rd Qu.:1.000 ## Max. :2.000 Max. :2.000 5.3.4 Opción 4 Cargar el paquete ez y ejectuar la función exPrecis() para el conjunto de datos (dataset) if(!require(&#39;ez&#39;)) install.packages(&#39;ez&#39;); library(ez) ## Loading required package: ez ezPrecis(dataset) ## Data frame dimensions: 1000 rows, 21 columns ## type missing values min max ## Creditability numeric 0 2 0 1 ## Account.Balance numeric 0 4 1 4 ## Duration.of.Credit..month. numeric 0 33 4 72 ## Payment.Status.of.Previous.Credit numeric 0 5 0 4 ## Purpose numeric 0 10 0 10 ## Credit.Amount numeric 0 923 250 18424 ## Value.Savings.Stocks numeric 0 5 1 5 ## Length.of.current.employment numeric 0 5 1 5 ## Instalment.per.cent numeric 0 4 1 4 ## Sex...Marital.Status numeric 0 4 1 4 ## Guarantors numeric 0 3 1 3 ## Duration.in.Current.address numeric 0 4 1 4 ## Most.valuable.available.asset numeric 0 4 1 4 ## Age..years. numeric 0 53 19 75 ## Concurrent.Credits numeric 0 3 1 3 ## Type.of.apartment numeric 0 3 1 3 ## No.of.Credits.at.this.Bank numeric 0 4 1 4 ## Occupation numeric 0 4 1 4 ## No.of.dependents numeric 0 2 1 2 ## Telephone numeric 0 2 1 2 ## Foreign.Worker numeric 0 2 1 2 5.4 Visualizaciones para explorar datos Utlizar el paquete ggplot2 para la visualización de los datos y el paquete farver (High Performance Colour Space Manipulation) Utilizar el diagrama de bigote (diagrama de caja o boxplot), únicamente para variables continuas, para visualizar datos extremos (outliers) Aquí, generar un boxplot para las 2 variables Creditibility (lo que significa default) y Credit.Amount (Monto del crédito) del dataset library(ggplot2) library(farver) dataset.boxplot &lt;- ggplot(data=dataset, aes(x = as.factor(Creditability), y = Credit.Amount)) # agregar la capa del boxplot mediante la función geom_boxplot() dataset.boxplot + geom_boxplot() # y utilizar etiquetas adecuadas mediante la función labs() dataset.boxplot + geom_boxplot() + labs(x=&quot;Default (0 or 1)&quot;, y = &quot;Amount&quot;) Utilizar histogramas. Estos diagramas se pueden utilizar para variables continuas y categóricas (factor) Histogramas proveen información sobre un posible sesgo en la distribución de los datos (skewness) y sobre su nivel de levantamiento o cuán aplanada es la distribución (kurtosis). Es decir, se puede ver el nivel de normalidad de la distribución dataset.histogram &lt;- ggplot(data=dataset, aes(x = Creditability)) + theme(legend.position=&quot;none&quot;) dataset.histogram + geom_bar(colour=&quot;darkgreen&quot;, fill=&quot;white&quot; ) + labs(x=&quot;Default 0 or 1&quot;, y=&quot;Frequency&quot;) 5.5 Guardar un histograma Guardar la gráfica en un archivo de tipo png, bajo el nombre HistogramDefault.png en el directorio de trabajo de R, utilizando la función ggsave() Comprobar en el directorio de trabajo, si usted puede encontrar este archivo en este lugar (una vez guardado) y abrirlo con un visor de imágenes (herramienta de windows)  #ggsave(file=&quot;HistogramDefault.png&quot;) 5.6 Apalancarse por el paquete DescTools El paquete DescTools provee funcionalidad en términos de una estadística descriptiva y de un análisis exploratorio de los datos para comprender mejor los datos (antes de generar modelos). Donde, DescTools = Tools for Descriptive Statistics and Exploratory Data Analysis. Cargar este paquete, utilizando la función library() if(!require(&#39;DescTools&#39;)) install.packages(&#39;DescTools&#39;); library(DescTools) ## Loading required package: DescTools ## ## Attaching package: &#39;DescTools&#39; ## The following objects are masked from &#39;package:tidyquant&#39;: ## ## IRR, NPV, PMT library(DescTools) Consultar la páginas de ayuda de DescTools: ?DescTools ?DescTools Describir del dataset (con los datos de los créditos) los datos de la columna Credit.Amount, utilizando la función Desc(). Nota: Es con D mayúscula Observar el resultado en la pantalla Desc(dataset$Credit.Amount) ## ------------------------------------------------------------------------------ ## dataset$Credit.Amount (integer) ## ## length n NAs unique 0s mean meanCI&#39; ## 1&#39;000 1&#39;000 0 923 0 3&#39;271.25 3&#39;096.08 ## 100.0% 0.0% 0.0% 3&#39;446.41 ## ## .05 .10 .25 median .75 .90 .95 ## 708.95 934.70 1&#39;365.50 2&#39;319.50 3&#39;972.25 7&#39;179.40 9&#39;162.70 ## ## range sd vcoef mad IQR skew kurt ## 18&#39;174.00 2&#39;822.75 0.86 1&#39;627.15 2&#39;606.75 1.94 4.25 ## ## lowest : 250, 276, 338, 339, 343 ## highest: 15&#39;653, 15&#39;672, 15&#39;857, 15&#39;945, 18&#39;424 ## ## &#39; 95%-CI (classic) Para la columna dataset$Credit.Amount realizar un qq-plot (gráfica), utilizando el paquete DescTools Interpretar el resultado, que muestra la gráfica (el QQ-Plot) PlotQQ(dataset$Credit.Amount) Ahora, utilizar la función PlotFdist() de DescTools (Frequency Distribution Plot) para la misma variable (Credit.Amount) Observar el resultado, que combina una gráfica de la distribución de frecuencias, un histograma, un diagrama de caja (box plot) y ecdf.plotd PlotFdist(dataset$Credit.Amount) Generar una tabla de frecuencias para la variable Credit.Amount, utilizando la función Freq() Observar el resultado Freq(dataset$Credit.Amount) ## level freq perc cumfreq cumperc ## 1 [0,2e+03] 432 43.2% 432 43.2% ## 2 (2e+03,4e+03] 322 32.2% 754 75.4% ## 3 (4e+03,6e+03] 97 9.7% 851 85.1% ## 4 (6e+03,8e+03] 79 7.9% 930 93.0% ## 5 (8e+03,1e+04] 30 3.0% 960 96.0% ## 6 (1e+04,1.2e+04] 19 1.9% 979 97.9% ## 7 (1.2e+04,1.4e+04] 9 0.9% 988 98.8% ## 8 (1.4e+04,1.6e+04] 11 1.1% 999 99.9% ## 9 (1.6e+04,1.8e+04] 0 0.0% 999 99.9% ## 10 (1.8e+04,2e+04] 1 0.1% 1&#39;000 100.0% Generar un diagrama de caja de dos dimensiones (two dimensional boxplot). Es decir, un bagplot. Este diagrama se genera con base en dos variables numéricos x y y. Aquí vamos a utilizar: Credit.Amount y Duration.of.Credit..month Observar el resultado ¿Qué se puede decir, con respecto a valores extremos (outliers)? PlotBag(dataset$Credit.Amount, dataset$Duration.of.Credit..month.) 5.7 Ejercicio 4 Analizar el paquete DataExplorer de R para explorar datos Cargar los datos de la siguiente forma: url=http://freakonometrics.free.fr/german_credit.csv dataset &lt;- read.csv(url, header = TRUE, sep = ,) Luego, utilizar el paquete DataExplorer, utilizando la función plot_str() Visualizar los valores faltantes, utilizando una función adecuada del paquete DataExplorer Crear histogramas para (las variables continúas) del dataset, utilizando una función adecuada del paquete DataExplorer Crear un data frame dataset2, que contiene los valores de las columnas Age..years. y Credit.Amount del dataset Visualizar las correlaciones entre los valores de las columnas Age..years. y Credit.Amount del dataset2 Aplicar la función plot_bar del paquete DataExplorer al dataset "],["tidy.html", "Sección 6 El paquete tidyverse y su funcionalidad 6.1 Objetivo y contextualización 6.2 tibble (parte del ecosistema tidyverse) 6.3 Utilizar y aplicar funciones del tidyverse 6.4 Ejercicio más avanzado 6.5 Ejercicio 5", " Sección 6 El paquete tidyverse y su funcionalidad 6.1 Objetivo y contextualización Conocer un sistema interesante de paquetes en R para agilizar la programación y lectura de código. El tidyverse es un sistema coherente de varios paquetes para la manipulación, exploración y visualización de datos. Los elementos de tidyverse comparten una filosofía de diseño común. Los elementos del tidyverse conforman un conjunto de paquetes. La siguiente página web informa sobre estos: https://www.tidyverse.org/packages/ El siguiente vínculo presenta una visualización gráfica y panorámica del tidyverse: https://rviews.rstudio.com/post/2017-06-09-What-is-the-tidyverse_files/tidyverse1.png Tidy data se refiere a datos ordenados. Es un término que describe un enfoque estandarizado para estructurar conjuntos de datos para facilitar su análisis y las visualizaciones Frigaard, M. (12/05/2017). Getting Started with tidyverse in R Hay tres principios para los datos ordenados Frigaard, M. (12/05/2017). Getting Started with tidyverse in R: Variables conforman las columnas Las observaciones forman las filas Los valores entran en las celdas 6.2 tibble (parte del ecosistema tidyverse) Un tibble, o tbl_df, es una presentación moderna de un data frame. Manteniendo elementos que en el tiempo se han demostrado como efectivo y descartando lo que no lo es (https://tibble.tidyverse.org/). Leer algunos datos de la web (http://freakonometrics.free.fr/german_credit.csv), desde un archivo csv  véase aquí y asignar el resultado a una variable dataset url=&quot;http://freakonometrics.free.fr/german_credit.csv&quot; dataset &lt;- read.csv(url, header = TRUE, sep = &quot;,&quot;) Transformar estos datos a un tibble, utilizando la función as_tibble() del paquete tidyverse Mostrar en la pantalla las primeras seis filas de este tibble library(tidyverse) # dplyr ?tidyverse dataset &lt;- as_tibble(dataset) class(dataset) # [1] &quot;tbl_df&quot; &quot;tbl&quot; &quot;data.frame&quot; ## [1] &quot;tbl_df&quot; &quot;tbl&quot; &quot;data.frame&quot; print(head(dataset, n= 5)) ## # A tibble: 5 x 21 ## Creditability Account.Balance Duration.of.Credit~ Payment.Status.of.P~ Purpose ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 1 1 18 4 2 ## 2 1 1 9 4 0 ## 3 1 2 12 2 9 ## 4 1 1 12 4 0 ## 5 1 1 12 4 0 ## # ... with 16 more variables: Credit.Amount &lt;int&gt;, Value.Savings.Stocks &lt;int&gt;, ## # Length.of.current.employment &lt;int&gt;, Instalment.per.cent &lt;int&gt;, ## # Sex...Marital.Status &lt;int&gt;, Guarantors &lt;int&gt;, ## # Duration.in.Current.address &lt;int&gt;, Most.valuable.available.asset &lt;int&gt;, ## # Age..years. &lt;int&gt;, Concurrent.Credits &lt;int&gt;, Type.of.apartment &lt;int&gt;, ## # No.of.Credits.at.this.Bank &lt;int&gt;, Occupation &lt;int&gt;, No.of.dependents &lt;int&gt;, ## # Telephone &lt;int&gt;, Foreign.Worker &lt;int&gt; Ver los nombres de las variables (columnas) colnames(dataset) # devuelve los nombres de las columnas ## [1] &quot;Creditability&quot; &quot;Account.Balance&quot; ## [3] &quot;Duration.of.Credit..month.&quot; &quot;Payment.Status.of.Previous.Credit&quot; ## [5] &quot;Purpose&quot; &quot;Credit.Amount&quot; ## [7] &quot;Value.Savings.Stocks&quot; &quot;Length.of.current.employment&quot; ## [9] &quot;Instalment.per.cent&quot; &quot;Sex...Marital.Status&quot; ## [11] &quot;Guarantors&quot; &quot;Duration.in.Current.address&quot; ## [13] &quot;Most.valuable.available.asset&quot; &quot;Age..years.&quot; ## [15] &quot;Concurrent.Credits&quot; &quot;Type.of.apartment&quot; ## [17] &quot;No.of.Credits.at.this.Bank&quot; &quot;Occupation&quot; ## [19] &quot;No.of.dependents&quot; &quot;Telephone&quot; ## [21] &quot;Foreign.Worker&quot; # rownames(dataset) # devuelve los números de las filas... Mostrar, en una tabla (de frecuencias), las frecuencias para los valores (binarios) de la variable Creditability (columna Creditability), utilizando la función table() Observar el resultado: ¿Cuántas observaciones son de buena paga? table(dataset$Creditability) # 300 = 0 y 700 = 1, donde 1 significa &quot;buena calidad crediticia&quot; ## ## 0 1 ## 300 700 6.3 Utilizar y aplicar funciones del tidyverse 6.3.1 filter Filtrar el dataset, por ejemplo por el campo Creditability == 0, utilizando tidyverse con el comando pipe [ %&gt;% ] y la función filter() Mostrar las primeras 5 filas dataset %&gt;% filter(Creditability == 0) %&gt;% head(n=5) ## # A tibble: 5 x 21 ## Creditability Account.Balance Duration.of.Credit~ Payment.Status.of.P~ Purpose ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 0 2 36 2 5 ## 2 0 1 18 2 0 ## 3 0 4 18 4 6 ## 4 0 2 36 3 9 ## 5 0 1 15 2 0 ## # ... with 16 more variables: Credit.Amount &lt;int&gt;, Value.Savings.Stocks &lt;int&gt;, ## # Length.of.current.employment &lt;int&gt;, Instalment.per.cent &lt;int&gt;, ## # Sex...Marital.Status &lt;int&gt;, Guarantors &lt;int&gt;, ## # Duration.in.Current.address &lt;int&gt;, Most.valuable.available.asset &lt;int&gt;, ## # Age..years. &lt;int&gt;, Concurrent.Credits &lt;int&gt;, Type.of.apartment &lt;int&gt;, ## # No.of.Credits.at.this.Bank &lt;int&gt;, Occupation &lt;int&gt;, No.of.dependents &lt;int&gt;, ## # Telephone &lt;int&gt;, Foreign.Worker &lt;int&gt; 6.3.2 arrange (para ordenar datos) Ordenar el resultado anterior por la columna edad (Age..years.) de manera descendente, utilizando la función arrange() dataset %&gt;% filter(Creditability ==0) %&gt;% arrange(desc(Age..years.)) %&gt;% head(n=5) ## # A tibble: 5 x 21 ## Creditability Account.Balance Duration.of.Credit~ Payment.Status.of.P~ Purpose ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 0 2 9 1 1 ## 2 0 4 18 2 0 ## 3 0 1 6 2 0 ## 4 0 2 12 2 3 ## 5 0 3 30 3 9 ## # ... with 16 more variables: Credit.Amount &lt;int&gt;, Value.Savings.Stocks &lt;int&gt;, ## # Length.of.current.employment &lt;int&gt;, Instalment.per.cent &lt;int&gt;, ## # Sex...Marital.Status &lt;int&gt;, Guarantors &lt;int&gt;, ## # Duration.in.Current.address &lt;int&gt;, Most.valuable.available.asset &lt;int&gt;, ## # Age..years. &lt;int&gt;, Concurrent.Credits &lt;int&gt;, Type.of.apartment &lt;int&gt;, ## # No.of.Credits.at.this.Bank &lt;int&gt;, Occupation &lt;int&gt;, No.of.dependents &lt;int&gt;, ## # Telephone &lt;int&gt;, Foreign.Worker &lt;int&gt; 6.3.3 group_by y summarize (contar registros) Contar las observaciones por el campo destino (Purpose) del crédito, utilizando la función group_by() y la función summarize() Mostrar el resultado en la pantalla dataset %&gt;% group_by(Purpose) %&gt;% summarize(cantidad = n()) ## # A tibble: 10 x 2 ## Purpose cantidad ## &lt;int&gt; &lt;int&gt; ## 1 0 234 ## 2 1 103 ## 3 2 181 ## 4 3 280 ## 5 4 12 ## 6 5 22 ## 7 6 50 ## 8 8 9 ## 9 9 97 ## 10 10 12 6.3.4 select Seleccionar únicamente las columnas Creditability y Credit.Amount del dataset, utilizando la función select(), y mostrar las primeras 5 filas dataset %&gt;% select(Creditability, Credit.Amount) %&gt;% head(n=5) ## # A tibble: 5 x 2 ## Creditability Credit.Amount ## &lt;int&gt; &lt;int&gt; ## 1 1 1049 ## 2 1 2799 ## 3 1 841 ## 4 1 2122 ## 5 1 2171 6.3.5 mutate Agregar una nueva columna Avg.Amount al dataset que contiene el promedio del monto del crédito (Credit.Amount), utilizando la función mutate() Mostrar las primeras 5 filas del dataset dataset %&gt;% mutate(Avg.Amount = mean(Credit.Amount)) %&gt;% head(n=5) ## # A tibble: 5 x 22 ## Creditability Account.Balance Duration.of.Credit~ Payment.Status.of.P~ Purpose ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 1 1 18 4 2 ## 2 1 1 9 4 0 ## 3 1 2 12 2 9 ## 4 1 1 12 4 0 ## 5 1 1 12 4 0 ## # ... with 17 more variables: Credit.Amount &lt;int&gt;, Value.Savings.Stocks &lt;int&gt;, ## # Length.of.current.employment &lt;int&gt;, Instalment.per.cent &lt;int&gt;, ## # Sex...Marital.Status &lt;int&gt;, Guarantors &lt;int&gt;, ## # Duration.in.Current.address &lt;int&gt;, Most.valuable.available.asset &lt;int&gt;, ## # Age..years. &lt;int&gt;, Concurrent.Credits &lt;int&gt;, Type.of.apartment &lt;int&gt;, ## # No.of.Credits.at.this.Bank &lt;int&gt;, Occupation &lt;int&gt;, No.of.dependents &lt;int&gt;, ## # Telephone &lt;int&gt;, Foreign.Worker &lt;int&gt;, Avg.Amount &lt;dbl&gt; Agregar una nueva columna Default al dataset, que contiene el valor Yes, si el valor del campo Creditability es igual a 0, en el caso contrario, colocar el valor No. Utilizar la función mutate() con ifelse() al respecto Mostrar las primeras 5 filas del dataset dataset %&gt;% mutate(Default = ifelse(Creditability==0, &#39;Yes&#39;, &#39;No&#39;)) %&gt;% head(n=5) ## # A tibble: 5 x 22 ## Creditability Account.Balance Duration.of.Credit~ Payment.Status.of.P~ Purpose ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 1 1 18 4 2 ## 2 1 1 9 4 0 ## 3 1 2 12 2 9 ## 4 1 1 12 4 0 ## 5 1 1 12 4 0 ## # ... with 17 more variables: Credit.Amount &lt;int&gt;, Value.Savings.Stocks &lt;int&gt;, ## # Length.of.current.employment &lt;int&gt;, Instalment.per.cent &lt;int&gt;, ## # Sex...Marital.Status &lt;int&gt;, Guarantors &lt;int&gt;, ## # Duration.in.Current.address &lt;int&gt;, Most.valuable.available.asset &lt;int&gt;, ## # Age..years. &lt;int&gt;, Concurrent.Credits &lt;int&gt;, Type.of.apartment &lt;int&gt;, ## # No.of.Credits.at.this.Bank &lt;int&gt;, Occupation &lt;int&gt;, No.of.dependents &lt;int&gt;, ## # Telephone &lt;int&gt;, Foreign.Worker &lt;int&gt;, Default &lt;chr&gt; # o con case_when() # dataset &lt;- dataset %&gt;% # mutate(Default = case_when(Creditability == 1 ~ &#39;No&#39;, # Creditability == 0 ~ &#39;Yes&#39; )) 6.4 Ejercicio más avanzado 6.4.1 Procesar datos bursátiles con pipes (%&gt;%) Cargar el paquete (library) tidyverse Bajar los datos de la bolsa New York Stock Exchange (NYSE), mediante la función tq_exchange(NYSE) y asignar el resultado a la variable nyse Bajar los datos de la bolsa NASDAQ, mediante la función tq_exchange(NASDAQ) y asignar el resultado a la variable nasdaq Unir los registros de las dos fuentes de datos (variables) nyse y nasdaq, utlizando la función rbind(), creando una variable nueva nyse_nasdaq Bajar los datos del indice búrsatil S&amp;P500 (SP500), mediante la función tq_index(SP500) y asignar el resultado a la variable sp500 Une sp500 y nyse_nasdaq, utilizando un inner join (función inner_join()) y tomando el atributo (columna) symbol, dado que estas dos fuentes tienen este atributo en común Filtrar por registros, donde el año del IPO (ipo.year) es menor al año 2000 y donde el campo market.cap no tiene datos faltantes (NA) Ordenar por el campo (columna) weight de forma descendente y mostrar únicamente las primeras 10 filas, utilizando la función slice() Mostrar el resultado en la pantalla Es decir, lo que se hace aquí es que queremos utilizar el conjunto de datos que consiste, por un lado, en las diez acciones más grandes dentro del índice S&amp;P500, que tuvieron su IPO antes de enero del año 2000. Por otro lado, debemos combinar ambos conjuntos de datos (S&amp;P500 y NYSE más NASDAQ, usando un inner join, porque solo queremos mantener los símbolos del S&amp;P500, que también se negocian en NYSE o NASDAQ Stöckl, S. (21/09/2018). Tidy Portfoliomanagement in R. library(tidyverse) library(tidyquant) # debe ser la versión actual (&gt;=0.5.9) tq_exchange_options() # &quot;AMEX&quot; &quot;NASDAQ&quot; &quot;NYSE&quot; ## [1] &quot;AMEX&quot; &quot;NASDAQ&quot; &quot;NYSE&quot; nyse &lt;- tq_exchange(&quot;NYSE&quot;) ## Getting data... nasdaq &lt;- tq_exchange(&quot;NASDAQ&quot;) ## Getting data... nyse_nasdaq &lt;- rbind(nyse,nasdaq) sp500 &lt;- tq_index(&quot;SP500&quot;) ## Getting holdings for SP500 acciones.seleccion &lt;- sp500 %&gt;% inner_join(nyse_nasdaq, by=c(&quot;symbol&quot;)) %&gt;% select(symbol,last.sale.price, market.cap, weight, ipo.year)%&gt;% # join datasets filter(ipo.year&lt;2000 &amp; !is.na(market.cap)) %&gt;% # filtrar años con año del ipo&lt;2000 o ipo=NA arrange(desc(weight)) %&gt;% # ordenar en orden descendente slice(1:10) print(acciones.seleccion) # se puede observar que AAPL (Apple) es la empresa &quot;más grande&quot;... ## # A tibble: 10 x 5 ## symbol last.sale.price market.cap weight ipo.year ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; ## 1 AAPL 173. 3001384821312 0.0707 1980 ## 2 MSFT 309. 2318405942859 0.0617 1986 ## 3 AMZN 2972. 1507364442069 0.0335 1997 ## 4 NVDA 240. 600800000000 0.0152 1999 ## 5 ADBE 527. 248482126000 0.00656 1986 ## 6 CSCO 55.5 233950635606 0.00625 1990 ## 7 QCOM 174. 196022955495 0.00498 1991 ## 8 INTU 551. 155908863471 0.00403 1993 ## 9 UPS 201. 175049574721 0.00385 1999 ## 10 ORCL 80.6 215144562555 0.00346 1986 6.5 Ejercicio 5 Cargar el paquete tidyverse Utilizar el conjunto de datos iris, que se instaló con R: data(iris) Ver la siguiente descripción al respecto: https://es.wikipedia.org/wiki/Conjunto_de_datos_flor_iris Mostrar las primeras 5 filas de iris en la pantalla Agrupar los datos de iris por la columna Species y asignar el resultado a una variable iris.por.species, utilizando tidyverse Mostrar las últimas 3 filas de iris.por.species Agregar una columna a iris.por.species, donde se muestra el valor promedio para los valores de la columna Sepal.Length, utilizando tidyverse "],["bucles.html", "Sección 7 Bucles / ciclos 7.1 Objetivo 7.2 ¿Qué son las funciones del tipo apply()? 7.3 apply 7.4 lapply 7.5 sapply 7.6 Ejercicio 6", " Sección 7 Bucles / ciclos 7.1 Objetivo Programar un ciclo de una forma sencilla. Es decir, una secuencia de comandos que se ejecuta repetidas veces, pero sin escribir mucho código. 7.2 ¿Qué son las funciones del tipo apply()? Respuesta: ciclos, bucles o loops apply - se utiliza para una matriz. Para iterar sobre sus filas o columnas. tapply - se utiliza para una matriz para extraer subconjuntos de datos y aplicar una función sobre ellos. Para data frames es parecido al concepto de group by en SQL (Standard Query Language) eapply - se utiliza para un entorno (environment (E)) lapply - se utiliza para iterar sobre los elementos de una lista ( list (L)) sapply - una versión más sencilla de lapply. Es decir, simplifica el resultado (simplify (S)), ya que el resultado no se muestra como una lista, sino como matriz o vector vapply - devuelve un valor predeterminado (pre-defined return value (V)) replicate - ejecuta una función varias veces y se utiliza, en términos generales, en la generación de números (variables) aleatorios mapply - versión multivariada (multivariate (M)) de sapply. Los argumentos de la función se pueden reciclar rapply - una versión recursiva de lapply (recursive (R) version) A continuación, nos enfocamos en la aplicación de las funciones: apply, lapply y sapply. Dónde, apply se utiliza para matrices y lapply y sapply para listas y vectores. Consultar la ayuda para la función apply ?apply 7.3 apply Apply tiene la siguiente signatura: apply(X, MARGIN, FUN, ) Donde, x es una matriz y margin es 1 (rows) o 2 (columns) y FuN es una función (function), p.ej. una función parecida a la función promedio: mean() Generar primero manualmente un data frame dataset con los siguientes datos para poder demostrar después el funcionamiento de las funciones del tipo apply() id Nombre Apellido Ingresos Egresos Calificación 1 Jimmy Toro 4000000 3500000 80 2 Joe Arango 3500000 4000000 20 3 Diana Ramírez 3000000 3000000 50 4 Cris Mesa 2500000 2000000 70 5 Manuela Meier 2000000 1000000 70 6 Lucia Müller 1500000 1400000 45 7 Andrés Aveláez 1000000 1000000 40 8 Bill Jaramillo 750000 800000 10 9 Gabriel Arias 500000 500000 12 10 Javier Gómez 450000 450000 10 dataset &lt;- data.frame(id= 1:10, Nombre = c(&quot;Jimmy&quot;, &quot;Joe&quot;, &quot;Diana&quot;, &quot;Cris&quot;, &quot;Manuela&quot;, &quot;Lucia&quot;, &quot;Andrés&quot;, &quot;Bill&quot;, &quot;Gabriel&quot;, &quot;Javier&quot;), Apellido = c(&quot;Toro&quot;, &quot;Arango&quot;, &quot;Ramírez&quot;, &quot;Mesa&quot;, &quot;Meier&quot;, &quot;Müller&quot;, &quot;Aveláez&quot;, &quot;Jaramillo&quot;, &quot;Arias&quot;, &quot;Gómez&quot;), Ingresos = c(4000000, 3500000, 3000000, 2500000, 2000000, 1500000, 1000000, 750000, 500000, 450000), Egresos = c(3500000, 4000000, 3000000, 2000000, 1000000, 1400000, 1000000, 800000, 500000, 450000), Calificacion = c(80, 20, 50, 70, 70, 45, 40, 10, 12, 10) ) class(dataset) ## [1] &quot;data.frame&quot; print(dataset) # imprimir el dataset a la pantalla (consola) ## id Nombre Apellido Ingresos Egresos Calificacion ## 1 1 Jimmy Toro 4000000 3500000 80 ## 2 2 Joe Arango 3500000 4000000 20 ## 3 3 Diana Ramírez 3000000 3000000 50 ## 4 4 Cris Mesa 2500000 2000000 70 ## 5 5 Manuela Meier 2000000 1000000 70 ## 6 6 Lucia Müller 1500000 1400000 45 ## 7 7 Andrés Aveláez 1000000 1000000 40 ## 8 8 Bill Jaramillo 750000 800000 10 ## 9 9 Gabriel Arias 500000 500000 12 ## 10 10 Javier Gómez 450000 450000 10 Determinar el valor máximo para las filas (para cada fila) del dataset, utlizando apply() con la función max apply(dataset, 1, max) # 1 = por filas ## [1] &quot;Toro&quot; &quot;Joe&quot; &quot;Ramírez&quot; &quot;Mesa&quot; &quot;Meier&quot; &quot;Müller&quot; ## [7] &quot;Aveláez&quot; &quot;Jaramillo&quot; &quot;Gabriel&quot; &quot;Javier&quot; Determinar el valor máximo para las columnas (para cada columna) del dataset, utilizando apply/() con la función max apply(dataset, 2, max) # 2 = por columnas ## id Nombre Apellido Ingresos Egresos Calificacion ## &quot;10&quot; &quot;Manuela&quot; &quot;Toro&quot; &quot;4000000&quot; &quot;4000000&quot; &quot;80&quot; Determinar, si el dataset tiene datos faltantes, utilizando apply con la función is.na apply(dataset, 2, is.na) ## id Nombre Apellido Ingresos Egresos Calificacion ## [1,] FALSE FALSE FALSE FALSE FALSE FALSE ## [2,] FALSE FALSE FALSE FALSE FALSE FALSE ## [3,] FALSE FALSE FALSE FALSE FALSE FALSE ## [4,] FALSE FALSE FALSE FALSE FALSE FALSE ## [5,] FALSE FALSE FALSE FALSE FALSE FALSE ## [6,] FALSE FALSE FALSE FALSE FALSE FALSE ## [7,] FALSE FALSE FALSE FALSE FALSE FALSE ## [8,] FALSE FALSE FALSE FALSE FALSE FALSE ## [9,] FALSE FALSE FALSE FALSE FALSE FALSE ## [10,] FALSE FALSE FALSE FALSE FALSE FALSE Determinar la estructura del dataset, utilizando la función str() str(dataset) # data frame ## &#39;data.frame&#39;: 10 obs. of 6 variables: ## $ id : int 1 2 3 4 5 6 7 8 9 10 ## $ Nombre : chr &quot;Jimmy&quot; &quot;Joe&quot; &quot;Diana&quot; &quot;Cris&quot; ... ## $ Apellido : chr &quot;Toro&quot; &quot;Arango&quot; &quot;Ramírez&quot; &quot;Mesa&quot; ... ## $ Ingresos : num 4000000 3500000 3000000 2500000 2000000 1500000 1000000 750000 500000 450000 ## $ Egresos : num 3500000 4000000 3000000 2000000 1000000 1400000 1000000 800000 500000 450000 ## $ Calificacion: num 80 20 50 70 70 45 40 10 12 10 Mejor es, utilizar únicamente datos numéricos para las siguientes operaciones. De acuerdo con lo anterior, generar una variable dataset.num a partir del dataset, utilizando las siguientes columnas (numéricas): Ingresos, Egresos y Calificacion dataset.num &lt;- dataset[ , c(&quot;Ingresos&quot;, &quot;Egresos&quot;, &quot;Calificacion&quot;)] print(dataset.num) ## Ingresos Egresos Calificacion ## 1 4000000 3500000 80 ## 2 3500000 4000000 20 ## 3 3000000 3000000 50 ## 4 2500000 2000000 70 ## 5 2000000 1000000 70 ## 6 1500000 1400000 45 ## 7 1000000 1000000 40 ## 8 750000 800000 10 ## 9 500000 500000 12 ## 10 450000 450000 10 Determinar para dataset.num el promedio por filas, utilizando apply() con mean apply(dataset.num, 1, mean) # calcula el promedio por columna (2) ## [1] 2500026.7 2500006.7 2000016.7 1500023.3 1000023.3 966681.7 666680.0 ## [8] 516670.0 333337.3 300003.3 Determinar para datset.num el promedio por columnas, utilizando apply() con mean apply(dataset.num, 2, mean) # calcula el promedio por columna (2) ## Ingresos Egresos Calificacion ## 1920000.0 1765000.0 40.7 #mean(dataset$Ingresos) # validación para la columna &quot;ingresos&quot; Determinar el promedio para la tercera fila del dataset.num apply(dataset.num[3, ], 1, mean) # 1 = por filas ## 3 ## 2000017 7.3.1 apply vs for (for loop) Comparar apply() con un bucle (loop), utilizando for(), para calcular el promedio para cada fila #loop output &lt;- NULL # preparando un vector vacío nrow(dataset.num) # 10; comprobando por la cantidad de filas del data frame ## [1] 10 for(i in 1:nrow(dataset.num)){ output[i] &lt;- mean(as.numeric(dataset.num[i, ])) # aqui as.numeric es obligatorio } print(output) ## [1] 2500026.7 2500006.7 2000016.7 1500023.3 1000023.3 966681.7 666680.0 ## [8] 516670.0 333337.3 300003.3 Hacer lo mismo que lo anterior (for loop), pero utilizando apply() en lugar del for(), lo que significa escribir menos código Después, utilizar rowMeans(), que debe arrojar el mismo resultado en este caso apply(dataset.num, 1, mean) ## [1] 2500026.7 2500006.7 2000016.7 1500023.3 1000023.3 966681.7 666680.0 ## [8] 516670.0 333337.3 300003.3 rowMeans(dataset.num) # da igual ## [1] 2500026.7 2500006.7 2000016.7 1500023.3 1000023.3 966681.7 666680.0 ## [8] 516670.0 333337.3 300003.3 7.4 lapply Utilizar lapply(), lo que devuelve una lista. Es decir, apply y lapply se diferencian en el sentido, que lapply recibe y devuelve una lista. Vamos a crear entonces una lista de 3 data frames (dataset.A, dataset.B y dataset.C), para tener tres veces el dataset.num y Colocar estos tres data frames en una lista con el nombre dataset.list Mostar dataset.list en la pantalla, utilizando el comando print() Ahora, extraer de esta lista de cada data frame el primer elemento, utilizando lapply() dataset.A &lt;- dataset.num dataset.B &lt;- dataset.num dataset.C &lt;- dataset.num # class(dataset.A) # [1] &quot;data.frame&quot; dataset.list &lt;- list(dataset.A, dataset.B, dataset.C) print(dataset.list) ## [[1]] ## Ingresos Egresos Calificacion ## 1 4000000 3500000 80 ## 2 3500000 4000000 20 ## 3 3000000 3000000 50 ## 4 2500000 2000000 70 ## 5 2000000 1000000 70 ## 6 1500000 1400000 45 ## 7 1000000 1000000 40 ## 8 750000 800000 10 ## 9 500000 500000 12 ## 10 450000 450000 10 ## ## [[2]] ## Ingresos Egresos Calificacion ## 1 4000000 3500000 80 ## 2 3500000 4000000 20 ## 3 3000000 3000000 50 ## 4 2500000 2000000 70 ## 5 2000000 1000000 70 ## 6 1500000 1400000 45 ## 7 1000000 1000000 40 ## 8 750000 800000 10 ## 9 500000 500000 12 ## 10 450000 450000 10 ## ## [[3]] ## Ingresos Egresos Calificacion ## 1 4000000 3500000 80 ## 2 3500000 4000000 20 ## 3 3000000 3000000 50 ## 4 2500000 2000000 70 ## 5 2000000 1000000 70 ## 6 1500000 1400000 45 ## 7 1000000 1000000 40 ## 8 750000 800000 10 ## 9 500000 500000 12 ## 10 450000 450000 10 lapply(dataset.list, &quot;[&quot;, 1, 1) # una lista con 3 veces: 4000000 o 4e+06 ## [[1]] ## [1] 4e+06 ## ## [[2]] ## [1] 4e+06 ## ## [[3]] ## [1] 4e+06 # donde [ se refiere a los segundos corchetes ya que R sabe que estamos iterando sobre los elementos de una lista. # lapply(dataset.list, &quot;[&quot;, 1, 1) es igual a: # dataset.list[[1]][1,1]; dataset.list[[2]][1,1]; dataset.list[[3]][1,1] Utilizando lapply() y la función rowMeans(), determinar el promedio de cada fila para los 3 elementos (data frames) en datset.list Luego, en lugar de utilizar rowMeans(), aplicar una función (es decir, function (x)) para acceder al primer elemento de cada uno de los 3 data frames de dataset.list lapply(dataset.list, rowMeans) ## [[1]] ## [1] 2500026.7 2500006.7 2000016.7 1500023.3 1000023.3 966681.7 666680.0 ## [8] 516670.0 333337.3 300003.3 ## ## [[2]] ## [1] 2500026.7 2500006.7 2000016.7 1500023.3 1000023.3 966681.7 666680.0 ## [8] 516670.0 333337.3 300003.3 ## ## [[3]] ## [1] 2500026.7 2500006.7 2000016.7 1500023.3 1000023.3 966681.7 666680.0 ## [8] 516670.0 333337.3 300003.3 lapply(dataset.list, function(x) x[1,1]) # 3 veces: 4e+06 ## [[1]] ## [1] 4e+06 ## ## [[2]] ## [1] 4e+06 ## ## [[3]] ## [1] 4e+06 Calcular la diferencia (resta) entre los valores de la primera y la segunda fila para cada uno de los 3 data frames de dataset.list. Es decir, valores de la primera fila menos valores de la segunda fila lapply(dataset.list, function(z) z[1,] - z[2,]) # Ingresos y Egresos: 5e+05 Cali. 60 ## [[1]] ## Ingresos Egresos Calificacion ## 1 5e+05 -5e+05 60 ## ## [[2]] ## Ingresos Egresos Calificacion ## 1 5e+05 -5e+05 60 ## ## [[3]] ## Ingresos Egresos Calificacion ## 1 5e+05 -5e+05 60 7.5 sapply En comparación con el comando anterior de lapply(), el comando sapply() recibe una lista, pero devuelve un vector (o una matriz). En este sentido, sapply es una versión más simple de lapply, ya que se devuelve un vector (matriz) en lugar de una lista, lo que es más fácil a leer y entender. Ahora, extraer del data frame dataset.list de cada data frame el primer elemento, utilizando sapply() y observar la diferencia con respecto a lapply() sapply(dataset.list, &quot;[&quot;, 1, 1) # devuelve un vector con 3 elementos: [1] 4e+06 4e+06 4e+06 ## [1] 4e+06 4e+06 4e+06 Ahora, extraer la segunda columna (Egresos\") de cada uno de los 3 data frames en la lista (dataset.list) Luego, extraer los valores de la segunda fila de cada uno de los 3 data frames en la lista (dataset.list) Después, extraer los valores de la segunda fila de cada uno de los 3 data frames en la lista (dataset.list), pero únicamente los valores de las segunda hasta la tercera columna sapply(dataset.list, &quot;[&quot;, 2) # 2 para la segunda columna... (como vector) ## $Egresos ## [1] 3500000 4000000 3000000 2000000 1000000 1400000 1000000 800000 500000 ## [10] 450000 ## ## $Egresos ## [1] 3500000 4000000 3000000 2000000 1000000 1400000 1000000 800000 500000 ## [10] 450000 ## ## $Egresos ## [1] 3500000 4000000 3000000 2000000 1000000 1400000 1000000 800000 500000 ## [10] 450000 sapply(dataset.list, &quot;[&quot;, 2, ) # segunda fila, todas las columnas (como matriz) ## [,1] [,2] [,3] ## Ingresos 3500000 3500000 3500000 ## Egresos 4e+06 4e+06 4e+06 ## Calificacion 20 20 20 sapply(dataset.list, &quot;[&quot;, 2, 2:3) # segunda fila, columnas 2 hasta 3 (como matriz) ## [,1] [,2] [,3] ## Egresos 4e+06 4e+06 4e+06 ## Calificacion 20 20 20 ¿Cuál es el valor mínimo en cada fila de los 3 data frames de dataset.list? sapply(dataset.list, apply, 1, min) ## [,1] [,2] [,3] ## [1,] 80 80 80 ## [2,] 20 20 20 ## [3,] 50 50 50 ## [4,] 70 70 70 ## [5,] 70 70 70 ## [6,] 45 45 45 ## [7,] 40 40 40 ## [8,] 10 10 10 ## [9,] 12 12 12 ## [10,] 10 10 10 which.min(dataset.list[[1]][1,]) # indica que los valores mínimos son en la tercera columna (&quot;Calificacion&quot;) ## Calificacion ## 3 7.6 Ejercicio 6 Utilizar el conjunto de datos iris, que se instaló con R: data(iris) Ver la siguiente descripción al respecto: https://es.wikipedia.org/wiki/Conjunto_de_datos_flor_iris Mostrar las primeras 5 filas de iris en la pantalla Utlizando la función apply, calcular el promedio de cada columna del dataset iris, que contiene números Realizar el mismo cálculo, utilizando la función lapply (en lugar de apply()) Con base en los resultados obtenidos, explicar la diferencia entre apply y lapply Ahora bien, realizar el mismo cálculo (promedio de las columnas), pero utilizando un ciclo (bucle), aplicando la función for() "],["ajusteDistri.html", "Sección 8 Ajuste de datos a una distribución 8.1 Objetivo 8.2 Distribución normal 8.3 Distribución exponencial 8.4 Distribución uniforme 8.5 Distribución lognormal 8.6 Distribución Poisson (discreta) 8.7 Distribución binomial 8.8 Unir todo en un solo data frame 8.9 Realizar el ajuste 8.10 Ejercicio 7", " Sección 8 Ajuste de datos a una distribución 8.1 Objetivo Determinar, a cuál distribución se ajustan datos, utilizando el paquete rriskDistributions de R. Cargar el paquete / library rriskDistributions if(!require(rriskDistributions)) install.packages(&#39;rriskDistributions&#39;); library(rriskDistributions) ## Loading required package: rriskDistributions 8.2 Distribución normal Generar 1000 datos a partir de una distribución normal (función rnorm()) con media = 0 y sd = 1 (sd = standard deviation) Iniciar con una semilla 123 y finalmente mostrar las primeras seis filas de los datos generados set.seed(123) datos.norm &lt;- rnorm(1000, mean = 0, sd = 1) head(datos.norm) ## [1] -0.56047565 -0.23017749 1.55870831 0.07050839 0.12928774 1.71506499 Graficar los datos, utilizando un histograma hist(datos.norm) 8.3 Distribución exponencial Generar 1000 datos a partir una distribución exponencial (función rexp()). Iniciar con una semilla 123 y finalmente mostrar las primeras seis filas de los datos generados set.seed(123) datos.exp &lt;- rexp(1000) # mostrar los primeros 6 datos head(datos.exp) ## [1] 0.84345726 0.57661027 1.32905487 0.03157736 0.05621098 0.31650122 Graficar los datos, utilizando un histograma hist(datos.exp) 8.4 Distribución uniforme Generar 1000 datos a partir una distribución uniforme (función runif(), con min = 0 y max = 50). Iniciar con una semilla 123 y finalmente mostrar las primeras seis filas de los datos generados set.seed(123) datos.unif &lt;- runif(1000, min = 0, max = 10) # mostrar los primeros 6 datos head(datos.unif) ## [1] 2.875775 7.883051 4.089769 8.830174 9.404673 0.455565 Graficar los datos en un histograma hist(datos.unif) 8.5 Distribución lognormal Generar 1000 datos a partir una distribución lognormal (función log(), con mean = 10, sd = 2.5): log(m^2 / sqrt(s^2 + m^2)) Utilizar la siguiente referencia como ayuda: https://msalganik.wordpress.com/2017/01/21/making-sense-of-the-rlnorm-function-in-r/ Iniciar con una semilla 123 y finalmente mostrar las primeras seis filas de los datos generados # source: https://msalganik.wordpress.com/2017/01/21/making-sense-of-the-rlnorm-function-in-r/ set.seed(123) m &lt;- 10 s &lt;- 2.5 location &lt;- log(m^2 / sqrt(s^2 + m^2)) shape &lt;- sqrt(log(1 + (s^2 / m^2))) print(paste(&quot;location:&quot;, location)) ## [1] &quot;location: 2.27227278208583&quot; print(paste(&quot;shape:&quot;, shape)) ## [1] &quot;shape: 0.24622067706924&quot; datos.lognorm &lt;- rlnorm(1000, location, shape) # mostrar los primeros 6 datos head(datos.lognorm) ## [1] 8.450893 9.166892 14.240058 9.871318 10.015222 14.798965 # prueba mean(datos.lognorm) ## [1] 10.03593 sd(datos.lognorm) ## [1] 2.504223 Graficar los datos, utilizando un histograma hist(datos.lognorm) 8.6 Distribución Poisson (discreta) Generar 1000 datos a partir una distribución Poisson, que es una distribución discreta (función rpois(), rate = 10, donde rate = cantidad de eventos en promedio por periodo). Iniciar con una semilla 123 y finalmente mostrar las primeras seis filas de los datos generados set.seed(123) rate = 10 # cantidad de eventos en promedio por periodo datos.poiss &lt;- rpois(1000, rate) # mostrar los primeros 6 datos head(datos.poiss) ## [1] 8 9 14 10 10 15 Graficar los datos en un histograma hist(datos.poiss) 8.7 Distribución binomial Generar 1000 datos a partir una distribución binomial (0 y 1), utilizando la función rbinom() con: n=1 # Bernoulli trials, p=.5 # probabilidad Iniciar con una semilla 123 y finalmente mostrar las primeras seis filas de los datos generados set.seed(123) n=1 # Bernoulli trials p=.5 # definir la probabilidad datos.binom &lt;- rbinom(1000,n,p) # cada vez diferente # mostrar los primeros 6 datos head(datos.binom) ## [1] 0 1 0 1 1 0 # tabla table(datos.binom) ## datos.binom ## 0 1 ## 507 493 Graficar los datos, utilizando un histograma hist(datos.binom) 8.8 Unir todo en un solo data frame Unir datos.norm, datos.exp, datos.unif, datos.lognorm y datos.poiss en un solo data frame con el nombre datos datos &lt;- data.frame(normal = datos.norm, expon = datos.exp, uniforme = datos.unif, logn = datos.lognorm, poiss = datos.poiss) 8.9 Realizar el ajuste Utilizar la función fit.cont() del paquete rriskDistributions para distribuciones continuas con el fin de realizar el ajuste. Nota: Este proceso es pesado y se demora un rato  Finalmente, se abre una nueva ventana, que informa sobre la distribución más ajustada. Esta figura no se muestra a continuación. Sin embargo, el resultado se presentará en una tabla library(rriskDistributions) # utilizar la función fit.cont() para distribuciones continuas res1 &lt;- fit.cont(datos$normal) ## ## Begin fitting distributions --------------------------------------- ## * fitting normal distribution ... OK ## * fitting Cauchy distribution ... OK ## * fitting logistic distribution ... OK ## * fitting beta distribution ... failed ## * fitting exponential distribution ... failed ## * fitting chi-square distribution ... failed ## * fitting uniform distribution ... OK ## * fitting gamma distribution ... failed ## * fitting lognormal distribution ... failed ## * fitting Weibull distribution ... failed ## * fitting F-distribution ... failed ## * fitting Student&#39;s t-distribution ... OK ## * fitting Gompertz distribution ... failed ## * fitting triangular distribution ... failed ## End fitting distributions ----------------------------------------- ## logL AIC BIC Chisq(value) Chisq(p) AD(value) H(AD) ## Normal -1410.1 2824.2 2834.01 17.91 0.85 0.30 not rejected ## Cauchy -1583.96 3171.91 3181.73 216.84 0.00 11.99 rejected ## Logistic -1419.22 2842.43 2852.25 19.91 0.75 0.58 not rejected ## Uniform NULL NULL NULL Inf 0.00 Inf NULL ## Student -1410.68 2823.37 2828.28 17.88 0.88 0.40 NULL ## KS(value) H(KS) ## Normal 0.02 not rejected ## Cauchy 0.08 rejected ## Logistic 0.02 not rejected ## Uniform 0.07 rejected ## Student 0.02 not rejected ## ## Chosen continuous distribution is: NA ## Fitted parameters are: ## [1] NA #res2 &lt;- fit.cont(datos$expon) # quitar el # #res3 &lt;- fit.cont(datos$uniforme) # quitar el # #res4 &lt;- fit.cont(datos$logn) # quitar el # #res5 &lt;- fit.cont(datos$poiss) # quitar el # 8.10 Ejercicio 7 Generar en R 15 números aleatorios, con base en una distribución uniforme, entre 1 (mínimum) y 50 (máximum) y asignar el resultado a una variable vector.aleatorio1 Luego, generar en R otros 15 números aleatorios, con base en una distribución normal, con una media de 0 y una desviación estándar de 1, y asignar el resultado a una variable vector.aleatorio2 Combinar los valores de los 2 vectores en un único vector vector.aleatorio3 en R / RStudio Realizar el ajuste a la distribución, utilizando el paquete rriskDistributions "],["regLineal.html", "Sección 9 Un modelo lineal sencillo (regresión lineal) 9.1 Objetivo 9.2 Cargar datos sobre carros 9.3 Crear el modelo lineal (regresión lineal) 9.4 Realizar una predicción 9.5 Un segundo ejemplo sencillo", " Sección 9 Un modelo lineal sencillo (regresión lineal) 9.1 Objetivo Construir un modelo lineal para realizar una predicción. Aquí esta predicción se refiere a un puntaje (score) que refleja la eficiencia de un carro con respecto al consumo de gasolina. 9.2 Cargar datos sobre carros Utilizar el dataset mtcars, que viene con la instalación de R: data(mtcars) Primero, analizar estos datos con la función View() Asignar estos datos a un data frame df y Mostrar las primeras seis filas de df y adicionalmente mostrar la clase de df data(&quot;mtcars&quot;) View(mtcars) df &lt;- mtcars head(df) ## mpg cyl disp hp drat wt qsec vs am gear carb ## Mazda RX4 21.0 6 160 110 3.90 2.620 16.46 0 1 4 4 ## Mazda RX4 Wag 21.0 6 160 110 3.90 2.875 17.02 0 1 4 4 ## Datsun 710 22.8 4 108 93 3.85 2.320 18.61 1 1 4 1 ## Hornet 4 Drive 21.4 6 258 110 3.08 3.215 19.44 1 0 3 1 ## Hornet Sportabout 18.7 8 360 175 3.15 3.440 17.02 0 0 3 2 ## Valiant 18.1 6 225 105 2.76 3.460 20.22 1 0 3 1 class(df) # data.frame ## [1] &quot;data.frame&quot; Colocar los nombres de los modelos de los carros en una primera columna (columna adicional) del data frame df. Esta nueva columna debe tener el nombre (título) modelos Esto se puede lograr combinando la función cbind(), que une columnas, con la función rownames(), que devuelve los nombre de las filas de un data frame Luego, analizar las primeras seis filas de df df &lt;- cbind(modelos = rownames(df), df) head(df) ## modelos mpg cyl disp hp drat wt qsec vs am ## Mazda RX4 Mazda RX4 21.0 6 160 110 3.90 2.620 16.46 0 1 ## Mazda RX4 Wag Mazda RX4 Wag 21.0 6 160 110 3.90 2.875 17.02 0 1 ## Datsun 710 Datsun 710 22.8 4 108 93 3.85 2.320 18.61 1 1 ## Hornet 4 Drive Hornet 4 Drive 21.4 6 258 110 3.08 3.215 19.44 1 0 ## Hornet Sportabout Hornet Sportabout 18.7 8 360 175 3.15 3.440 17.02 0 0 ## Valiant Valiant 18.1 6 225 105 2.76 3.460 20.22 1 0 ## gear carb ## Mazda RX4 4 4 ## Mazda RX4 Wag 4 4 ## Datsun 710 4 1 ## Hornet 4 Drive 3 1 ## Hornet Sportabout 3 2 ## Valiant 3 1 9.3 Crear el modelo lineal (regresión lineal) Generar un modelo de una regresión lineal, utilizando la función lm() y asignar el resultado del modelo a una variable (objeto) lin.mod Generar el modelo con las siguientes variables de entrada: cyl + wt + hp Investigar primero sobre esta función lm (con F1) antes de utilizarla. Finalmente, mostrar el contenido de lin.mod (del modelo construido) en la pantalla, utilizando la función print() lin.mod &lt;- lm(mpg ~ cyl + wt + hp, data = df) print(lin.mod) ## ## Call: ## lm(formula = mpg ~ cyl + wt + hp, data = df) ## ## Coefficients: ## (Intercept) cyl wt hp ## 38.75179 -0.94162 -3.16697 -0.01804 Revisar el resumen (estadístico) del modelo lineal generado, que arroja los coeficientes y el valor p para cada variable. ¿Cómo se interpretan los valores p? summary(lin.mod) ## ## Call: ## lm(formula = mpg ~ cyl + wt + hp, data = df) ## ## Residuals: ## Min 1Q Median 3Q Max ## -3.9290 -1.5598 -0.5311 1.1850 5.8986 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 38.75179 1.78686 21.687 &lt; 2e-16 *** ## cyl -0.94162 0.55092 -1.709 0.098480 . ## wt -3.16697 0.74058 -4.276 0.000199 *** ## hp -0.01804 0.01188 -1.519 0.140015 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 2.512 on 28 degrees of freedom ## Multiple R-squared: 0.8431, Adjusted R-squared: 0.8263 ## F-statistic: 50.17 on 3 and 28 DF, p-value: 2.184e-11 9.4 Realizar una predicción Realizar una predicción, utilizando el modelo generado (lin.mod) y la función predict() y asignar el resultado a una variable mpgScore como columna adicional del data frame df. Donde mpg = miles per galón. Esta función predict () requiere dos parámetros: Un modelo (aquí: lin.mod) y datos (aquí: df\") Nota: El resultado de la predicción se refiere a un puntaje (score) que refleja la cantidad de millas que corre un carro con un galón de gasolina. Es decir, el score se refiere a la eficiencia de un carro con respecto al consumo de gasolina. Luego, analizar las primeras seis filas del data frame df, y en particular los valores de la nueva columna mpgScore df$mpgScore &lt;- predict(lin.mod, df) head(df) ## modelos mpg cyl disp hp drat wt qsec vs am ## Mazda RX4 Mazda RX4 21.0 6 160 110 3.90 2.620 16.46 0 1 ## Mazda RX4 Wag Mazda RX4 Wag 21.0 6 160 110 3.90 2.875 17.02 0 1 ## Datsun 710 Datsun 710 22.8 4 108 93 3.85 2.320 18.61 1 1 ## Hornet 4 Drive Hornet 4 Drive 21.4 6 258 110 3.08 3.215 19.44 1 0 ## Hornet Sportabout Hornet Sportabout 18.7 8 360 175 3.15 3.440 17.02 0 0 ## Valiant Valiant 18.1 6 225 105 2.76 3.460 20.22 1 0 ## gear carb mpgScore ## Mazda RX4 4 4 22.82043 ## Mazda RX4 Wag 4 4 22.01285 ## Datsun 710 4 1 25.96040 ## Hornet 4 Drive 3 1 20.93608 ## Hornet Sportabout 3 2 17.16780 ## Valiant 3 1 20.25036 9.5 Un segundo ejemplo sencillo 9.5.1 Utilidad en función del gasto para publicidad Los datos: utilidades: 13, 14, 12, 14, 15 (millones $) publicadad: 5, 9, 5, 8, 9 (millones $) Generar un data frame con estos datos utilidad &lt;- c(13, 14, 12, 14, 15) publicidad &lt;- c(5, 9, 5, 8, 9) datosPubl &lt;- data.frame(utilidad, publicidad) print(datosPubl) ## utilidad publicidad ## 1 13 5 ## 2 14 9 ## 3 12 5 ## 4 14 8 ## 5 15 9 Graficar, utilizando el paquete ggplot2, la dispersión de los datos (publicidad vs utilidad) library(ggplot2) ggplot(datosPubl, aes(x = publicidad, y = utilidad)) + geom_point() Generar el modelo de una regresión lineal con la función lm() y asignar el resultado a una variable modelo.lineal modelo.lineal &lt;- lm(utilidad ~ publicidad, data = datosPubl) Generar el resumen estadístico del modelo generado summary(modelo.lineal) ## ## Call: ## lm(formula = utilidad ~ publicidad, data = datosPubl) ## ## Residuals: ## 1 2 3 4 5 ## 5.000e-01 -5.000e-01 -5.000e-01 3.608e-16 5.000e-01 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 10.0000 1.0465 9.555 0.00243 ** ## publicidad 0.5000 0.1409 3.550 0.03810 * ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.5774 on 3 degrees of freedom ## Multiple R-squared: 0.8077, Adjusted R-squared: 0.7436 ## F-statistic: 12.6 on 1 and 3 DF, p-value: 0.0381 Mostrar los coeficientes para el modelo generado modelo.lineal$coefficients ## (Intercept) publicidad ## 10.0 0.5 Supuesto: $ 12 (millones) de gasto para publicidad Ahora, utilizar los coefficientes para indicar, cuánta utilidad generan estos 12 millones de publicidad, segun este modelo lineal 10 + 0.5 * 12 # 16 ## [1] 16 # Es decir, con 12 millones de publicidad se generan 16 millones de utilidad "],["electre1.html", "Sección 10 MCDA: Outranking - sobre calificación 10.1 Objetivo y contextualización 10.2 Generar datos 10.3 Leer los datos desde un archivo de Excel 10.4 Analizar el paquete Outranking Tools y la función electre_1() 10.5 Transformar los datos al formato requerido", " Sección 10 MCDA: Outranking - sobre calificación 10.1 Objetivo y contextualización Uno de los riesgos que enfrentan las instituciones financieras y demás organizaciones tiene que ver con las personas. Una parte de este riesgo se refiere al proceso de la contratación del personal y como las organizaciones toman esas decisiones de la selección del personal. La selección de personal, en este caso para el área de la gestión de riesgos, requiere de la toma de decisiones, en la cual intervienen múltiples criterios. En el siguiente caso hipotético sencillo tenemos tres candidatos (alternativas) para el puesto del CRO (chief risk officer) en una entidad financiera, con sus respectivas características, ya evaluadas por expertos de la empresa. La siguiente tabla muestra, en las columnas, los tres candidatos para el cargo / puesto. En las filas se muestran los criterios de evaluación para los candidatos (personal). Para cada candidato se muestran los datos (valores numéricos) correspondientes que lo caracterizan. Donde: 1 = no tan bueno; 10 = mejor calificación posible. En la columna MiniMax se indica para cada uno de los criterios, si este se debe minimizar o maximizar. En el presente ejemplo, los valores de todos los criterios se deben maximizar. La columna Peso indica el peso (la ponderación) para cada criterio. Para seleccionar la mejor alternativa, basado en estos criterios, la institución financiera pide su ayuda. La institución quiere que usted aplique el método ELECTRE_1() para evaluar las alternativas (candidatos). Usted debe aplicar ELECTRE basado en el paquete OutrankingTools de R, que implementa los algoritmos de sobre clasificación (outranking), que se pueden aplicar a estos problemas de MCDA (multiple criteria decision analysis). ¿Cuál candidato se debe seleccionar? Es decir, ¿cuál candidato sobre califica (outranks) a otro? 10.2 Generar datos Primero, generar manualmente un archivo en MS-Excel (xlsx) con los siguientes datos: Alternativa1 Alternativa2 Alternativa3 MinMax Peso Criterio Daniela Jaime Alejandro Referencias 5 8 5 max 0.10 Experiencia 2 10 5 max 0.35 Educacion 8 6 8 max 0.35 Liderazgo 1 6 6 max 0.20 Determinar su directorio de trabajo para R, utilizando la función getwd() Pegar los datos, que se muestran en la tabla anterior, a la primera hoja del Excel Guardar los datos como archivo de Excel (xlsx), bajo el nombre electre_datos.xlsx, en su directorio de trabajo de R 10.3 Leer los datos desde un archivo de Excel Para leer los datos desde Excel, utilizar el paquete readxl de R library(readxl) mis.datos &lt;- read_excel(&#39;electre_datos.xlsx&#39;) # del working directory ## New names: ## * `` -&gt; ...1 View(mis.datos) 10.4 Analizar el paquete Outranking Tools y la función electre_1() Analizar el paquete Outranking Tools y la función Electre_1() mediante el comando ?Electre_1 (después de haber ejecutado el comando library(OutrankingTools)) library(OutrankingTools) ## Loading required package: igraph ## ## Attaching package: &#39;igraph&#39; ## The following object is masked from &#39;package:DescTools&#39;: ## ## %c% ## The following objects are masked from &#39;package:lubridate&#39;: ## ## %--%, union ## The following objects are masked from &#39;package:dplyr&#39;: ## ## as_data_frame, groups, union ## The following objects are masked from &#39;package:purrr&#39;: ## ## compose, simplify ## The following object is masked from &#39;package:tidyr&#39;: ## ## crossing ## The following object is masked from &#39;package:tibble&#39;: ## ## as_data_frame ## The following objects are masked from &#39;package:stats&#39;: ## ## decompose, spectrum ## The following object is masked from &#39;package:base&#39;: ## ## union ?Electre_1 10.5 Transformar los datos al formato requerido Vamos a transformar a continuación algunos datos al formato requerido por la función electre_1(). Asignar los valores de los datos, leídos desde Excel, para los siguientes dos parámetros: -alternativas y -criterios alternatives &lt;- as.character(mis.datos[1,c(2:4)]) class(alternatives) ## [1] &quot;character&quot; print(alternatives) ## [1] &quot;Daniela&quot; &quot;Jaime&quot; &quot;Alejandro&quot; criteria &lt;- as.character(mis.datos[-1,1]) class(criteria) ## [1] &quot;character&quot; print(criteria) ## [1] &quot;c(\\&quot;Referencias\\&quot;, \\&quot;Experiencia\\&quot;, \\&quot;Educacion\\&quot;, \\&quot;Liderazgo\\&quot;)&quot; Eliminar la primera fila, ya que esta no contiene números / valores relevantes mis.datos1 &lt;- mis.datos[-1, ] print(mis.datos1) ## # A tibble: 4 x 6 ## ...1 Alternativa1 Alternativa2 Alternativa3 MinMax Peso ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 Referencias 5 8 5 max 0.1 ## 2 Experiencia 2 10 5 max 0.35 ## 3 Educacion 8 6 8 max 0.35 ## 4 Liderazgo 1 6 6 max 0.2 Crear la matriz de desempeño (performance matrix) performanceMatrix &lt;- mis.datos1[, c(2:4)] print(performanceMatrix) ## # A tibble: 4 x 3 ## Alternativa1 Alternativa2 Alternativa3 ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 5 8 5 ## 2 2 10 5 ## 3 8 6 8 ## 4 1 6 6 Convertir los números a tipo de dato numeric performanceMatrix$Alternativa1 &lt;- as.numeric(performanceMatrix$Alternativa1) performanceMatrix$Alternativa2 &lt;- as.numeric(performanceMatrix$Alternativa2) performanceMatrix$Alternativa3 &lt;- as.numeric(performanceMatrix$Alternativa3) print(performanceMatrix) ## # A tibble: 4 x 3 ## Alternativa1 Alternativa2 Alternativa3 ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 5 8 5 ## 2 2 10 5 ## 3 8 6 8 ## 4 1 6 6 Transponer esta matriz performanceMatrix &lt;- t(performanceMatrix) print(performanceMatrix) ## [,1] [,2] [,3] [,4] ## Alternativa1 5 2 8 1 ## Alternativa2 8 10 6 6 ## Alternativa3 5 5 8 6 Asignar al parámetro criteriaweights los datos correspondientes, leídos del archivo de Excel criteriaWeights &lt;- as.numeric(mis.datos1$Peso) print(criteriaWeights) ## [1] 0.10 0.35 0.35 0.20 Asignar los datos correspondientes al parámetro minimaxcriteria, leídos de del archivo de Excel minmaxcriteria &lt;- mis.datos1$MinMax print(minmaxcriteria) ## [1] &quot;max&quot; &quot;max&quot; &quot;max&quot; &quot;max&quot; Corregir el tipo de dato de la variable criteria para que realmente haya un vector de criteria Esto se puede lograr mediante: as.character(unlist(mis.datos[-1,1])) print(criteria) # criteria como está actualmente ## [1] &quot;c(\\&quot;Referencias\\&quot;, \\&quot;Experiencia\\&quot;, \\&quot;Educacion\\&quot;, \\&quot;Liderazgo\\&quot;)&quot; print(mis.datos) ## # A tibble: 5 x 6 ## ...1 Alternativa1 Alternativa2 Alternativa3 MinMax Peso ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 Criterio Daniela Jaime Alejandro &lt;NA&gt; NA ## 2 Referencias 5 8 5 max 0.1 ## 3 Experiencia 2 10 5 max 0.35 ## 4 Educacion 8 6 8 max 0.35 ## 5 Liderazgo 1 6 6 max 0.2 #corrección: #criteria &lt;- mis.datos1$..1 #usar notación &quot;...$...&quot; con mis.datos1 o unlist con mis.datos: criteria &lt;- as.character(unlist(mis.datos[-1,1])) # mejor para no utilizar $..1 print(criteria) ## [1] &quot;Referencias&quot; &quot;Experiencia&quot; &quot;Educacion&quot; &quot;Liderazgo&quot; Ejecutar la función Electre_1() y asignar el resultado a una variable overall Utilizar, para los últimos dos parámetros que requiere Electre_1, lo siguiente: concordance_threshold = 0.6, discordance_threshold = 0.4 Observar el resultado, en particular la gráfica del outranking de los candidatos overall &lt;- Electre_1(performanceMatrix, alternatives, criteria, criteriaWeights, minmaxcriteria, concordance_threshold = 0.6, discordance_threshold = 0.4) Utilizando la variable overall, imprimir a la pantalla la Performance Matrix. Es decir, el contenido de la matriz de desempeño #performanceMatrix overall$`Performance Matrix` # o print(overall[[1]]) ## Referencias Experiencia Educacion Liderazgo ## Daniela 5 2 8 1 ## Jaime 8 10 6 6 ## Alejandro 5 5 8 6 #ConcordanceMatrix overall$`Concordance Matrix` ## Daniela Jaime Alejandro ## Daniela 1.00 0.35 0.45 ## Jaime 0.65 1.00 0.65 ## Alejandro 1.00 0.55 1.00 #DiscordanceMatrix overall$`Discordance Matrix` ## Daniela Jaime Alejandro ## Daniela 0.00 1.000 0.625 ## Jaime 0.25 0.000 0.250 ## Alejandro 0.00 0.625 0.000 "],["ahp.html", "Sección 11 Modelo AHP (Analytical Hierarchy Process) 11.1 Objetivo 11.2 Cargar el paquete MCDA 11.3 alternativesPairwiseComparisonsList 11.4 Mostrar resultado con AHP", " Sección 11 Modelo AHP (Analytical Hierarchy Process) 11.1 Objetivo El objetivo aquí es parecido al tema anterior (electre) y consiste en tomar una decisión multicriterio (MCDA - multiple criteria decision analysis). De acuerdo con lo anterior, esta sección es para el problema de seleccionar entre Tom, Dick, &amp; Harry como líder (problema de selección de personal): https://en.wikipedia.org/wiki/Analytic_hierarchy_process_%E2%80%93_leader_example El ejemplo concreto aquí es de Nicole Radziwill: http://qualityandinnovation.com/2016/01/04/analytic-hierarchy-process-ahp-with-the-ahp-package/ 11.2 Cargar el paquete MCDA MCDA - Multiple Criteria Decision Model 3 candidatos / alternativas de decisión: Tom, Dick y Harry (ejemplo ver wikipedia) 4 criterios de decision: Experiencia Educación Carisma Edad Leer los datos desde el archivo ahp_con_MCDA_cl.xlsx library(MCDA) library(readxl) data &lt;- read_excel(&#39;ahp_con_MCDA.xlsx&#39;) ## New names: ## * `` -&gt; ...2 ## * `` -&gt; ...3 ## * `` -&gt; ...4 ## * `` -&gt; ...5 print(data) ## # A tibble: 35 x 5 ## `Critería:` ...2 ...3 ...4 ...5 ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 CR1: Experiencia &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; ## 2 CR2: Educación &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; ## 3 CR3: Carisma &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; ## 4 CR4: Edad &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; ## 5 Alternativas: &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; ## 6 ALT1: Tom &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; ## 7 ALT2: Dick &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; ## 8 ALT3: Harry &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; ## 9 Matrices: &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; ## 10 &lt;NA&gt; CR 1 CR 2 CR 3 CR 4 ## # ... with 25 more rows Mejor, leer desde el archivo de Excel por partes: criterias de decision (que están en las celdas B3:C6) criteria &lt;- read_excel(&#39;ahp_con_MCDA.xlsx&#39;, sheet=&#39;ahp&#39;, col_names=FALSE, range=&#39;B3:C6&#39;) ## New names: ## * `` -&gt; ...1 ## * `` -&gt; ...2 print(criteria) ## # A tibble: 4 x 2 ## ...1 ...2 ## &lt;chr&gt; &lt;chr&gt; ## 1 CR1: Experiencia ## 2 CR2: Educación ## 3 CR3: Carisma ## 4 CR4: Edad # sin tilde educación criteria[2,2] &lt;- c(&quot;Educacion&quot;) alternativas de decisión (celdas B8:C10) alternativas &lt;- read_excel(&#39;ahp_con_MCDA.xlsx&#39;, sheet=&#39;ahp&#39;, col_names=FALSE, range=&#39;B8:C10&#39;) ## New names: ## * `` -&gt; ...1 ## * `` -&gt; ...2 print(alternativas) ## # A tibble: 3 x 2 ## ...1 ...2 ## &lt;chr&gt; &lt;chr&gt; ## 1 ALT1: Tom ## 2 ALT2: Dick ## 3 ALT3: Harry matriz de calificación de critrios (por expertos) leer estos datos desde el Excel (B12:F16) criteria.calif &lt;- read_excel(&#39;ahp_con_MCDA.xlsx&#39;, sheet=&#39;ahp&#39;, col_names=TRUE, range=&#39;B12:F16&#39;) ## New names: ## * `` -&gt; ...1 print(criteria.calif) ## # A tibble: 4 x 5 ## ...1 `CR 1` `CR 2` `CR 3` `CR 4` ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 CR 1 NA 4 3 7 ## 2 CR 2 0.25 NA 0.333 3 ## 3 CR 3 0.333 3 NA 5 ## 4 CR 4 0.143 0.333 0.2 NA reemplazar NAs por 1 (diagonal de la matriz) criteria.calif[is.na(criteria.calif)] = 1.0 preparar el comparativo por parejas, utilizando la matriz de los criterios ya calificados (criteria.calif) sin los nombres de las filas y asignar el resultado a una variable criteriaWeightsPairwiseComparisons criteriaWeightsPairwiseComparisons &lt;- as.matrix(criteria.calif[,2:5]) criteriaWeightsPairwiseComparisons ## CR 1 CR 2 CR 3 CR 4 ## [1,] 1.0000000 4.0000000 3.0000000 7 ## [2,] 0.2500000 1.0000000 0.3333333 3 ## [3,] 0.3333333 3.0000000 1.0000000 5 ## [4,] 0.1428571 0.3333333 0.2000000 1 asignar a este resultado nombres de las columnas y filas, utilizando la función t() que significa transponer colnames(criteriaWeightsPairwiseComparisons) = t(criteria[,2]) rownames(criteriaWeightsPairwiseComparisons) = t(criteria[,2]) criteriaWeightsPairwiseComparisons ## Experiencia Educacion Carisma Edad ## Experiencia 1.0000000 4.0000000 3.0000000 7 ## Educacion 0.2500000 1.0000000 0.3333333 3 ## Carisma 0.3333333 3.0000000 1.0000000 5 ## Edad 0.1428571 0.3333333 0.2000000 1 realizar el comparativo de las alternativas para cada criterio empezando con el criterio experiencia (experiencia comparison matriz) y leyendo esta parte del archivo de Excel # experiencia experiencia &lt;- read_excel(&#39;ahp_con_MCDA.xlsx&#39;, sheet=&#39;ahp&#39;, col_names=TRUE, range=&#39;B18:E21&#39;) experiencia[is.na(experiencia)] = 1.0 experiencia &lt;- as.matrix(experiencia[,-1]) colnames(experiencia) = t(alternativas[,2]) rownames(experiencia) = t(alternativas[,2]) experiencia ## Tom Dick Harry ## Tom 1.00 0.2500000 4 ## Dick 4.00 1.0000000 9 ## Harry 0.25 0.1111111 1 luego, lo mismo para el criterio educación # educacion edu &lt;- read_excel(&#39;ahp_con_MCDA.xlsx&#39;, sheet=&#39;ahp&#39;, col_names=TRUE, range=&#39;B24:E27&#39;) edu[is.na(edu)] = 1.0 edu &lt;- as.matrix(edu[,-1]) colnames(edu) = t(alternativas[,2]) rownames(edu) = t(alternativas[,2]) edu ## Tom Dick Harry ## Tom 1.0000000 3 0.2000000 ## Dick 0.3333333 1 0.1428571 ## Harry 5.0000000 7 1.0000000 #str(edu) luego, para el criterio carisma # carisma carisma &lt;- read_excel(&#39;ahp_con_MCDA.xlsx&#39;, sheet=&#39;ahp&#39;, col_names=TRUE, range=&#39;B29:E32&#39;) carisma[is.na(carisma)] = 1.0 carisma &lt;- as.matrix(carisma[,-1]) colnames(carisma) = t(alternativas[,2]) rownames(carisma) = t(alternativas[,2]) carisma ## Tom Dick Harry ## Tom 1.0000000 5.00 9 ## Dick 0.2000000 1.00 4 ## Harry 0.1111111 0.25 1 luego para el criterio edad # edad edad &lt;- read_excel(&#39;ahp_con_MCDA.xlsx&#39;, sheet=&#39;ahp&#39;, col_names=TRUE, range=&#39;B34:E37&#39;) edad[is.na(edad)] = 1.0 edad &lt;- as.matrix(edad[,-1]) colnames(edad) = t(alternativas[,2]) rownames(edad) = t(alternativas[,2]) edad ## Tom Dick Harry ## Tom 1.0 0.3333333 5 ## Dick 3.0 1.0000000 9 ## Harry 0.2 0.1111111 1 11.3 alternativesPairwiseComparisonsList Después, generar el alternativesPairwiseComparisonsList (ver también la documentación de MCDA para AHP) alternativesPairwiseComparisonsList &lt;- list(Experiencia=experiencia, Educacion=edu, Carisma=carisma, Edad=edad) # str(alternativesPairwiseComparisonsList) 11.4 Mostrar resultado con AHP Finalmente, mostrar el resultado, utilizando la función AHP() del paquete MCDA overall1 &lt;- AHP(criteriaWeightsPairwiseComparisons, alternativesPairwiseComparisonsList) overall1 ## Tom Dick Harry ## 0.3581368 0.4927882 0.1490750 Observar el resultado, en términos de los pesos asginados por esta función AHP: Tom Dick Harry 0.3581368 0.4927882 0.1490750 Conclusión: Se debe seleccionar la alternativa Dick, ya que él es la persona que obtuvo el mayor puntaje (49%), tomando en cuenta todos los criterios de decisión. "],["fuzzy.html", "Sección 12 Modelo fuzzy (borroso) 12.1 Objetivo y contextualización 12.2 Definir el universo (universe) 12.3 Definir las variables 12.4 Fuzzy rules - reglas borrosas 12.5 Definir el modelo borroso 12.6 Dos ejemplos fuzzy 12.7 Finalmente se debe resetear el universo", " Sección 12 Modelo fuzzy (borroso) 12.1 Objetivo y contextualización El objetivo consiste en presentar una solución para un problema borroso, donde borroso significa que los valores de las variables no representan un número exacto (crisp value), sino un rango, en términos de un conjunto borroso (fuzzy set). Este ejemplo se adaptó de: Juan De Dios Santos: https://github.com/juandes/FuzzyLogic-R y https://github.com/juandes/FuzzyLogic-R/blob/master/fuzzy_script.R El problema a solucionar se refiere a la selección de personal basado en la aptitud de las personas, que a su vez depende de tres variables (de entrada). Todas las variables son cualitativas y borrosas (fuzzy) como se muestra a continuación. Los valores (tres) de cada variable de entrada determinan, siguiendo las reglas que se muestran a continuación, el valor de la variable de salida (aptitud). Se utiliza el paquete de R sets: library(sets) Más detalles para el paquete sets se pueden consultar aquí: https://cran.r-project.org/web/packages/sets/index.html if(!require(sets)) install.packages(&#39;sets&#39;); library(sets) ## Loading required package: sets ## Registered S3 method overwritten by &#39;sets&#39;: ## method from ## print.element ggplot2 ## ## Attaching package: &#39;sets&#39; ## The following object is masked from &#39;package:igraph&#39;: ## ## %&gt;% ## The following object is masked from &#39;package:tidyquant&#39;: ## ## %&gt;% ## The following objects are masked from &#39;package:lubridate&#39;: ## ## as.interval, interval, is.interval ## The following object is masked from &#39;package:rvest&#39;: ## ## %&gt;% ## The following object is masked from &#39;package:forcats&#39;: ## ## %&gt;% ## The following object is masked from &#39;package:stringr&#39;: ## ## %&gt;% ## The following object is masked from &#39;package:dplyr&#39;: ## ## %&gt;% ## The following object is masked from &#39;package:purrr&#39;: ## ## %&gt;% ## The following object is masked from &#39;package:tidyr&#39;: ## ## %&gt;% ## The following object is masked from &#39;package:tibble&#39;: ## ## %&gt;% 12.2 Definir el universo (universe) Definir el universo, utilizando las funciones sets_options() y seq(), donde esta última genera una secuencia (sequence) de 1000 números entre 1 y 100 con un paso entre estos de 0.1 sets_options(universe, seq(1, 100, 0.1)) sets_options(&quot;universe&quot;, seq(1, 100, 0.1)) 12.3 Definir las variables Aquí, se definene tres variables lingüísticas de entrada y una variable de salida (aquí aptitud). Definir las siguientes tres variables de entrada, de forma borrosa (fuzzy): -experiencia -educación y -carisma La variable de salida, que se debe definir también de forma borrosa, es la aptitud. De acuerdo con lo anterior, borroso significa aquí, que los valores de las variables no representan un número exacto (crisp value), sino un rango que define una variable cualitativa (lingüística) por un conjunto borroso (fuzzy set). Por ejemplo, en el siguiente caso la variable (de entrada) experiencia, que caracteriza una persona (empleado potencial), está definida por un rango que va desde 30 hasta 90, donde 30 significa poca experiencia, el valor 90 significa mucha experiencia y un tercer valor 70 en este caso, significa experiencia aceptable. Para las demás variables, incluyendo la variable de salida, aplica esta misma lógica, definiendolas como variables borrosas de la siguiente forma en R: variables &lt;- set( experiencia = fuzzy_partition(varnames = c(poca = 30, aceptable = 70, mucha = 90), sd = 5.0), educacion = fuzzy_partition(varnames = c(baja = 30, media = 60, alta = 80), sd = 3.0), carisma = fuzzy_partition(varnames = c(poco = 30, medio = 60, alto = 90), sd = 7.5), aptitud = fuzzy_partition(varnames = c(poca = 40, ok = 65, perfecta = 80), FUN = fuzzy_cone, radius = 10) ) variables &lt;- set( experiencia = fuzzy_partition(varnames = c(poca = 30, aceptable = 70, mucha = 90), sd = 5.0), educacion = fuzzy_partition(varnames = c(baja = 30, media = 60, alta = 80), sd = 3.0), carisma = fuzzy_partition(varnames = c(poco = 30, medio = 60, alto = 90), sd = 7.5), aptitud = fuzzy_partition(varnames = c(poca = 40, ok = 65, perfecta = 80), FUN = fuzzy_cone, radius = 10) ) 12.4 Fuzzy rules - reglas borrosas Además, se tienen que definir reglas borrosas (fuzzy rules) de tipo si-entonces\" (if-then): Por ejemplo, la siguiente regla: Si la experiencia es aceptable y la educación es baja y el carisma es poco, entonces la aptitud es perfecta. y así se definen sucesivamente un conjunto de reglas borrosas: rules &lt;- set( fuzzy_rule(experiencia %is% aceptable &amp;&amp; educacion %is% baja &amp;&amp; carisma %is% poco, aptitud %is% perfecta), fuzzy_rule(experiencia %is% mucha &amp;&amp; educacion %is% alta &amp;&amp; carisma %is% alto, aptitud %is% poca), fuzzy_rule(experiencia %is% poca, aptitud %is% poca), fuzzy_rule(experiencia %is% aceptable || educacion %is% media || carisma %is% medio, aptitud %is% ok), fuzzy_rule(experiencia %is% mucha &amp;&amp; carisma %is% medio, aptitud %is% ok), fuzzy_rule(experiencia %is% mucha &amp;&amp; educacion %is% baja &amp;&amp; carisma %is% medio, aptitud %is% ok) ) rules &lt;- set( fuzzy_rule(experiencia %is% aceptable &amp;&amp; educacion %is% baja &amp;&amp; carisma %is% poco, aptitud %is% perfecta), fuzzy_rule(experiencia %is% mucha &amp;&amp; educacion %is% alta &amp;&amp; carisma %is% alto, aptitud %is% poca), fuzzy_rule(experiencia %is% poca, aptitud %is% poca), fuzzy_rule(experiencia %is% aceptable || educacion %is% media || carisma %is% medio, aptitud %is% ok), fuzzy_rule(experiencia %is% mucha &amp;&amp; carisma %is% medio, aptitud %is% ok), fuzzy_rule(experiencia %is% mucha &amp;&amp; educacion %is% baja &amp;&amp; carisma %is% medio, aptitud %is% ok) ) 12.5 Definir el modelo borroso Como tercer paso se define un modelo borroso de la siguiente forma, utilizando las variables variables y rules, previamente definidas: model &lt;- fuzzy_system(variables, rules) Esto modelo, con sus conjuntos borrosos, se puede mostrar en la pantalla: plot(model) Observe los diagramas generados para cada una de las variables. En particular, para la variable de entrada experiencia se sobrelapan las curvas, que representan los conjuntos borrosos, en el valor 80. Este sobrelapamiento caracteriza la borrosidad de la variable. ?fuzzy_system model &lt;- fuzzy_system(variables, rules) print(model) # imprime las variables y las reglas a la pantalla ## A fuzzy system consisting of 4 variables and 6 rules. ## ## Variables: ## ## aptitud(poca, ok, perfecta) ## educacion(baja, media, alta) ## experiencia(poca, aceptable, mucha) ## carisma(poco, medio, alto) ## ## Rules: ## ## experiencia %is% mucha &amp;&amp; carisma %is% medio =&gt; aptitud %is% ok ## experiencia %is% mucha &amp;&amp; educacion %is% alta &amp;&amp; carisma %is% =&gt; aptitud %is% poca ## alto =&gt; aptitud %is% poca ## experiencia %is% mucha &amp;&amp; educacion %is% baja &amp;&amp; carisma %is% =&gt; aptitud %is% ok ## medio =&gt; aptitud %is% ok ## experiencia %is% aceptable &amp;&amp; educacion %is% baja &amp;&amp; carisma %is% =&gt; aptitud %is% perfecta ## poco =&gt; aptitud %is% perfecta ## experiencia %is% aceptable || educacion %is% media || carisma %is% =&gt; aptitud %is% ok ## medio =&gt; aptitud %is% ok ## experiencia %is% poca =&gt; aptitud %is% poca plot(model) # imprime los conjuntos borrosos Nota: En la figura de la experiencia la calificación es aceptable (70) y mucha (90). Si el nivel (de experiencia) es 80, entonces este nivel de experiencia es aproximadamente 0.15 aceptable, 0.15 mucha y 0.0 poca. 12.6 Dos ejemplos fuzzy example.1 &lt;- fuzzy_inference(model, list(experiencia = 75, educacion = 0, carisma = 70)) plot(example.1) example.1 &lt;- fuzzy_inference(model, list(experiencia = 75, educacion = 0, carisma = 70)) plot(example.1) Ahora, defuzzificamos el ejemplo para transformar los parámetros en un número: gset_defuzzify(example.1, centroid) # 65 gset_defuzzify(example.1, &quot;centroid&quot;) # 65 ## [1] 65 Según el sistema, la aptitud es 0.65 ok (ver el diagrama de la aptitud). ¿Qué pasa, si el nivel de experiencia baja a 30 (75 en el ejemplo anterior)? example.2 &lt;- fuzzy_inference(model, list(experiencia = 30, educacion = 0, carisma = 70)) plot(example.2) example.2 &lt;- fuzzy_inference(model, list(experiencia = 30, educacion = 0, carisma = 70)) plot(example.2) y se realiza la defuzzificación: gset_defuzzify(example.2, largestofmax) gset_defuzzify(example.2, &quot;largestofmax&quot;) ## [1] 40 Respuesta: Si la experiencia baja a 30, el modelo disminuye la aptitud de ok a 0.4 (40), ver la figura, lo que significa, que la aptitud es 1.0 poca (es decir, la aptitud cambió de ok a poca). 12.7 Finalmente se debe resetear el universo Reseteando el universo (Reset universe), que se generó al principio, se hace en R de la siguiente forma: sets_options(universe, NULL) sets_options(&quot;universe&quot;, NULL) "],["muestreo.html", "Sección 13 Muestreo - sampling 13.1 Objetivo 13.2 Muestreo aleatorio simple - Simple Random Sampling 13.3 Proceso de muestreo para realizar una encuesta 13.4 Muestreo para un problema de datos masivos (big data) 13.5 Muestreo estratificado - Stratified sampling 13.6 Trabajar con potencia (power analysis) 13.7 Ejercicio 8", " Sección 13 Muestreo - sampling 13.1 Objetivo El objetivo consiste en presentar diferentes formas de construir una muestra, que representa una población, p.ej. para diseñar un experimento. 13.2 Muestreo aleatorio simple - Simple Random Sampling Fuente: https://dzone.com/articles/data-sampling-methods-in-r El contexto. Planeamos diseñar un experimento para una encuesta donde queremos saber, si a las personas les gustan nuestros productos. Las dos respuestas permitidas son Sí o No. Antes de enviar las encuestas a 500 personas, preparamos un análisis (ejemplo) para el que es necesario generar una muestra con una relación de respuesta de 9 : 1. Para simular esto podemos utilizar la función sample() de R de la siguiente forma: sample(0:1, 500, replace = TRUE, prob = c(0.90, 0.10)) Es decir, se generan aleatoriamente 500 números de 0 (No) y 1 (Sí), tomando en cuenta las probabilidades (pesos) dados para cada uno de estos dos números (0.9 y 0.1). sample(0:1, 500, replace = TRUE, prob = c(0.90, 0.10)) # nota: replace = TRUE ## [1] 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 ## [38] 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 ## [75] 1 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ## [112] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 ## [149] 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 ## [186] 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 ## [223] 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 ## [260] 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 ## [297] 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 ## [334] 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 ## [371] 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 ## [408] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 ## [445] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 ## [482] 0 0 0 1 0 0 0 1 1 0 0 0 0 1 1 0 0 0 1 13.3 Proceso de muestreo para realizar una encuesta En mercadeo, a menudo se genera nuevo conocimiento a través de encuestas. Dado que es costoso preguntar a toda una población numerosa, generalmente se trabaja con una muestra. Si la población es menor que 100.000 (personas), se puede proceder de la siguiente forma. Fuente: http://www.marketing-xxi.com/proceso-de-la-investigacion-de-mercados-i-24.htm 13.3.1 Creamos nuestra propia función en R Según: https://www.tutorialspoint.com/r/r_functions.htm, una función permite realizar una operación, como un cálculo, que se puede reutilizar de forma fácil. function_name &lt;- function(arg_1, arg_2, ) { Function body } En nuestro caso se trata de crear la función (llamémosla muestra.n) para calcular la muestra para una población con menos de 100.000 individuos: Donde: n = Número de elementos de la muestra. N = Número de elementos del universo (población). P/Q = Probabilidades con las que se presenta el fenómeno. Q = 1-P. Si P es desconocido el valor es 0,5 (50%). Z^2 = Valor crítico correspondiente al nivel de confianza elegido. E = Margen de error permitido (a determinar por el director del estudio). Típicamente 5% o 6%. muestra.n &lt;- function(N, P, Q, Z, E){ ((Z^2)*P*Q*N) / ((E^2)*(N-1)+(Z^2)*P*Q) } 13.3.2 Definir los valores para los parámetros de la función muestra.n Con: Z &lt;- 1.96 # 1.96 = 95% nivel de confianza P &lt;- 0.5 #0.5 Q &lt;- 1-P N &lt;- 1300 #1300 E &lt;- 0.05 #5% o 0.05 13.3.3 Llamar la función muestra.n y observar el resultado Se puede observar el resultado del cálculo del tamaño de la muestra, utilizando estos valores: muestra.n(N, P, Q, Z, E) Z &lt;- 1.96 # 1.96 = 95% nivel de confianza P &lt;- 0.5 # 0.5 Q &lt;- 0.5 # 1-P N &lt;- 1300 #1300 E &lt;- 0.05 #5% o 0.05 muestra.n(N, P, Q, Z, E) #296.7086 = 297 = n ## [1] 296.7086 13.3.4 Para poblaciones mayor que 100.000 personas Para poblaciones mayor que 100.000 la función es: muestra.n.2 &lt;- function(P, Q, Z, E){ ((Z^2) P*Q) / (E^2) } muestra.n.2 &lt;- function(P1, Q1, Z1, E1){ ((Z1^2)*P1*Q1) / (E1^2) } 13.3.5 Definir los valores para los parámetros de la función muestra.n.2 Z1 &lt;- 1.96 # 1.96 = 95% nivel de confianza P1 &lt;- 0.5 # 0.5 Q1 &lt;- 1-P N1 &lt;- 48000000 # 48000000 , p.ej. cantidad de habitantes de Colombia en el año 2018. Nota: N no se usa en la función. E1 &lt;- 0.05 # 5% o 0.05 13.3.6 Llamar (usar) la función muestra.n.2(P1, Q1, Z1, E1) con estos valores. Z1 &lt;- 1.96 # 1.96 = 95% nivel de confianza P1 &lt;- 0.5 # 0.5 Q1 &lt;- 0.5 # 1-P N1 &lt;- 48000000 # 48000000 , p.ej. cantidad de habitantes de Colombia en el año 2018. Nota: N no se usa en la función. E1 &lt;- 0.05 # 5% o 0.05 muestra.n.2(P1, Q1, Z1, E1) # 384.16 = 385 = n ## [1] 384.16 13.4 Muestreo para un problema de datos masivos (big data) El siguiente ejemplo se tomó de la siguiente fuente: https://medium.com/data-science-journal/how-to-correctly-select-a-sample-from-a-huge-dataset-in-machine-learning-24327650372c Lo que vamos a hacer es, considerar cada variable independientemente de las demás. Si cada uno de los histogramas únicos y univariados de las columnas de muestra es comparable con el histograma correspondiente de las columnas de población, podemos suponer que la muestra no está sesgada. Algunos de ustedes podrían pensar que estamos olvidando la correlación entre las variables. Esto no es del todo cierto si seleccionamos nuestra muestra de manera uniforme. Es ampliamente conocido que seleccionar una submuestra de manera uniforme producirá, con grandes números, la misma distribución de probabilidad de la población original. Potentes métodos de remuestreo como bootstrap se basan en este concepto. El histograma para variables categóricas se puede comparar utilizando un Pearsons chi-square test, mientras la función de la distribución cumulativa de variables numéricas se puede comparar utilizando un Kolmogorov-Smirnov test. Ambas pruebas estadísticas funcionan bajo la hipótesis nula de que la muestra tiene la misma distribución como la población. Dado que una muestra está compuesta por muchas columnas y queremos que todas sean significativas, podemos rechazar la hipótesis nula si el valor p de al menos una de las pruebas es inferior al nivel de confianza, habitualmente del 5%. En otras palabras, queremos que cada columna pase la prueba de significancia para aceptar la muestra como válida. Simulemos algunos datos (masivos). Crearemos una dataset con 1 millón de registros y 2 columnas. -El primero tiene 500,000 registros tomados de una distribución normal, mientras que los otros 500,000 registros se toman de una distribución uniforme. Esta variable está claramente sesgada y me ayudará a explicar los conceptos de significancia estadística más adelante. -El otro campo es una variable de factor creada usando las primeras 10 letras del alfabeto distribuidas uniformemente. set.seed(100), N = 1000000 # = 1e06, dataset = data.frame( # La variable x1 tiene un sesgo. Se toman los primeros 500 mil valores, # de una distribución normal, mientras que los 500 mil restantes, # se toman de una distribución uniforme, x1 = c( rnorm(N/2,0,1) , runif(N/2,0,1) ), # Variable categórica construida por las primeras 10 letras del alfabeto, x2 = sample(LETTERS[1:10],N,replace=TRUE) ) set.seed(100) N = 1000000 # = 1e06 dataset = data.frame( x1 = c( rnorm(N/2,0,1) , runif(N/2,0,1) ), x2 = sample(LETTERS[1:10],N,replace=TRUE) ) # La variable x1 tiene un sesgo. Se toman los primeros 500 mil valores # de una distribución normal, mientras que los 500 mil restantes # se toman de una distribución uniforme # X2: Variable categórica construida por las primeras 10 letras del alfabeto head(dataset) ## x1 x2 ## 1 -0.50219235 F ## 2 0.13153117 A ## 3 -0.07891709 F ## 4 0.88678481 J ## 5 0.11697127 G ## 6 0.31863009 A Ahora podemos intentar de crear una muestra compuesta por 10.000 registros del conjunto de datos original y verificar su significancia. Para cada prueba, almacenaremos su valor p en una lista con nombre para la verificación final. Si todos los valores p son superiores al 5%, podemos decir que la muestra no está sesgada. sample_size = 10000 set.seed(1) idxs = sample(1:nrow(dataset), sample_size, replace=F) subsample = dataset[idxs, ] pvalues = list() for (col in names(dataset)) { if (class(dataset[,col]) %in% c(numeric,integer)) { # Variable númerico. Utilizando Kolmogorov-Smirnov test pvalues[[col]] = ks.test(subsample[[col]],dataset[[col]])\\(p.value \\} else \\{ # Variable categórica. Utilizando Pearson&#39;s Chi-square test probs = table(dataset[[col]])/nrow(dataset) pvalues[[col]] = chisq.test(table(subsample[[col]]),p=probs)\\)p.value } } pvalues sample_size = 10000 set.seed(1) idxs = sample(1:nrow(dataset), sample_size, replace=F) subsample = dataset[idxs, ] pvalues = list() for (col in names(dataset)) { if (class(dataset[,col]) %in% c(&quot;numeric&quot;,&quot;integer&quot;)) { pvalues[[col]] = ks.test(subsample[[col]],dataset[[col]])$p.value } else { probs = table(dataset[[col]])/nrow(dataset) pvalues[[col]] = chisq.test(table(subsample[[col]]),p=probs)$p.value } } ## Warning in ks.test(subsample[[col]], dataset[[col]]): p-value will be ## approximate in the presence of ties pvalues ## $x1 ## [1] 0.4569533 ## ## $x2 ## [1] 0.6144188 # ks.test: Variable númerica. Utilizando Kolmogorov-Smirnov test # probs: Variable categórica. Utilizando Pearson&#39;s Chi-square test Cada uno de los valores p es superior al 5%, por lo que podemos decir, que la muestra es estadísticamente significativa. 13.5 Muestreo estratificado - Stratified sampling Fuente: https://dzone.com/articles/data-sampling-methods-in-r En el muestreo estratificado, la población de datos se divide en grupos y se toman muestras de cada grupo. La división de la población en grupos se llama strate, y la muestra aleatoria simple para cada grupo se llama stratum. Utilizamos el paquete dplyr (parte del tidyversee) y los datos iris, que vienen con la instalación de R. Agrupamos por especie. sample_iris &lt;- iris %&gt;% group_by(Species) %&gt;% sample_n(2) Nota: los datos iris tienen 150 observaciones y 5 variables Resultado: 6 observaciones de 5 variables = 2 de cada especie 13.6 Trabajar con potencia (power analysis) library(pwr) # Power analysis Ejemplo: Queremos medir el cambio de la productividad con respecto a una población (empresas de un determinado sector en una región). Conocemos o suponemos que el crecimiento de la productividad tiene una desviación estándar (SD) de 4.0% (anual) y que una diferencia de 3% en la variación de la productividad (anual) se puede considerar una variación importante (el tamaño del efecto d sería d=3/4=0.75 - la diferencia de medias dividido la SD -). Para una potencia del 80% (el valor que típicamente se usa) y un nivel de confianza del 95%, ¿cuántos participantes necesitamos en nuestro estudio? 13.6.1 Utilziar la función pwr.t.test() - Power calculations for t-tests of means ?pwr.t.test pwr.t.test(d=.75, sig.level=.05, power=.8, type=two.sample, alternative=two.sided) two.sample es para dos grupos. Un grupo de que se va a intervenir o otro que sirve como grupo de control (control group). if(!require(pwr)) install.packages(&#39;pwr&#39;); library(pwr) ## Loading required package: pwr ?pwr.t.test pwr.t.test(d=.75, sig.level=.05, power=.8, type=&quot;two.sample&quot;, alternative=&quot;two.sided&quot;) ## ## Two-sample t test power calculation ## ## n = 28.89959 ## d = 0.75 ## sig.level = 0.05 ## power = 0.8 ## alternative = two.sided ## ## NOTE: n is number in *each* group Nota: Si podemos asumir para el presente caso, que solo hay crecimiento y no hay decrecimiento, p.ej. por la situación coyuntural durante el estudio, se puede definir single.sided (solo un lado de la distribución). 13.7 Ejercicio 8 Si se requiere saber, cuántas personas de una región estan dispuestas de trabajar en el extranjero, y si se puede asumir que la población de la región que trabaja o puede trabajar es de 50 mil personas, ¿qué tan grande debe ser la muestra para una encuesta que busca determinar esta disposición para trabajar en otro país? Asumimos para la generación de esta muestra que el margen de error es de 5% y el nivel de confianza requerido es de 95%. P y Q son 0.5 "],["arbolDec.html", "Sección 14 Árbol de decisión - Decision Tree 14.1 Objetivo 14.2 Cargar los datos 14.3 Explorar los datos 14.4 Mejorar los nombres (etiquetas) de las columnas del dataset 14.5 Transformar algunos datos 14.6 Particionar los datos 14.7 Construir el modelo (árbol de decisión, AD) 14.8 Realizar la predicción con base en el modelo 14.9 Evaluar el desempeño del modelo (árbol de decisión) 14.10 Ejercicio 9", " Sección 14 Árbol de decisión - Decision Tree 14.1 Objetivo El objetivo en este ejemplo consiste en clasificar datos de créditos (credit data), utilizando un modelo de árbol de decisión (AD) Vamos a utilizar los datos de crédito que están disponibles en línea como archivo csv, en la siguiente dirección (url), para clasificarlos en dos grupos (clases): buena paga y mala paga 14.2 Cargar los datos Bajar el archivo de los datos de la internet y leer los datos del archivo y asignarlos a una variable dataset url &lt;- http://freakonometrics.free.fr/german_credit.csv dataset &lt;- read.csv(url, header = TRUE, sep = ,) url &lt;- &quot;http://freakonometrics.free.fr/german_credit.csv&quot; dataset &lt;- read.csv(url, header = TRUE, sep = &quot;,&quot;) # Estos mismos datos también se pueden bajar de la siguiente dirección: # url &lt;- &quot;https://newonlinecourses.science.psu.edu/onlinecourses/sites/stat508/files/german_credit.csv&quot; # credit &lt;- read.csv(url(direccion)) 14.3 Explorar los datos Mostrar las primeras seis filas de los datos (dataset) en la pantalla Analizar la estructura de los datos Determinar la clase de los datos (class()) Realizar una estadística descriptiva de los datos, utilizando la función summary() Observe: Todos los datos son numéricos ¿Cuál es la variable de salida, cuáles son variables de entrada para el modelo (aquí: árbol de decisión)? print(head(dataset)) ## Creditability Account.Balance Duration.of.Credit..month. ## 1 1 1 18 ## 2 1 1 9 ## 3 1 2 12 ## 4 1 1 12 ## 5 1 1 12 ## 6 1 1 10 ## Payment.Status.of.Previous.Credit Purpose Credit.Amount Value.Savings.Stocks ## 1 4 2 1049 1 ## 2 4 0 2799 1 ## 3 2 9 841 2 ## 4 4 0 2122 1 ## 5 4 0 2171 1 ## 6 4 0 2241 1 ## Length.of.current.employment Instalment.per.cent Sex...Marital.Status ## 1 2 4 2 ## 2 3 2 3 ## 3 4 2 2 ## 4 3 3 3 ## 5 3 4 3 ## 6 2 1 3 ## Guarantors Duration.in.Current.address Most.valuable.available.asset ## 1 1 4 2 ## 2 1 2 1 ## 3 1 4 1 ## 4 1 2 1 ## 5 1 4 2 ## 6 1 3 1 ## Age..years. Concurrent.Credits Type.of.apartment No.of.Credits.at.this.Bank ## 1 21 3 1 1 ## 2 36 3 1 2 ## 3 23 3 1 1 ## 4 39 3 1 2 ## 5 38 1 2 2 ## 6 48 3 1 2 ## Occupation No.of.dependents Telephone Foreign.Worker ## 1 3 1 1 1 ## 2 3 2 1 1 ## 3 2 1 1 1 ## 4 2 2 1 2 ## 5 2 1 1 2 ## 6 2 2 1 2 str(dataset) ## &#39;data.frame&#39;: 1000 obs. of 21 variables: ## $ Creditability : int 1 1 1 1 1 1 1 1 1 1 ... ## $ Account.Balance : int 1 1 2 1 1 1 1 1 4 2 ... ## $ Duration.of.Credit..month. : int 18 9 12 12 12 10 8 6 18 24 ... ## $ Payment.Status.of.Previous.Credit: int 4 4 2 4 4 4 4 4 4 2 ... ## $ Purpose : int 2 0 9 0 0 0 0 0 3 3 ... ## $ Credit.Amount : int 1049 2799 841 2122 2171 2241 3398 1361 1098 3758 ... ## $ Value.Savings.Stocks : int 1 1 2 1 1 1 1 1 1 3 ... ## $ Length.of.current.employment : int 2 3 4 3 3 2 4 2 1 1 ... ## $ Instalment.per.cent : int 4 2 2 3 4 1 1 2 4 1 ... ## $ Sex...Marital.Status : int 2 3 2 3 3 3 3 3 2 2 ... ## $ Guarantors : int 1 1 1 1 1 1 1 1 1 1 ... ## $ Duration.in.Current.address : int 4 2 4 2 4 3 4 4 4 4 ... ## $ Most.valuable.available.asset : int 2 1 1 1 2 1 1 1 3 4 ... ## $ Age..years. : int 21 36 23 39 38 48 39 40 65 23 ... ## $ Concurrent.Credits : int 3 3 3 3 1 3 3 3 3 3 ... ## $ Type.of.apartment : int 1 1 1 1 2 1 2 2 2 1 ... ## $ No.of.Credits.at.this.Bank : int 1 2 1 2 2 2 2 1 2 1 ... ## $ Occupation : int 3 3 2 2 2 2 2 2 1 1 ... ## $ No.of.dependents : int 1 2 1 2 1 2 1 2 1 1 ... ## $ Telephone : int 1 1 1 1 1 1 1 1 1 1 ... ## $ Foreign.Worker : int 1 1 1 2 2 2 2 2 1 1 ... class(dataset) # data.frame ## [1] &quot;data.frame&quot; summary(dataset) ## Creditability Account.Balance Duration.of.Credit..month. ## Min. :0.0 Min. :1.000 Min. : 4.0 ## 1st Qu.:0.0 1st Qu.:1.000 1st Qu.:12.0 ## Median :1.0 Median :2.000 Median :18.0 ## Mean :0.7 Mean :2.577 Mean :20.9 ## 3rd Qu.:1.0 3rd Qu.:4.000 3rd Qu.:24.0 ## Max. :1.0 Max. :4.000 Max. :72.0 ## Payment.Status.of.Previous.Credit Purpose Credit.Amount ## Min. :0.000 Min. : 0.000 Min. : 250 ## 1st Qu.:2.000 1st Qu.: 1.000 1st Qu.: 1366 ## Median :2.000 Median : 2.000 Median : 2320 ## Mean :2.545 Mean : 2.828 Mean : 3271 ## 3rd Qu.:4.000 3rd Qu.: 3.000 3rd Qu.: 3972 ## Max. :4.000 Max. :10.000 Max. :18424 ## Value.Savings.Stocks Length.of.current.employment Instalment.per.cent ## Min. :1.000 Min. :1.000 Min. :1.000 ## 1st Qu.:1.000 1st Qu.:3.000 1st Qu.:2.000 ## Median :1.000 Median :3.000 Median :3.000 ## Mean :2.105 Mean :3.384 Mean :2.973 ## 3rd Qu.:3.000 3rd Qu.:5.000 3rd Qu.:4.000 ## Max. :5.000 Max. :5.000 Max. :4.000 ## Sex...Marital.Status Guarantors Duration.in.Current.address ## Min. :1.000 Min. :1.000 Min. :1.000 ## 1st Qu.:2.000 1st Qu.:1.000 1st Qu.:2.000 ## Median :3.000 Median :1.000 Median :3.000 ## Mean :2.682 Mean :1.145 Mean :2.845 ## 3rd Qu.:3.000 3rd Qu.:1.000 3rd Qu.:4.000 ## Max. :4.000 Max. :3.000 Max. :4.000 ## Most.valuable.available.asset Age..years. Concurrent.Credits ## Min. :1.000 Min. :19.00 Min. :1.000 ## 1st Qu.:1.000 1st Qu.:27.00 1st Qu.:3.000 ## Median :2.000 Median :33.00 Median :3.000 ## Mean :2.358 Mean :35.54 Mean :2.675 ## 3rd Qu.:3.000 3rd Qu.:42.00 3rd Qu.:3.000 ## Max. :4.000 Max. :75.00 Max. :3.000 ## Type.of.apartment No.of.Credits.at.this.Bank Occupation No.of.dependents ## Min. :1.000 Min. :1.000 Min. :1.000 Min. :1.000 ## 1st Qu.:2.000 1st Qu.:1.000 1st Qu.:3.000 1st Qu.:1.000 ## Median :2.000 Median :1.000 Median :3.000 Median :1.000 ## Mean :1.928 Mean :1.407 Mean :2.904 Mean :1.155 ## 3rd Qu.:2.000 3rd Qu.:2.000 3rd Qu.:3.000 3rd Qu.:1.000 ## Max. :3.000 Max. :4.000 Max. :4.000 Max. :2.000 ## Telephone Foreign.Worker ## Min. :1.000 Min. :1.000 ## 1st Qu.:1.000 1st Qu.:1.000 ## Median :1.000 Median :1.000 ## Mean :1.404 Mean :1.037 ## 3rd Qu.:2.000 3rd Qu.:1.000 ## Max. :2.000 Max. :2.000 14.4 Mejorar los nombres (etiquetas) de las columnas del dataset Mostrar primero estos nombres. Es decir, los nombres de las columnas del dataset colnames(dataset) ## [1] &quot;Creditability&quot; &quot;Account.Balance&quot; ## [3] &quot;Duration.of.Credit..month.&quot; &quot;Payment.Status.of.Previous.Credit&quot; ## [5] &quot;Purpose&quot; &quot;Credit.Amount&quot; ## [7] &quot;Value.Savings.Stocks&quot; &quot;Length.of.current.employment&quot; ## [9] &quot;Instalment.per.cent&quot; &quot;Sex...Marital.Status&quot; ## [11] &quot;Guarantors&quot; &quot;Duration.in.Current.address&quot; ## [13] &quot;Most.valuable.available.asset&quot; &quot;Age..years.&quot; ## [15] &quot;Concurrent.Credits&quot; &quot;Type.of.apartment&quot; ## [17] &quot;No.of.Credits.at.this.Bank&quot; &quot;Occupation&quot; ## [19] &quot;No.of.dependents&quot; &quot;Telephone&quot; ## [21] &quot;Foreign.Worker&quot; 14.5 Transformar algunos datos Asignar los siguientes nombres nuevos para las columnas del dataset. newColNames &lt;- c(Creditability_Default, Account_Balance, Duration_Credit_Month, Pmt_Status_Prev_Cred, Purpose, Credit_Amount, Value_Savings_Stocks, Length_current_employment, Instalment_per_cent, Sex_Marital_Status, Guarantors, Duration_current_address, Most_value_avail_asset, Age_years, Concurrent_Credits, Type_of_apartment, No_of_Credits_at_this_Bank, Occupation, No.of.dependents, Telephone, Foreign_Worker ) newColNames &lt;- c(&quot;Creditability_Default&quot;, &quot;Account_Balance&quot;, &quot;Duration_Credit_Month&quot;, &quot;Pmt_Status_Prev_Cred&quot;, &quot;Purpose&quot;, &quot;Credit_Amount&quot;, &quot;Value_Savings_Stocks&quot;, &quot;Length_current_employment&quot;, &quot;Instalment_per_cent&quot;, &quot;Sex_Marital_Status&quot;, &quot;Guarantors&quot;, &quot;Duration_current_address&quot;, &quot;Most_value_avail_asset&quot;, &quot;Age_years&quot;, &quot;Concurrent_Credits&quot;, &quot;Type_of_apartment&quot;, &quot;No_of_Credits_at_this_Bank&quot;, &quot;Occupation&quot;, &quot;No.of.dependents&quot;, &quot;Telephone&quot;, &quot;Foreign_Worker&quot; ) #Asignar estos nombres para utilizarlos a partir de ahora names(dataset) &lt;- newColNames colnames(dataset) ## [1] &quot;Creditability_Default&quot; &quot;Account_Balance&quot; ## [3] &quot;Duration_Credit_Month&quot; &quot;Pmt_Status_Prev_Cred&quot; ## [5] &quot;Purpose&quot; &quot;Credit_Amount&quot; ## [7] &quot;Value_Savings_Stocks&quot; &quot;Length_current_employment&quot; ## [9] &quot;Instalment_per_cent&quot; &quot;Sex_Marital_Status&quot; ## [11] &quot;Guarantors&quot; &quot;Duration_current_address&quot; ## [13] &quot;Most_value_avail_asset&quot; &quot;Age_years&quot; ## [15] &quot;Concurrent_Credits&quot; &quot;Type_of_apartment&quot; ## [17] &quot;No_of_Credits_at_this_Bank&quot; &quot;Occupation&quot; ## [19] &quot;No.of.dependents&quot; &quot;Telephone&quot; ## [21] &quot;Foreign_Worker&quot; Analizar la variable dependiente (variable de salida): Creditability_Default, en términos de una tabla que muestra las frecuencias para los valores 0 y 1 ¿Cuál es el valor para buena paga? ¿0 o 1? table(dataset$Creditability_Default) ## ## 0 1 ## 300 700 prop.table(table(dataset$Creditability_Default)) # lo mismo pero como porcentajes ## ## 0 1 ## 0.3 0.7 Determinar la clase de la variable (columna) Creditability_Default class(dataset$Creditability_Default) # integer ## [1] &quot;integer&quot; Transformar esta variable (dependiente) en una variable categórica (factor) dataset$Creditability_Default &lt;- as.factor(dataset$Creditability_Default) str(dataset$Creditability_Default) ## Factor w/ 2 levels &quot;0&quot;,&quot;1&quot;: 2 2 2 2 2 2 2 2 2 2 ... 14.6 Particionar los datos Particionar (dividir) los datos en dos partes, de forma aleatoria. En una parte (un grupo) de entrenamiento (credit_train) y otra de prueba (credit_test), utilizando una relación 66% (nombre: credit_train) y 34% (nombre: credit_test) Utilizar la función sample() y la semilla 123 para hacer los resultados reproducibles (set.seed()) Nota: La cantidad de los datos se puede determinar con: nrow(dataset) set.seed(123) d = sort(sample(nrow(dataset),nrow(dataset)*0.66, replace=FALSE)) # dividir en una conjunto de training y test set credit_train &lt;- dataset[d, ] credit_test &lt;- dataset[-d, ] Luego, verificar las proporciones entre estos dos grupos con respecto a la variable de salida (variable de predicción) prop.table(table(credit_train$Creditability_Default)) ## ## 0 1 ## 0.2787879 0.7212121 prop.table(table(credit_test$Creditability_Default)) ## ## 0 1 ## 0.3411765 0.6588235 Como se puede observar a través del resultado, las proporciones no se conservaron exactamente, pero aproximadamente 14.7 Construir el modelo (árbol de decisión, AD) Analizar el paquete C50, que permite construir un árbol de decisión Construir un árbol de decisión sencillo con el nombre credit_DT_model, utilizando el paquete C50 (con C mayúscula), la función C50() y los datos de entrenamiento Excluir de los datos la columna Telephone (porque no explica si un cliente es de buena o de mala paga) y adicionalmente la variable de salida (variable de predicción) Mostrar los resultados (output), utilizando la función summary() y analizarlos ¿Cuál es la variable más importante para estimar, si un cliente es de buena paga o mala paga? if(!require(C50)) install.packages(&#39;C50&#39;); library(C50) ## Loading required package: C50 ## Registered S3 methods overwritten by &#39;inum&#39;: ## method from ## print.interval sets ## [.interval sets ## format.interval sets ?C5.0 # create the DT credit_DT_model &lt;- C5.0(credit_train[ , -c(1,20)], credit_train$Creditability_Default) # -1 excluye la columna Creditability_Default y -20 la columna del Telephone summary(credit_DT_model) ## ## Call: ## C5.0.default(x = credit_train[, -c(1, 20)], y ## = credit_train$Creditability_Default) ## ## ## C5.0 [Release 2.07 GPL Edition] Mon Jan 31 15:53:15 2022 ## ------------------------------- ## ## Class specified by attribute `outcome&#39; ## ## Read 660 cases (20 attributes) from undefined.data ## ## Decision tree: ## ## Account_Balance &gt; 2: ## :...Concurrent_Credits &lt;= 2: ## : :...No_of_Credits_at_this_Bank &lt;= 1: ## : : :...Most_value_avail_asset &gt; 1: 1 (18/1) ## : : : Most_value_avail_asset &lt;= 1: ## : : : :...Length_current_employment &lt;= 2: 0 (2) ## : : : Length_current_employment &gt; 2: 1 (2) ## : : No_of_Credits_at_this_Bank &gt; 1: ## : : :...Pmt_Status_Prev_Cred &lt;= 1: 0 (3) ## : : Pmt_Status_Prev_Cred &gt; 1: ## : : :...Credit_Amount &lt;= 6527: 1 (15/2) ## : : Credit_Amount &gt; 6527: 0 (4/1) ## : Concurrent_Credits &gt; 2: ## : :...Age_years &gt; 34: 1 (127/4) ## : Age_years &lt;= 34: ## : :...Credit_Amount &lt;= 7511: 1 (129/19) ## : Credit_Amount &gt; 7511: ## : :...Duration_Credit_Month &lt;= 54: 0 (4) ## : Duration_Credit_Month &gt; 54: 1 (2) ## Account_Balance &lt;= 2: ## :...Duration_Credit_Month &lt;= 11: ## :...Pmt_Status_Prev_Cred &lt;= 1: 0 (5/1) ## : Pmt_Status_Prev_Cred &gt; 1: 1 (49/4) ## Duration_Credit_Month &gt; 11: ## :...Value_Savings_Stocks &gt; 1: ## :...Pmt_Status_Prev_Cred &gt; 2: 1 (27/3) ## : Pmt_Status_Prev_Cred &lt;= 2: ## : :...Type_of_apartment &lt;= 1: ## : :...Instalment_per_cent &lt;= 1: 1 (2) ## : : Instalment_per_cent &gt; 1: ## : : :...Account_Balance &gt; 1: 0 (8) ## : : Account_Balance &lt;= 1: ## : : :...Most_value_avail_asset &lt;= 2: 1 (2) ## : : Most_value_avail_asset &gt; 2: 0 (3/1) ## : Type_of_apartment &gt; 1: ## : :...Occupation &gt; 3: ## : :...Length_current_employment &gt; 4: 0 (3) ## : : Length_current_employment &lt;= 4: ## : : :...Age_years &lt;= 35: 0 (4/1) ## : : Age_years &gt; 35: 1 (3) ## : Occupation &lt;= 3: ## : :...Type_of_apartment &lt;= 2: 1 (38/6) ## : Type_of_apartment &gt; 2: ## : :...Concurrent_Credits &lt;= 2: 1 (2) ## : Concurrent_Credits &gt; 2: ## : :...Account_Balance &lt;= 1: 0 (3) ## : Account_Balance &gt; 1: 1 (3/1) ## Value_Savings_Stocks &lt;= 1: ## :...Guarantors &gt; 2: ## :...Purpose &lt;= 0: 0 (4) ## : Purpose &gt; 0: 1 (14/1) ## Guarantors &lt;= 2: ## :...Duration_Credit_Month &lt;= 22: ## :...Pmt_Status_Prev_Cred &gt; 2: ## : :...Most_value_avail_asset &gt; 1: 1 (22/3) ## : : Most_value_avail_asset &lt;= 1: ## : : :...Age_years &lt;= 38: 0 (3) ## : : Age_years &gt; 38: 1 (4) ## : Pmt_Status_Prev_Cred &lt;= 2: ## : :...Guarantors &gt; 1: 1 (3) ## : Guarantors &lt;= 1: ## : :...No_of_Credits_at_this_Bank &gt; 1: ## : :...Account_Balance &lt;= 1: 0 (6) ## : : Account_Balance &gt; 1: ## : : :...Type_of_apartment &lt;= 1: 0 (3) ## : : Type_of_apartment &gt; 1: 1 (2) ## : No_of_Credits_at_this_Bank &lt;= 1: ## : :...Account_Balance &gt; 1: ## : :...Credit_Amount &lt;= 1546: 0 (5/1) ## : : Credit_Amount &gt; 1546: 1 (8) ## : Account_Balance &lt;= 1: ## : :...Type_of_apartment &gt; 2: 0 (2) ## : Type_of_apartment &lt;= 2: ## : :...Type_of_apartment &lt;= 1: ## : :...Instalment_per_cent &lt;= 3: 1 (6/1) ## : : Instalment_per_cent &gt; 3: 0 (3) ## : Type_of_apartment &gt; 1: ## : :...Purpose &gt; 6: 1 (3) ## : Purpose &lt;= 6: [S1] ## Duration_Credit_Month &gt; 22: ## :...Type_of_apartment &lt;= 1: 0 (19/2) ## Type_of_apartment &gt; 1: ## :...Purpose &lt;= 0: 0 (17/2) ## Purpose &gt; 0: ## :...Concurrent_Credits &lt;= 2: ## :...Duration_current_address &lt;= 1: 1 (3/1) ## : Duration_current_address &gt; 1: ## : :...Age_years &lt;= 42: 0 (11) ## : Age_years &gt; 42: 1 (3/1) ## Concurrent_Credits &gt; 2: ## :...Pmt_Status_Prev_Cred &lt;= 1: 0 (5/1) ## Pmt_Status_Prev_Cred &gt; 1: ## :...Purpose &gt; 6: 0 (3) ## Purpose &lt;= 6: ## :...Duration_current_address &lt;= 1: 1 (4) ## Duration_current_address &gt; 1: ## :...Type_of_apartment &gt; 2: ## :...Occupation &lt;= 3: 0 (3) ## : Occupation &gt; 3: 1 (3/1) ## Type_of_apartment &lt;= 2: [S2] ## ## SubTree [S1] ## ## Sex_Marital_Status &gt; 3: 1 (4/1) ## Sex_Marital_Status &lt;= 3: ## :...Occupation &lt;= 2: 0 (5) ## Occupation &gt; 2: ## :...Duration_current_address &lt;= 1: 1 (2) ## Duration_current_address &gt; 1: 0 (8/1) ## ## SubTree [S2] ## ## Length_current_employment &gt; 4: 1 (5) ## Length_current_employment &lt;= 4: ## :...No_of_Credits_at_this_Bank &gt; 1: 1 (4/1) ## No_of_Credits_at_this_Bank &lt;= 1: ## :...Occupation &gt; 3: ## :...Account_Balance &lt;= 1: 1 (3) ## : Account_Balance &gt; 1: 0 (2) ## Occupation &lt;= 3: ## :...Age_years &gt; 33: 0 (5) ## Age_years &lt;= 33: ## :...Most_value_avail_asset &lt;= 2: 0 (3/1) ## Most_value_avail_asset &gt; 2: 1 (2) ## ## ## Evaluation on training data (660 cases): ## ## Decision Tree ## ---------------- ## Size Errors ## ## 60 62( 9.4%) &lt;&lt; ## ## ## (a) (b) &lt;-classified as ## ---- ---- ## 134 50 (a): class 0 ## 12 464 (b): class 1 ## ## ## Attribute usage: ## ## 100.00% Account_Balance ## 56.52% Concurrent_Credits ## 54.55% Duration_Credit_Month ## 46.21% Pmt_Status_Prev_Cred ## 45.45% Value_Savings_Stocks ## 45.45% Age_years ## 30.91% Type_of_apartment ## 30.61% Guarantors ## 25.30% Credit_Amount ## 18.18% No_of_Credits_at_this_Bank ## 17.58% Purpose ## 13.94% Occupation ## 9.24% Duration_current_address ## 9.24% Most_value_avail_asset ## 5.76% Length_current_employment ## 3.64% Instalment_per_cent ## 2.88% Sex_Marital_Status ## ## ## Time: 0.0 secs 14.8 Realizar la predicción con base en el modelo Utilizar el modelo anteriormente generado para hacer una predicción (prediction vector), utilizando la función predict() y los datos de prueba (credit_test) Asignar el resultado de la predicción a la variable credit_pred credit_pred &lt;- predict(credit_DT_model, credit_test) 14.9 Evaluar el desempeño del modelo (árbol de decisión) Evaluar el desempeño del modelo, generando una matriz de error (matriz de confusión o matriz de clasificación) con respecto a la variable de predicción (variable de salida), utilizando los datos de prueba Esta matriz se puede crear, utilizando el paquete gmodels y la función CrossTable() o simplemente usando la función table(), que genera una tabla más sencilla, pero con la misma cantidad de observaciones Explicar, cómo se debe interpretar el contenido de la tabla ¿Cuántos 0 clasificó bien el modelo? if(!require(gmodels)) install.packages(&#39;gmodels&#39;); library(gmodels) ## Loading required package: gmodels ## Registered S3 method overwritten by &#39;gdata&#39;: ## method from ## reorder.factor DescTools CrossTable(credit_test$Creditability_Default, credit_pred) ## ## ## Cell Contents ## |-------------------------| ## | N | ## | Chi-square contribution | ## | N / Row Total | ## | N / Col Total | ## | N / Table Total | ## |-------------------------| ## ## ## Total Observations in Table: 340 ## ## ## | credit_pred ## credit_test$Creditability_Default | 0 | 1 | Row Total | ## ----------------------------------|-----------|-----------|-----------| ## 0 | 43 | 73 | 116 | ## | 15.304 | 3.968 | | ## | 0.371 | 0.629 | 0.341 | ## | 0.614 | 0.270 | | ## | 0.126 | 0.215 | | ## ----------------------------------|-----------|-----------|-----------| ## 1 | 27 | 197 | 224 | ## | 7.925 | 2.055 | | ## | 0.121 | 0.879 | 0.659 | ## | 0.386 | 0.730 | | ## | 0.079 | 0.579 | | ## ----------------------------------|-----------|-----------|-----------| ## Column Total | 70 | 270 | 340 | ## | 0.206 | 0.794 | | ## ----------------------------------|-----------|-----------|-----------| ## ## #Alternativa table(credit_test$Creditability_Default, credit_pred) ## credit_pred ## 0 1 ## 0 43 73 ## 1 27 197 14.10 Ejercicio 9 Realizar un árbol decisión en R, utilizando el paquete ISLR y el dataset Smarket, que viene con este paquete, para clasificar los datos del dataset con el objetivo de determinar, si el mercado (índice S&amp;P500) va a subir o bajar. Mostrar las primeras 3 filas de este dataset Smarket y analizar de esta forma las columnas (variables) del dataset. Nota: Las variables Lag.. se refieren a precios determinados en el mercado de capitales (S&amp;P Stock Market Data) y refleja rendimientos diarios de este índice búrsatil, expresado como porcentaje. Utilizar el comando ?Smarket para consultar las páginas de ayuda al respecto Mostrar, la estructura de este dataset, utilizando la función str() Utilizando la semilla 123 (set.seed(123)), dividir los datos en una parte de entrenamiento (train_data) y otra parte de pruebas (test_data). 66% del total de los datos se deben utilizar para el entrenamiento y el resto para las pruebas (test_data) Analizar el paquete C50, que permite construir un árbol de decisión Construir un árbol de decisión sencillo con el nombre modelo.AD, utilizando el paquete C50 (con C mayúscula), la función C50() y los datos de entrenamiento Mostrar los resultados (output), utilizando la función summary() y analizarlos Realizar la predicción, utilzando el modelo construido y los datos de prueba (test_data), asignando el resultado a una variable pred Mostrar el resultado de la clasificación en una tabla, utilizando p.ej. la función table() Interpretar el resultado obtenido "],["regrLog.html", "Sección 15 Regresión logística (modelo logit) 15.1 Objetivo 15.2 Cargar los datos históricos de un archivo csv 15.3 Explorar los datos 15.4 Mejorar los nombres (etiquetas) de las columnas del dataset 15.5 Transformar algunos datos 15.6 Particionar los datos 15.7 Construir el modelo logit (regresión logística) 15.8 Generar el modelo mejorado 15.9 Realizar una predicción con el modelo logit mejorado 15.10 Convertir estas probabilidades en dos clases: 1 y 0 (buena paga y mala paga) 15.11 Ejercicio 10", " Sección 15 Regresión logística (modelo logit) 15.1 Objetivo El objetivo en este ejemplo consiste en clasificar datos de créditos (credit data), utilizando un modelo de regresión logística Para este modelo de la regresión logística véase p.ej. también las definiciones en: https://en.wikipedia.org/wiki/Logit 15.2 Cargar los datos históricos de un archivo csv Vamos a utilizar un conjunto de datos de créditos de la web. El objetivo consiste en construir un clasificador, utilizando una regresión logística, para clasificar los registros en dos grupos (clases): buena paga y mala paga. Bajar el archivo de los datos de la internet y leer los datos del archivo y asignarlos a una variable mis.datos url &lt;- http://freakonometrics.free.fr/german_credit.csv mis.datos &lt;- read.csv(url, header = TRUE, sep = ,) url &lt;- &quot;http://freakonometrics.free.fr/german_credit.csv&quot; mis.datos &lt;- read.csv(url, header = TRUE, sep = &quot;,&quot;) # Estos mismos datos también se pueden bajar de la siguiente dirección: # url &lt;- &quot;https://newonlinecourses.science.psu.edu/onlinecourses/sites/stat508/files/german_credit.csv&quot; # mis.datos &lt;- read.csv(url(direccion)) 15.3 Explorar los datos Mostrar las primeras seis filas de los datos (dataset) en la pantalla Analizar la estructura de los datos Determinar la clase de los datos (class()) Realizar una estadística descriptiva de los datos, utilizando la función summary() Observe: Todos los datos son numéricos ¿Cuál es la variable de salida y cuáles son variables de entrada para el modelo a construir (aquí: regresión logística)? print(head(mis.datos)) ## Creditability Account.Balance Duration.of.Credit..month. ## 1 1 1 18 ## 2 1 1 9 ## 3 1 2 12 ## 4 1 1 12 ## 5 1 1 12 ## 6 1 1 10 ## Payment.Status.of.Previous.Credit Purpose Credit.Amount Value.Savings.Stocks ## 1 4 2 1049 1 ## 2 4 0 2799 1 ## 3 2 9 841 2 ## 4 4 0 2122 1 ## 5 4 0 2171 1 ## 6 4 0 2241 1 ## Length.of.current.employment Instalment.per.cent Sex...Marital.Status ## 1 2 4 2 ## 2 3 2 3 ## 3 4 2 2 ## 4 3 3 3 ## 5 3 4 3 ## 6 2 1 3 ## Guarantors Duration.in.Current.address Most.valuable.available.asset ## 1 1 4 2 ## 2 1 2 1 ## 3 1 4 1 ## 4 1 2 1 ## 5 1 4 2 ## 6 1 3 1 ## Age..years. Concurrent.Credits Type.of.apartment No.of.Credits.at.this.Bank ## 1 21 3 1 1 ## 2 36 3 1 2 ## 3 23 3 1 1 ## 4 39 3 1 2 ## 5 38 1 2 2 ## 6 48 3 1 2 ## Occupation No.of.dependents Telephone Foreign.Worker ## 1 3 1 1 1 ## 2 3 2 1 1 ## 3 2 1 1 1 ## 4 2 2 1 2 ## 5 2 1 1 2 ## 6 2 2 1 2 str(mis.datos) ## &#39;data.frame&#39;: 1000 obs. of 21 variables: ## $ Creditability : int 1 1 1 1 1 1 1 1 1 1 ... ## $ Account.Balance : int 1 1 2 1 1 1 1 1 4 2 ... ## $ Duration.of.Credit..month. : int 18 9 12 12 12 10 8 6 18 24 ... ## $ Payment.Status.of.Previous.Credit: int 4 4 2 4 4 4 4 4 4 2 ... ## $ Purpose : int 2 0 9 0 0 0 0 0 3 3 ... ## $ Credit.Amount : int 1049 2799 841 2122 2171 2241 3398 1361 1098 3758 ... ## $ Value.Savings.Stocks : int 1 1 2 1 1 1 1 1 1 3 ... ## $ Length.of.current.employment : int 2 3 4 3 3 2 4 2 1 1 ... ## $ Instalment.per.cent : int 4 2 2 3 4 1 1 2 4 1 ... ## $ Sex...Marital.Status : int 2 3 2 3 3 3 3 3 2 2 ... ## $ Guarantors : int 1 1 1 1 1 1 1 1 1 1 ... ## $ Duration.in.Current.address : int 4 2 4 2 4 3 4 4 4 4 ... ## $ Most.valuable.available.asset : int 2 1 1 1 2 1 1 1 3 4 ... ## $ Age..years. : int 21 36 23 39 38 48 39 40 65 23 ... ## $ Concurrent.Credits : int 3 3 3 3 1 3 3 3 3 3 ... ## $ Type.of.apartment : int 1 1 1 1 2 1 2 2 2 1 ... ## $ No.of.Credits.at.this.Bank : int 1 2 1 2 2 2 2 1 2 1 ... ## $ Occupation : int 3 3 2 2 2 2 2 2 1 1 ... ## $ No.of.dependents : int 1 2 1 2 1 2 1 2 1 1 ... ## $ Telephone : int 1 1 1 1 1 1 1 1 1 1 ... ## $ Foreign.Worker : int 1 1 1 2 2 2 2 2 1 1 ... class(mis.datos) # data.frame ## [1] &quot;data.frame&quot; summary(mis.datos) ## Creditability Account.Balance Duration.of.Credit..month. ## Min. :0.0 Min. :1.000 Min. : 4.0 ## 1st Qu.:0.0 1st Qu.:1.000 1st Qu.:12.0 ## Median :1.0 Median :2.000 Median :18.0 ## Mean :0.7 Mean :2.577 Mean :20.9 ## 3rd Qu.:1.0 3rd Qu.:4.000 3rd Qu.:24.0 ## Max. :1.0 Max. :4.000 Max. :72.0 ## Payment.Status.of.Previous.Credit Purpose Credit.Amount ## Min. :0.000 Min. : 0.000 Min. : 250 ## 1st Qu.:2.000 1st Qu.: 1.000 1st Qu.: 1366 ## Median :2.000 Median : 2.000 Median : 2320 ## Mean :2.545 Mean : 2.828 Mean : 3271 ## 3rd Qu.:4.000 3rd Qu.: 3.000 3rd Qu.: 3972 ## Max. :4.000 Max. :10.000 Max. :18424 ## Value.Savings.Stocks Length.of.current.employment Instalment.per.cent ## Min. :1.000 Min. :1.000 Min. :1.000 ## 1st Qu.:1.000 1st Qu.:3.000 1st Qu.:2.000 ## Median :1.000 Median :3.000 Median :3.000 ## Mean :2.105 Mean :3.384 Mean :2.973 ## 3rd Qu.:3.000 3rd Qu.:5.000 3rd Qu.:4.000 ## Max. :5.000 Max. :5.000 Max. :4.000 ## Sex...Marital.Status Guarantors Duration.in.Current.address ## Min. :1.000 Min. :1.000 Min. :1.000 ## 1st Qu.:2.000 1st Qu.:1.000 1st Qu.:2.000 ## Median :3.000 Median :1.000 Median :3.000 ## Mean :2.682 Mean :1.145 Mean :2.845 ## 3rd Qu.:3.000 3rd Qu.:1.000 3rd Qu.:4.000 ## Max. :4.000 Max. :3.000 Max. :4.000 ## Most.valuable.available.asset Age..years. Concurrent.Credits ## Min. :1.000 Min. :19.00 Min. :1.000 ## 1st Qu.:1.000 1st Qu.:27.00 1st Qu.:3.000 ## Median :2.000 Median :33.00 Median :3.000 ## Mean :2.358 Mean :35.54 Mean :2.675 ## 3rd Qu.:3.000 3rd Qu.:42.00 3rd Qu.:3.000 ## Max. :4.000 Max. :75.00 Max. :3.000 ## Type.of.apartment No.of.Credits.at.this.Bank Occupation No.of.dependents ## Min. :1.000 Min. :1.000 Min. :1.000 Min. :1.000 ## 1st Qu.:2.000 1st Qu.:1.000 1st Qu.:3.000 1st Qu.:1.000 ## Median :2.000 Median :1.000 Median :3.000 Median :1.000 ## Mean :1.928 Mean :1.407 Mean :2.904 Mean :1.155 ## 3rd Qu.:2.000 3rd Qu.:2.000 3rd Qu.:3.000 3rd Qu.:1.000 ## Max. :3.000 Max. :4.000 Max. :4.000 Max. :2.000 ## Telephone Foreign.Worker ## Min. :1.000 Min. :1.000 ## 1st Qu.:1.000 1st Qu.:1.000 ## Median :1.000 Median :1.000 ## Mean :1.404 Mean :1.037 ## 3rd Qu.:2.000 3rd Qu.:1.000 ## Max. :2.000 Max. :2.000 15.4 Mejorar los nombres (etiquetas) de las columnas del dataset Primero, mostrar estos nombres, utilizando la función colnames() colnames(mis.datos) ## [1] &quot;Creditability&quot; &quot;Account.Balance&quot; ## [3] &quot;Duration.of.Credit..month.&quot; &quot;Payment.Status.of.Previous.Credit&quot; ## [5] &quot;Purpose&quot; &quot;Credit.Amount&quot; ## [7] &quot;Value.Savings.Stocks&quot; &quot;Length.of.current.employment&quot; ## [9] &quot;Instalment.per.cent&quot; &quot;Sex...Marital.Status&quot; ## [11] &quot;Guarantors&quot; &quot;Duration.in.Current.address&quot; ## [13] &quot;Most.valuable.available.asset&quot; &quot;Age..years.&quot; ## [15] &quot;Concurrent.Credits&quot; &quot;Type.of.apartment&quot; ## [17] &quot;No.of.Credits.at.this.Bank&quot; &quot;Occupation&quot; ## [19] &quot;No.of.dependents&quot; &quot;Telephone&quot; ## [21] &quot;Foreign.Worker&quot; 15.5 Transformar algunos datos Asignar los siguientes nombres nuevos para las columnas del dataset mis.datos newColNames &lt;- c(Creditability_Default, Account_Balance, Duration_Credit_Month, Pmt_Status_Prev_Cred, Purpose, Credit_Amount, Value_Savings_Stocks, Length_current_employment, Instalment_per_cent, Sex_Marital_Status, Guarantors, Duration_current_address, Most_value_avail_asset, Age_years, Concurrent_Credits, Type_of_apartment, No_of_Credits_at_this_Bank, Occupation, No.of.dependents, Telephone, Foreign_Worker ) newColNames &lt;- c(&quot;Creditability_Default&quot;, &quot;Account_Balance&quot;, &quot;Duration_Credit_Month&quot;, &quot;Pmt_Status_Prev_Cred&quot;, &quot;Purpose&quot;, &quot;Credit_Amount&quot;, &quot;Value_Savings_Stocks&quot;, &quot;Length_current_employment&quot;, &quot;Instalment_per_cent&quot;, &quot;Sex_Marital_Status&quot;, &quot;Guarantors&quot;, &quot;Duration_current_address&quot;, &quot;Most_value_avail_asset&quot;, &quot;Age_years&quot;, &quot;Concurrent_Credits&quot;, &quot;Type_of_apartment&quot;, &quot;No_of_Credits_at_this_Bank&quot;, &quot;Occupation&quot;, &quot;No.of.dependents&quot;, &quot;Telephone&quot;, &quot;Foreign_Worker&quot; ) #Asignar estos nombres nuevos para utilizarlos en adelante names(mis.datos) &lt;- newColNames colnames(mis.datos) ## [1] &quot;Creditability_Default&quot; &quot;Account_Balance&quot; ## [3] &quot;Duration_Credit_Month&quot; &quot;Pmt_Status_Prev_Cred&quot; ## [5] &quot;Purpose&quot; &quot;Credit_Amount&quot; ## [7] &quot;Value_Savings_Stocks&quot; &quot;Length_current_employment&quot; ## [9] &quot;Instalment_per_cent&quot; &quot;Sex_Marital_Status&quot; ## [11] &quot;Guarantors&quot; &quot;Duration_current_address&quot; ## [13] &quot;Most_value_avail_asset&quot; &quot;Age_years&quot; ## [15] &quot;Concurrent_Credits&quot; &quot;Type_of_apartment&quot; ## [17] &quot;No_of_Credits_at_this_Bank&quot; &quot;Occupation&quot; ## [19] &quot;No.of.dependents&quot; &quot;Telephone&quot; ## [21] &quot;Foreign_Worker&quot; Analizar la variable dependiente (variable de salida): Creditability_Default, en términos de una tabla que muestra las frecuencias para los valores 0 y 1 ¿Cuál es el valor para buena paga? ¿0 o 1? ?table table(mis.datos$Creditability_Default) ## ## 0 1 ## 300 700 prop.table(table(mis.datos$Creditability_Default)) ## ## 0 1 ## 0.3 0.7 # lo mismo, pero como porcentajes Transformar la variable (dependiente) en una variable categórica (factor) mis.datos$Creditability_Default &lt;- as.factor(mis.datos$Creditability_Default) str(mis.datos$Creditability_Default) ## Factor w/ 2 levels &quot;0&quot;,&quot;1&quot;: 2 2 2 2 2 2 2 2 2 2 ... 15.6 Particionar los datos Particionar (dividir) los datos en dos partes, de forma aleatoria. En una parte (un grupo) de entrenamiento (credit_train) y otra de pruebas (credit_test), utilizando una relación 66% (nombre: credit_train) y 34% (nombre: credit_test) Utlizar la función sample() y la semilla 123 para hacer los resultados reproducibles (set.seed()) Nota: La cantidad de los datos se puede determinar con: nrow(dataset) set.seed(123) d = sort(sample(nrow(mis.datos),nrow(mis.datos)*0.66, replace=FALSE)) # dividir en una conjunto de training y test set train_data &lt;- mis.datos[d, ] test_data &lt;- mis.datos[-d, ] Luego, verificar las proporciones entre estos dos grupos con respecto a la variable de salida (variable de predicción) prop.table(table(train_data$Creditability_Default)) ## ## 0 1 ## 0.2787879 0.7212121 prop.table(table(test_data$Creditability_Default)) ## ## 0 1 ## 0.3411765 0.6588235 Como se puede observar a través del resultado, las proporciones no se conservaron exactamente, pero aproximadamente 15.7 Construir el modelo logit (regresión logística) Generar el modelo logit con los datos de entrenamiento (train_data), utilizando la función glm(), generalized linear models, y asignar el resultado a una variable modelo.logit. Donde el parámetro family de la función glm debe tener el valor binomial(logit) Mostrar el resultado (del modelo), utilizando la función summary() Observar, cuáles de las variables de entrada son estadísticamente significativas ?glm modelo.logit &lt;- glm(Creditability_Default ~ ., family = binomial(&quot;logit&quot;), data = train_data) summary(modelo.logit) ## ## Call: ## glm(formula = Creditability_Default ~ ., family = binomial(&quot;logit&quot;), ## data = train_data) ## ## Deviance Residuals: ## Min 1Q Median 3Q Max ## -2.5567 -0.6795 0.4411 0.7091 1.7835 ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) -3.408e+00 1.194e+00 -2.855 0.00430 ** ## Account_Balance 5.717e-01 8.708e-02 6.566 5.18e-11 *** ## Duration_Credit_Month -1.108e-02 1.179e-02 -0.939 0.34758 ## Pmt_Status_Prev_Cred 4.241e-01 1.068e-01 3.972 7.13e-05 *** ## Purpose 3.130e-02 3.725e-02 0.840 0.40076 ## Credit_Amount -1.528e-04 5.478e-05 -2.788 0.00530 ** ## Value_Savings_Stocks 2.459e-01 7.484e-02 3.286 0.00102 ** ## Length_current_employment 8.025e-02 9.009e-02 0.891 0.37307 ## Instalment_per_cent -3.191e-01 1.053e-01 -3.030 0.00245 ** ## Sex_Marital_Status 2.884e-01 1.450e-01 1.989 0.04671 * ## Guarantors 2.482e-01 2.262e-01 1.097 0.27249 ## Duration_current_address -5.409e-02 9.728e-02 -0.556 0.57818 ## Most_value_avail_asset -2.067e-01 1.135e-01 -1.821 0.06863 . ## Age_years 1.285e-02 1.025e-02 1.253 0.21027 ## Concurrent_Credits 2.073e-01 1.366e-01 1.518 0.12912 ## Type_of_apartment 5.090e-01 2.057e-01 2.475 0.01332 * ## No_of_Credits_at_this_Bank -1.745e-01 2.040e-01 -0.856 0.39220 ## Occupation -3.867e-03 1.731e-01 -0.022 0.98218 ## No.of.dependents -3.335e-01 2.947e-01 -1.132 0.25782 ## Telephone 3.418e-01 2.356e-01 1.450 0.14692 ## Foreign_Worker 6.553e-01 6.500e-01 1.008 0.31338 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 781.18 on 659 degrees of freedom ## Residual deviance: 612.14 on 639 degrees of freedom ## AIC: 654.14 ## ## Number of Fisher Scoring iterations: 5 Eliminar las variables que estadísticamente no son significativas, generando un conjunto de datos train_data2 y test_data2 y generamos el modelo nuevamente con estas variables Esta eliminación se puede realizar de la siguiente forma: train_data[ ,!(colnames(train_data) %in% c(Duration_Credit_Month, Purpose,)) ] train_data2 &lt;- train_data[ ,!(colnames(train_data) %in% c(&quot;Duration_Credit_Month&quot;, &quot;Purpose&quot;, &quot;Length_current_employment&quot;, &quot;Guarantors&quot;, &quot;Duration_current_address&quot;, &quot;Age_years&quot;, &quot;Concurrent_Credits&quot;, &quot;No_of_Credits_at_this_Bank&quot;, &quot;Occupation&quot;, &quot;No.of.dependents&quot;, &quot;Telephone&quot;, &quot;Foreign_Worker&quot;)) ] head(train_data2) ## Creditability_Default Account_Balance Pmt_Status_Prev_Cred Credit_Amount ## 1 1 1 4 1049 ## 5 1 1 4 2171 ## 6 1 1 4 2241 ## 7 1 1 4 3398 ## 8 1 1 4 1361 ## 9 1 4 4 1098 ## Value_Savings_Stocks Instalment_per_cent Sex_Marital_Status ## 1 1 4 2 ## 5 1 4 3 ## 6 1 1 3 ## 7 1 1 3 ## 8 1 2 3 ## 9 1 4 2 ## Most_value_avail_asset Type_of_apartment ## 1 2 1 ## 5 2 2 ## 6 1 1 ## 7 1 2 ## 8 1 2 ## 9 3 2 test_data2 &lt;- test_data [ ,!(colnames(test_data) %in% c(&quot;Duration_Credit_Month&quot;, &quot;Purpose&quot;, &quot;Length_current_employment&quot;, &quot;Guarantors&quot;, &quot;Duration_current_address&quot;, &quot;Age_years&quot;, &quot;Concurrent_Credits&quot;, &quot;No_of_Credits_at_this_Bank&quot;, &quot;Occupation&quot;, &quot;No.of.dependents&quot;, &quot;Telephone&quot;, &quot;Foreign_Worker&quot;)) ] head(test_data2) ## Creditability_Default Account_Balance Pmt_Status_Prev_Cred Credit_Amount ## 2 1 1 4 2799 ## 3 1 2 2 841 ## 4 1 1 4 2122 ## 10 1 2 2 3758 ## 11 1 1 4 3905 ## 14 1 2 3 7582 ## Value_Savings_Stocks Instalment_per_cent Sex_Marital_Status ## 2 1 2 3 ## 3 2 2 2 ## 4 1 3 3 ## 10 3 1 2 ## 11 1 2 3 ## 14 2 2 3 ## Most_value_avail_asset Type_of_apartment ## 2 1 1 ## 3 1 1 ## 4 1 1 ## 10 4 1 ## 11 1 1 ## 14 4 2 También es posible lograr lo mismo con pipes: library(dplyr) train_data2 &lt;- train_data %&gt;% select(-Duration_Credit_Month, -Purpose, -Length_current_employment, -Guarantors, -Duration_current_address, -Age_years, -Concurrent_Credits, -No_of_Credits_at_this_Bank, -Occupation, -No.of.dependents, -Telephone, -Foreign_Worker) head(train_data2) test_data2 &lt;- test_data %&gt;% select(-Duration_Credit_Month, -Purpose, -Length_current_employment, -Guarantors, -Duration_current_address, -Age_years, -Concurrent_Credits, -No_of_Credits_at_this_Bank, -Occupation, -No.of.dependents, -Telephone, -Foreign_Worker) head(test_data2) 15.8 Generar el modelo mejorado Generar el modelo mejorado significa que se utilizan únicamente las variables de train_data2 Nombrar el nuevo modelo (mejorado): modelo.logit2 Mostrar el resultado (del nuevo modelo), utilizando la función summary() Observar, cuáles de las variables de entrada son estadísticamente significativas modelo.logit2 &lt;- glm(Creditability_Default ~ ., family = binomial(&quot;logit&quot;), data = train_data2) summary(modelo.logit2) ## ## Call: ## glm(formula = Creditability_Default ~ ., family = binomial(&quot;logit&quot;), ## data = train_data2) ## ## Deviance Residuals: ## Min 1Q Median 3Q Max ## -2.6394 -0.7639 0.4531 0.7399 1.6532 ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) -1.641e+00 6.130e-01 -2.677 0.007434 ** ## Account_Balance 5.754e-01 8.465e-02 6.797 1.07e-11 *** ## Pmt_Status_Prev_Cred 4.357e-01 9.409e-02 4.630 3.66e-06 *** ## Credit_Amount -1.683e-04 4.133e-05 -4.072 4.67e-05 *** ## Value_Savings_Stocks 2.478e-01 7.252e-02 3.417 0.000634 *** ## Instalment_per_cent -3.059e-01 9.859e-02 -3.102 0.001920 ** ## Sex_Marital_Status 2.763e-01 1.405e-01 1.966 0.049264 * ## Most_value_avail_asset -2.372e-01 1.061e-01 -2.236 0.025368 * ## Type_of_apartment 5.447e-01 1.899e-01 2.868 0.004131 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 781.18 on 659 degrees of freedom ## Residual deviance: 626.78 on 651 degrees of freedom ## AIC: 644.78 ## ## Number of Fisher Scoring iterations: 5 15.9 Realizar una predicción con el modelo logit mejorado Realizar esta predicción, utilizando la función predict() y los datos de prueba test_data2 y asignar el resultado a una variable probs, ya que el resultado representa probabilidades. Nota: el parámetro type debe ser response Observar el resultado, utilizando la función head() # probabilidades: probs &lt;- predict(modelo.logit2, test_data2, type = &quot;response&quot;) head(probs) ## 2 3 4 10 11 14 ## 0.7268033 0.7278048 0.6870849 0.5828999 0.6883315 0.5972874 15.10 Convertir estas probabilidades en dos clases: 1 y 0 (buena paga y mala paga) Convertir estas probabilidades en dos clases: 1 y 0, utilizando la función ifelse(), que funciona parecida a la función Si() en MS-Excel Generar una matriz de error (matriz de clasificación), utilizando la función table() con respecto a la variable de salida (variable de predicción) Interpretar los valores de esta matriz prediccion &lt;- ifelse(probs &gt; 0.5, 1, 0) table(prediccion, test_data2$Creditability_Default) ## ## prediccion 0 1 ## 0 41 22 ## 1 75 202 15.11 Ejercicio 10 Realizar una regresión logística en R, utilizando el paquete ISLR y el dataset Smarket, que viene con este paquete, para clasificar los datos del dataset con el objetivo de determinar, si el mercado (índice S&amp;P500) va a subir o bajar. Mostrar las primeras 3 filas de este dataset Smarket y analizar de esta forma las columnas (variables) del dataset. Nota: Las variables Lag.. se refieren a precios determinados en el mercado de capitales (S&amp;P Stock Market Data) y refleja rendimientos diarios de este índice bursátil, expresado como porcentaje. Utilizar el comando ?Smarket para consultar las páginas de ayuda al respecto Mostrar, la estructura de este dataset, utilizando la función str() Utilizando la semilla 123 (set.seed(123)), dividir los datos en una parte de entrenamiento (train_data) y otra parte de pruebas (test_data). 66% del total de los datos se deben utilizar para el entrenamiento y el resto para las pruebas Realizar un modelo de regresión logística con los datos de entrenamiento, utilizando como variables de entrada únicamente las variables Lag1, Lag2 y Lag3. Asignar el resultado a una variable modelo.logit, Nota: En este caso no se preocupe de los valores p (p-values) obtenidos para las tres variables de entrada Mostrar el resultado de la regresión en la pantalla, utilizando la función summary() para el modelo de la regresión generada Luego, realizar la predicción para el S&amp;P500, utilizando el modelo generado y los datos de prueba (test_data) y asignar el resultado (probabilidades) a una variable probs Si las probabilidades son mayor que 0.5, asigna el valor 1, en el caso contrario el valor 0 Mostrar el resultado de la clasificación en una tabla, utilizando p.ej. la función table() Interpretar el resultado obtenido "],["normalizar.html", "Sección 16 Escalar y normalizar (estandarizar datos) 16.1 Objetivo 16.2 Cargar los datos históricos de un archivo csv 16.3 Analizar los datos de la columna Credit.Amount (monto del crédito) 16.4 Escalar los datos 16.5 La normalización de los datos 16.6 Escala logarítmica 16.7 Creando variables dummy (one-hot encoding) 16.8 Ejercicio 11", " Sección 16 Escalar y normalizar (estandarizar datos) 16.1 Objetivo El objetivo de esta sección consiste en explicar, cómo se pueden escalar y/o normalizar datos en R, para evitar sesgos en el análisis de estos. Además, cómo se puede crear una variable dummy en R (one-hot encoding). 16.2 Cargar los datos históricos de un archivo csv Vamos a utilizar un conjunto de datos de créditos de la web. Bajar el archivo de los datos de la internet y leer los datos del archivo y asignarlos a una variable mis.datos. url &lt;- http://freakonometrics.free.fr/german_credit.csv datos &lt;- read.csv(url, header = TRUE, sep = ,) url &lt;- &quot;http://freakonometrics.free.fr/german_credit.csv&quot; datos &lt;- read.csv(url, header = TRUE, sep = &quot;,&quot;) # Estos mismos datos también se pueden bajar de la siguiente dirección: # url &lt;- &quot;https://newonlinecourses.science.psu.edu/onlinecourses/sites/stat508/files/german_credit.csv&quot; # datos &lt;- read.csv(url(direccion)) 16.3 Analizar los datos de la columna Credit.Amount (monto del crédito) Analizar los datos de la columna Credit.Amount, utilizando las funciones summary() y sd(). Esta última para determinar también la desviación estándar (standard deviation) de los datos de esta columna summary(datos$Credit.Amount) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 250 1366 2320 3271 3972 18424 sd(datos$Credit.Amount) ## [1] 2822.752 Como se puede observar en el resultado, los valores de la variable (Credit.Amount) son dispersos, ya que existe una diferencia grande entre el monto mínimo y máximo y la desviación estándar también es alta, lo que puede dificultar la implementación de técnicas de analítica de datos y Machine Learning. Recordar, la variable Credit.Amount se refiere a valores que representan dinero, p.ej. dólares. 16.4 Escalar los datos Escalar datos significa colocar los datos en la misma escala, generalmente, entre 0 y 1. Realizar un escalado de la variable Credit.Amount en un rango [0,1] de la siguiente forma y asignar el resultado a la variable datos$Credit.Amount2: x.escalada = (x - min(x)) / (max(x) - min(x)) Esto se puede lograr más facil, utilizando la función rescale() del paquete scales de R. (Nota: Esto de pronto requiere también de la instalación del paquete lifecycle en su equipo de cómputo) Observar las primeras seis filas de los datos de la columna Credit.Amount. Todos los valores ahora deben estar entre 0 y 1 if(!require(scales)) install.packages(&#39;scales&#39;); library(scales) ## Loading required package: scales ## ## Attaching package: &#39;scales&#39; ## The following object is masked from &#39;package:purrr&#39;: ## ## discard ## The following object is masked from &#39;package:readr&#39;: ## ## col_factor ?scales datos$Credit.Amount2 &lt;- rescale(datos$Credit.Amount) head(datos$Credit.Amount2) ## [1] 0.04396390 0.14025531 0.03251898 0.10300429 0.10570045 0.10955211 16.5 La normalización de los datos La normalización significa ajustar los valores medidos en diferentes escalas respecto a una escala común. El objetivo de la normalización es eliminar variaciones sistemáticas, conservando la señal en los datos. Se pueden normalizar únicamente columnas con datos numéricos. Realizar esta normalización para todos los datos del data frame datos, menos la viable de salida (aquí: Creditability) y asignar el resultado a una variable datos2 Utilizar el paquete tidyverse (dplyr) y la función mutate_if() para realizar una prueba, si los datos son númericos Recordar, en datos solo existen datos numéricos, pero se debe utilizar mutate_if(). Esta función aplica de forma condicional una función. En el presente caso se trata de is.numeric(), que actúa como un filtro condicional Mostrar las primeras seis filas de datos2 Reflexionar, si es realmente adecuado normalizar todas las variables de entrada, tomando en cuenta la naturaleza de los datos de este ejemplo ind &lt;- sapply(datos[,-1], is.numeric) datos[ind] &lt;- lapply(datos[ind], scale) head(datos[ind]) ## Creditability Account.Balance Duration.of.Credit..month. ## 1 0.6543263 -1.2539382 -0.2407368 ## 2 0.6543263 -1.2539382 -0.9870788 ## 3 0.6543263 -0.4587967 -0.7382981 ## 4 0.6543263 -1.2539382 -0.7382981 ## 5 0.6543263 -1.2539382 -0.7382981 ## 6 0.6543263 -1.2539382 -0.9041519 ## Payment.Status.of.Previous.Credit Purpose Credit.Amount ## 1 1.3433419 -0.301701 -0.7872630 ## 2 1.3433419 -1.030447 -0.1673006 ## 3 -0.5031762 2.248911 -0.8609500 ## 4 1.3433419 -1.030447 -0.4071375 ## 5 1.3433419 -1.030447 -0.3897785 ## 6 1.3433419 -1.030447 -0.3649800 ## Value.Savings.Stocks Length.of.current.employment Instalment.per.cent ## 1 -0.69935708 -1.1454050 0.91801781 ## 2 -0.69935708 -0.3178002 -0.86974813 ## 3 -0.06645474 0.5098045 -0.86974813 ## 4 -0.69935708 -0.3178002 0.02413484 ## 5 -0.69935708 -0.3178002 0.91801781 ## 6 -0.69935708 -1.1454050 -1.76363111 ## Sex...Marital.Status Guarantors Duration.in.Current.address ## 1 -0.9631679 -0.3035339 1.0464631 ## 2 0.4491018 -0.3035339 -0.7655942 ## 3 -0.9631679 -0.3035339 1.0464631 ## 4 0.4491018 -0.3035339 -0.7655942 ## 5 0.4491018 -0.3035339 1.0464631 ## 6 0.4491018 -0.3035339 0.1404344 ## Most.valuable.available.asset Age..years. Concurrent.Credits ## 1 -0.3408845 -1.28093214 0.4606002 ## 2 -1.2930760 0.04034293 0.4606002 ## 3 -1.2930760 -1.10476213 0.4606002 ## 4 -1.2930760 0.30459795 0.4606002 ## 5 -0.3408845 0.21651294 -2.3738626 ## 6 -1.2930760 1.09736299 0.4606002 ## Type.of.apartment No.of.Credits.at.this.Bank Occupation No.of.dependents ## 1 -1.7503294 -0.7045734 0.1468757 -0.4280754 ## 2 -1.7503294 1.0265652 0.1468757 2.3337012 ## 3 -1.7503294 -0.7045734 -1.3830794 -0.4280754 ## 4 -1.7503294 1.0265652 -1.3830794 2.3337012 ## 5 0.1358014 1.0265652 -1.3830794 -0.4280754 ## 6 -1.7503294 1.0265652 -1.3830794 2.3337012 ## Telephone Foreign.Worker Credit.Amount2 ## 1 -0.8229061 -0.1959163 -0.7872630 ## 2 -0.8229061 -0.1959163 -0.1673006 ## 3 -0.8229061 -0.1959163 -0.8609500 ## 4 -0.8229061 5.0991176 -0.4071375 ## 5 -0.8229061 5.0991176 -0.3897785 ## 6 -0.8229061 5.0991176 -0.3649800 Con tidyverse: library(tidyverse) datos.normalizados &lt;- datos[,-1] %&gt;% mutate_if(is.numeric, scale) head(datos.normalizados) 16.5.1 Comprobar el resultado Queremos comprobar, si el resultado tiene una media de 0 y una desviación estándar (sd) de 1. Utilizar la función colMeans() y sd() Observar: La media esta cerca de 0 y la desviación estándar es 1 para las variables Reflexionar sobre lo siguiente: Algunas variables son categóricas, aunque estas tienen valores numéricos. Sin embargo, estos valores númericos representan una categoría. ¿Este hecho afecta la normalización? colMeans(datos[ind]) # version más rápida de apply(datos[ind], 2, mean) ## Creditability Account.Balance ## 1.110223e-16 8.187895e-17 ## Duration.of.Credit..month. Payment.Status.of.Previous.Credit ## 1.262671e-16 5.773160e-17 ## Purpose Credit.Amount ## 5.762057e-17 -2.445960e-19 ## Value.Savings.Stocks Length.of.current.employment ## -5.231926e-18 1.142419e-16 ## Instalment.per.cent Sex...Marital.Status ## 1.482078e-16 8.726353e-17 ## Guarantors Duration.in.Current.address ## -5.223599e-17 -1.909861e-16 ## Most.valuable.available.asset Age..years. ## -7.460699e-17 -1.331713e-16 ## Concurrent.Credits Type.of.apartment ## 2.771117e-16 1.056377e-16 ## No.of.Credits.at.this.Bank Occupation ## -9.992007e-19 1.604827e-16 ## No.of.dependents Telephone ## -1.126876e-16 1.989520e-16 ## Foreign.Worker Credit.Amount2 ## 4.306833e-16 8.211834e-17 apply(datos[ind], 2, sd) ## Creditability Account.Balance ## 1 1 ## Duration.of.Credit..month. Payment.Status.of.Previous.Credit ## 1 1 ## Purpose Credit.Amount ## 1 1 ## Value.Savings.Stocks Length.of.current.employment ## 1 1 ## Instalment.per.cent Sex...Marital.Status ## 1 1 ## Guarantors Duration.in.Current.address ## 1 1 ## Most.valuable.available.asset Age..years. ## 1 1 ## Concurrent.Credits Type.of.apartment ## 1 1 ## No.of.Credits.at.this.Bank Occupation ## 1 1 ## No.of.dependents Telephone ## 1 1 ## Foreign.Worker Credit.Amount2 ## 1 1 16.6 Escala logarítmica La escala logarítmica informa sobre los cambios relativos (multiplicativos), mientras que la escala lineal informa sobre los cambios absolutos (aditivos). ¿Cuándo se usa cada uno? Debes usar una escala logarítmica cuando el porcentaje cambia, o el cambio, en órdenes de magnitud, es más importante que cambios en unidades absolutas. Es de resaltar, lo que constituye una diferencia significativa depende del orden de magnitud de los valores, p.ej. ingresos, que se analizan. En una población donde algunas personas tienen ingresos muy altos, estos datos (observaciones) se compriman en una zona relativamente pequeña de la distribución de ingresos. Es decir, si la distribución es sesgada, es una buena idea utilizar una escala logarítmica (Zumel, N., &amp; Mount, J. (2014). Practical data science with R. Manning Publications Co., véase Anexo B). Ejemplo - Bolsa de Valores. La acción A cotiza en el día 1: $ 100. En el día 2: $ 101. Normalmente, se informa este cambio de dos maneras: (1) + $ 1. (2) + 1%. El primero es una medida de cambio absoluto y aditivo, el segundo una medida de cambio relativo. (Fuente: https://stats.stackexchange.com/questions/18844/when-and-why-should-you-take-the-log-of-a-distribution-of-numbers) Ejemplo: La acción A sube de $ 1 a $ 1.10. La acción B de $ 100 a $ 110. La acción A ganó 10%, la acción B ganó 10% (escala relativa, igual), pero la acción A ganó 10 centavos, mientras que la acción B ganó $ 10 (B ganó más cantidad absoluta en dólares). Si tomamos el log, los cambios relativos aparecen como cambios absolutos. La acción A aumenta de log10 ($ 1) a log10 ($ 1.10) = 0 a .0413 La acción B aumenta de log10 ($ 100) a log10 ($ 110) = 2 a 2.0413 Ahora, tomando la diferencia absoluta en el espacio logarítmico, encontramos que ambos cambiaron en .0413. El cálculo en R para la situación A y B: # A log10(1.10) - log10(1) # 0.04139269 ## [1] 0.04139269 # B log10(110) - log10(100) # 0.04139269 ## [1] 0.04139269 16.6.1 Un ejemplo - retornos logarítmicos Bajando datos bursátiles desde yahoo con el paquete quantmod. Cargar el paquete quantmod Este paquete requiere que se defina un entorno (environment): new.env() if(!require(quantmod)) install.packages(&#39;quantmod&#39;); library(quantmod) ?quantmod stockData &lt;- new.env() #Generar un entorno nuevo para que quantmod pueda guardar los datos en este entorno Definir una fecha de inicio y final para bajar los datos. - Utilizar como fecha final la fecha actual y como fecha de inicio la fecha final menos 30 días. startDate = Sys.Date() - 30 # o as.Date(&quot;2019-07-01&quot;) endDate = Sys.Date() Definir una lista de los tickers (empresas) para las cuales se requieren los datos. P.ej. Amazon: ticker - AMZN Descargar los datos históricos de la/s acción/es (para todos los tickers), utilizando la función getsymbols() de quantmod tickers &lt;- c(&quot;AMZN&quot;) getSymbols(tickers, env = stockData, src = &quot;yahoo&quot;, from = startDate, to = endDate) ## [1] &quot;AMZN&quot; Analizar las primeras 6 filas de estos datos ya descargados Observar la clase de los datos (class()) head(stockData$AMZN) ## AMZN.Open AMZN.High AMZN.Low AMZN.Close AMZN.Volume AMZN.Adjusted ## 2022-01-03 3351.00 3414.07 3323.21 3408.09 3176000 3408.09 ## 2022-01-04 3408.76 3428.00 3326.99 3350.44 3536300 3350.44 ## 2022-01-05 3337.66 3342.53 3287.14 3287.14 3215100 3287.14 ## 2022-01-06 3269.01 3296.00 3238.74 3265.08 2597900 3265.08 ## 2022-01-07 3276.78 3304.87 3240.62 3251.08 2329300 3251.08 ## 2022-01-10 3211.71 3233.23 3126.09 3229.72 4389900 3229.72 class(stockData) # environment ## [1] &quot;environment&quot; Determinar los retornos logarítmicos con base en los precios de la columna AMZN.Close y asignar el resultado a una variable prices Imprimir a la pantalla las primeras seis filas de los retornos logarítmicos calculados prices &lt;- stockData$AMZN$AMZN.Close log_returns &lt;- diff(log(prices), lag=1) head(log_returns) ## AMZN.Close ## 2022-01-03 NA ## 2022-01-04 -0.017060380 ## 2022-01-05 -0.019073810 ## 2022-01-06 -0.006733565 ## 2022-01-07 -0.004297016 ## 2022-01-10 -0.006591836 En las finanzas es común trabajar con retornos logarítmicos. 16.7 Creando variables dummy (one-hot encoding) En situaciones, donde tenemos variables categóricas (factores), pero necesitamos usarlas en métodos analíticos que requieren números, como por ejemplo en k vecinos más cercanos (KNN) o regresión lineal, necesitamos crear variables dummy. Utilizar el paquete dummies y la función dummy() para generar una variable dummy para los datos de la columna Type.of.apartment del data frame datos, que trabajamos al inicio de esta sección, y asignar el resultado a una variable datos$Dummy.Apartment.Type Mostrar en la pantalla los datos para las primeras 10 filas de datos$Dummy.Apartment.Type Interpretar este resultado if(!require(dummies)) install.packages(&#39;dummies&#39;); library(dummies) ## Loading required package: dummies ## dummies-1.5.6 provided by Decision Patterns datos$Dummy.Apartment.Type &lt;- dummy(datos$Type.of.apartment) ## Warning in model.matrix.default(~x - 1, model.frame(~x - 1), contrasts = FALSE): ## non-list contrasts argument ignored head(datos$Dummy.Apartment.Type, n = 10) ## bookdown::gitbook-1.75032943332907 bookdown::gitbook0.135801421551393 ## [1,] 1 0 ## [2,] 1 0 ## [3,] 1 0 ## [4,] 1 0 ## [5,] 0 1 ## [6,] 1 0 ## [7,] 0 1 ## [8,] 0 1 ## [9,] 0 1 ## [10,] 1 0 ## bookdown::gitbook2.02193227643185 ## [1,] 0 ## [2,] 0 ## [3,] 0 ## [4,] 0 ## [5,] 0 ## [6,] 0 ## [7,] 0 ## [8,] 0 ## [9,] 0 ## [10,] 0 Otro ejemplo: Fuente: https://stackoverflow.com/questions/11952706/generate-a-dummy-variable. Crear un data frame df1 con 4 años: 2016 hasta 2019, que tiene una columna id: 1-4 y luego una columna con los años mencionados, utilizando la función cbind() Luego, generar las columnas con las variables dummy y sus valores, utilizando la función dummy() del paquete dummies Mostrar el resultado (de df1) en la pantalla, utilizando la función print() Es decir, el resultado se debe presentar de la siguiente forma: id year df1_2016 df1_2017 df1_2018 df1_2019 1 2016 1 0 0 0 2 2017 0 1 0 0 3 2018 0 0 1 0 4 2019 0 0 0 1 library(dummies) df1 &lt;- data.frame(id = 1:4, year = 2016:2019) df1 &lt;- cbind(df1, dummy(df1$year, sep = &quot;&quot;)) ## Warning in model.matrix.default(~x - 1, model.frame(~x - 1), contrasts = FALSE): ## non-list contrasts argument ignored print(df1) ## id year bookdown::gitbook2016 bookdown::gitbook2017 bookdown::gitbook2018 ## 1 1 2016 1 0 0 ## 2 2 2017 0 1 0 ## 3 3 2018 0 0 1 ## 4 4 2019 0 0 0 ## bookdown::gitbook2019 ## 1 0 ## 2 0 ## 3 0 ## 4 1 16.8 Ejercicio 11 Utilizar el paquete ISLR y el dataset Smarket, que viene con este paquete, y escalar los datos de la columna Lag1 de este dataset, utilizando el paquete scales, y asignar el resultado a una variable Lag1.scaled Mostrar las últimas 10 filas del resultado en la pantalla "],["rn.html", "Sección 17 Red Neuronal 17.1 Objetivo 17.2 Cargar datos 17.3 Normalizar datos 17.4 Particionar los datos 17.5 Crear la Red Neuronal 17.6 Realizar la predicción", " Sección 17 Red Neuronal 17.1 Objetivo El objetivo en este ejemplo consiste en clasificar datos de créditos (credit data), utilizando un modelo de red neuronal (Neural Network) 17.2 Cargar datos Vamos a utilizar un conjunto de datos de créditos de la web, de la misma fuente que se utilizó antes 15. El objetivo consiste en construir un clasificador, utilizando una red neuronal, para clasificar los registros en dos grupos (clases): buena paga y mala paga. Bajar el archivo de los datos de la internet y leer los datos del archivo y asignarlos a una variable mis.datos url &lt;- http://freakonometrics.free.fr/german_credit.csv mis.datos &lt;- read.csv(url, header = TRUE, sep = ,) url &lt;- &quot;http://freakonometrics.free.fr/german_credit.csv&quot; mis.datos &lt;- read.csv(url, header = TRUE, sep = &quot;,&quot;) # Estos mismos datos también se pueden bajar de la siguiente dirección: # url &lt;- &quot;https://newonlinecourses.science.psu.edu/onlinecourses/sites/stat508/files/german_credit.csv&quot; # mis.datos &lt;- read.csv(url(direccion)) Mostrar las primeras 3 filas de los datos (mis.datos) Mostrar la estructura de los datos head(mis.datos,3) ## Creditability Account.Balance Duration.of.Credit..month. ## 1 1 1 18 ## 2 1 1 9 ## 3 1 2 12 ## Payment.Status.of.Previous.Credit Purpose Credit.Amount Value.Savings.Stocks ## 1 4 2 1049 1 ## 2 4 0 2799 1 ## 3 2 9 841 2 ## Length.of.current.employment Instalment.per.cent Sex...Marital.Status ## 1 2 4 2 ## 2 3 2 3 ## 3 4 2 2 ## Guarantors Duration.in.Current.address Most.valuable.available.asset ## 1 1 4 2 ## 2 1 2 1 ## 3 1 4 1 ## Age..years. Concurrent.Credits Type.of.apartment No.of.Credits.at.this.Bank ## 1 21 3 1 1 ## 2 36 3 1 2 ## 3 23 3 1 1 ## Occupation No.of.dependents Telephone Foreign.Worker ## 1 3 1 1 1 ## 2 3 2 1 1 ## 3 2 1 1 1 str(mis.datos) ## &#39;data.frame&#39;: 1000 obs. of 21 variables: ## $ Creditability : int 1 1 1 1 1 1 1 1 1 1 ... ## $ Account.Balance : int 1 1 2 1 1 1 1 1 4 2 ... ## $ Duration.of.Credit..month. : int 18 9 12 12 12 10 8 6 18 24 ... ## $ Payment.Status.of.Previous.Credit: int 4 4 2 4 4 4 4 4 4 2 ... ## $ Purpose : int 2 0 9 0 0 0 0 0 3 3 ... ## $ Credit.Amount : int 1049 2799 841 2122 2171 2241 3398 1361 1098 3758 ... ## $ Value.Savings.Stocks : int 1 1 2 1 1 1 1 1 1 3 ... ## $ Length.of.current.employment : int 2 3 4 3 3 2 4 2 1 1 ... ## $ Instalment.per.cent : int 4 2 2 3 4 1 1 2 4 1 ... ## $ Sex...Marital.Status : int 2 3 2 3 3 3 3 3 2 2 ... ## $ Guarantors : int 1 1 1 1 1 1 1 1 1 1 ... ## $ Duration.in.Current.address : int 4 2 4 2 4 3 4 4 4 4 ... ## $ Most.valuable.available.asset : int 2 1 1 1 2 1 1 1 3 4 ... ## $ Age..years. : int 21 36 23 39 38 48 39 40 65 23 ... ## $ Concurrent.Credits : int 3 3 3 3 1 3 3 3 3 3 ... ## $ Type.of.apartment : int 1 1 1 1 2 1 2 2 2 1 ... ## $ No.of.Credits.at.this.Bank : int 1 2 1 2 2 2 2 1 2 1 ... ## $ Occupation : int 3 3 2 2 2 2 2 2 1 1 ... ## $ No.of.dependents : int 1 2 1 2 1 2 1 2 1 1 ... ## $ Telephone : int 1 1 1 1 1 1 1 1 1 1 ... ## $ Foreign.Worker : int 1 1 1 2 2 2 2 2 1 1 ... Eliminar la columna Telephone de los datos, ya que este atributo no puede explicar la variable de salida (si un cliente es de buena paga o mala paga), asignando un valor NULL a este atributo de mis.datos # eliminar la columna Telephone de los datos mis.datos$Telephone &lt;- NULL 17.3 Normalizar datos Normalizar los datos numéricos, menos la variable de salida. Una RNN (red neuronal) típicamente requiere eso (más que otros modelos / algoritmos). Normalizar los datos correspondientes entre 0 y 1. Digamos aquí los siguientes atributos se deben normalizar: Duration.of.Credit..month. , Credit.Amount , Age..years. Es decir, hablamos de las columnas 3, 6 y 14 # normalizar los valores entre 0 y 1 # aquí las columnas con valores númericas. Es decir, las columnas 3, 6 y 14 mis.datos[, c(3,6,14)] &lt;- apply(mis.datos[, c(3,6,14)], MARGIN = 2, FUN = function(X) (X - min(X))/diff(range(X))) # también con la función scale() esto es posible: # maxs &lt;- apply(mis.datos[, c(3,6,14)], 2, max) # mins &lt;- apply(mis.datos[, c(3,6,14)], 2, min) # mis.datos[,c(3,6,14)] &lt;- scale(mis.datos[, c(3,6,14)], center = mins, scale = maxs - mins) Variables categóricas podemos someter a One-Hot-Encoding para mejorar (potencialmente) el desempeño del modelo (aquí de la red neuronal) Las variables categóricas contienen valores de etiqueta (haciendo referencia a una categoría como p.ej. nivel género: M, F) en lugar de valores numéricos Por consigiente, se requiere a menudo la transformación de estas variables One-Hot-Encoding transforma una variable categórica a un número entero, que el cómputo puede entender más facilmente. Aquí, en el data frame mis.datos las variables categoricas como p.ej. Occupation ya son codificados como números (que representan las categorias). Entonces, vamos a dejar los datos como están, sin aplicar el One-Hot-Encoding en este ejemplo 17.4 Particionar los datos El próximo paso consiste en particionar los datos en entrenamiento y pruebas de forma 66%/34% # particionar los datos d &lt;- sample(nrow(mis.datos), nrow(mis.datos)*0.66, replace=FALSE) train &lt;- mis.datos[d, ] test &lt;- mis.datos[-d, ] 17.5 Crear la Red Neuronal Ahora vamos a construir la red neuronal, utilizando el paquete neuralnet de R Identificar la variable de salida del modelo. Aqui: Creditability Tomar el resto de las variables como variables de entrada Generar la red neuronal utilizando la función neuralnet() con los parámetros: hidden = c(10,5), linear.output = FALSE, act.fct = logistic, threshold = 0.01 (para más detalles ver las páginas de ayuda de neuralnet) if(!require(&#39;neuralnet&#39;)) install.packages(&#39;neuralnet&#39;); library(neuralnet) ## Loading required package: neuralnet ## ## Attaching package: &#39;neuralnet&#39; ## The following object is masked from &#39;package:dplyr&#39;: ## ## compute rn_model &lt;- neuralnet(Creditability~., data = train, hidden = c(10,5), linear.output = FALSE, act.fct = &#39;logistic&#39;, threshold = 0.01) # act.fct puede ser logistic o tanh Graficar la red neuronal y observar los pesos que la red neuronal asignó a cada variable de entrada (cada variable independiente), utilizando la función plot() con los parámetros rn_model y rep=best # graficar con plot() # observar pesos asignados a las variables plot(rn_model, rep=&#39;best&#39;) Ahora, calcular el resultado, utilizando la función compute() con el fin de calcular la red neuronal Nota: Esta función recibe como parámetros el modelo rn_model y los datos test, pero sin la variable de salida (columna Creditability) Asignar el resultado a una variable: rn_model.resultados # calcular el resultado rn_model.resultados &lt;- compute(rn_model, test[ , -1]) # head(rn_model.resultados) 17.6 Realizar la predicción Finalmente, extraer del modelo de la red neuronal construido (rn_model) la predicción, accediendo al atributo net.result y asignar el resultado a una variable prediccion Utilizar la variable predicción para generar un data frame de dos columnas con los valores actuales de test$Creditability y con la prediccion para esta variable, realizada por el modelo (la red neuronal) Nota: La predicción finalmente es un porcentaje #predicción prediccion_RN &lt;- rn_model$net.result resultados &lt;- data.frame(actual=test$Creditability, pred=rn_model.resultados$net.result) head(resultados) ## actual pred ## 6 1 1.000000e+00 ## 15 1 1.552670e-14 ## 21 1 1.000000e+00 ## 24 1 1.000000e+00 ## 25 1 1.000000e+00 ## 27 1 9.999995e-01 Generar la tabla de clasificación (tabla de confusión) para visualizar de esta forma los resultados (valor actual de Creditibility vs el valor predicho) # tabla de confusión table(actual=resultados$actual, pred=ifelse(resultados$pred &gt; 0.5, 1, 0)) ## pred ## actual 0 1 ## 0 63 54 ## 1 52 171 Determinar la exactitud del modelo (red neuronal) # exactitud mean(resultados$actual==ifelse(resultados$pred &gt; 0.5, 1, 0)) # 0.6882353 ## [1] 0.6882353 ¿Qué es lo que se puede decir con respecto a la exactitud del modelo y su capacidad de clasificar los datos / registros (en buena paga y mala paga)? "],["VaR.html", "Sección 18 Determinar el VaR 18.1 Objetivo 18.2 Determinar retornos log 18.3 Generar estadística de datos 18.4 VaR", " Sección 18 Determinar el VaR 18.1 Objetivo Determinar, de diferentes formas, el valor en riesgo (VaR, value at risk): VaR paramétrico VaR histórico VaR Montecarlo 18.1.1 Obtener unos datos (Serie de tiempo, ST) Descargar desde yahoo finance datos para Google (ticker: GOOG), para el periodo 2018-01-01 hasta 2021-03-10, utilizando el paquete quantmod Utilizar para el serie de tiempo el precio adjusted close (GOOG.Adjusted) Mostrar los últimos 6 registros descargados library(quantmod) stockEnv &lt;- new.env() tickers &lt;- &#39;GOOG&#39; startdate &lt;- &#39;2018-01-01&#39; enddate &lt;- &#39;2021-03-10&#39; getSymbols(tickers, env=stockEnv, src=&#39;yahoo&#39;, from = startdate, to = enddate) ## [1] &quot;GOOG&quot; #stockEnv$GOOG data &lt;- stockEnv$GOOG #str(data) #head(data) print(tail(data$GOOG.Adjusted)) ## GOOG.Adjusted ## 2021-03-02 2075.84 ## 2021-03-03 2026.71 ## 2021-03-04 2049.09 ## 2021-03-05 2108.54 ## 2021-03-08 2024.17 ## 2021-03-09 2052.70 18.2 Determinar retornos log Luego, determinar los retornos log para estos precios log_returns &lt;- diff(log(data$GOOG.Adjusted), lag=1) head(log_returns, 2) ## GOOG.Adjusted ## 2018-01-02 NA ## 2018-01-03 0.01627989 tail(log_returns, 2) ## GOOG.Adjusted ## 2021-03-08 -0.04083602 ## 2021-03-09 0.01399621 Quitar NA que se generó por lag sobre escribir NA por el valor del segundo log return dim(log_returns) ## [1] 801 1 log_returns[1,1] &lt;- log_returns[2,1] Presentar el resumen de los log returns (multiplacado por 100) # resumen summary(log_returns*100) ## Index GOOG.Adjusted ## Min. :2018-01-02 Min. :-11.76673 ## 1st Qu.:2018-10-17 1st Qu.: -0.70491 ## Median :2019-08-06 Median : 0.15227 ## Mean :2019-08-05 Mean : 0.08395 ## 3rd Qu.:2020-05-21 3rd Qu.: 1.10228 ## Max. :2021-03-09 Max. : 9.93796 18.3 Generar estadística de datos Generar una variable statistics con la siguiente estadística: la longitud de los datos (¿cuantos registros hay?) el precio promedio el promedio de los log returns la desviación estándar de los log returns los retornos log anualizados: (255 * mean(log_returns)) # estadistica statistics &lt;- c(length(data$GOOG.Adjusted), mean(data$GOOG.Adjusted), mean(log_returns), sd(log_returns), 255*mean(log_returns)) statistics ## [1] 8.010000e+02 1.300582e+03 8.395269e-04 1.953059e-02 2.140794e-01 Asignar los siguientes nombres para la estadísticas calculados: Total days, Average price, Daily change, Daily volatility, Annualized returns Mostrar la el contenido de la variable statistics en pantalla # asignar nombres names(statistics) &lt;- c(&quot;Total days&quot;, &quot;Average price&quot;, &quot;Daily change&quot;, &quot;Daily volatility&quot;, &quot;Annualized returns&quot;) statistics ## Total days Average price Daily change Daily volatility ## 8.010000e+02 1.300582e+03 8.395269e-04 1.953059e-02 ## Annualized returns ## 2.140794e-01 18.3.1 Volatilidad Generar una variable volatility a partir de statistics y Mostrar el contenido de la variable generada en pantalla volatility &lt;- statistics[4] volatility ## Daily volatility ## 0.01953059 18.3.2 Retorno diario Generar una variable daily.return a partir de statistics y Mostrar el contenido de la variable generada en pantalla # daily average return (nota: anualizado = &quot;drift&quot;) daily.return &lt;- statistics[3] daily.return ## Daily change ## 0.0008395269 18.3.3 Supuestos para el cálculo del VaR Determinar el VaR (Valor en Riesgo) Asumir que se tienen 5000 acciones (de Google) Determinar el valor del portafolio con base en esta cantidad y el último precio y asignar el resultado a una variable value.portafolio Mostrar el valor del portafolio en la pantalla Asumir una duración (holding.period) de un día y alpha de 0.01 Es decir, un nivel de confianza (confidence) de 1-alpha (99%) Eso para calcular finalmente un VaR99% 18.4 VaR # Determinar el VaR # Parámetros de entrada cantidad &lt;- 5000 # cantidad de activos (&quot;stocks&quot;) value1 &lt;- tail(data$GOOG.Adjusted,1) # ultimo precio value.portfolio &lt;- value1 * cantidad print(value.portfolio) ## GOOG.Adjusted ## 2021-03-09 10263500 holding.period &lt;- 1 # dimensión de tiempo para el VaR alpha &lt;- 0.01 # nivel de confianza = 99% confidence &lt;- 1-alpha # VaR99% 18.4.1 VaR paramétrico Determinar el VaR parmétrico Mostrar su valor en la pantalla # Calcular el VaR - versión VAR paramétrico parametric.var &lt;- abs(value.portfolio * qnorm(1-confidence, 0, 1)*volatility * sqrt(holding.period)) names(parametric.var) &lt;- &quot;Parametric VaR&quot; parametric.var ## Parametric VaR ## 2021-03-09 466321.5 18.4.2 VaR histórico Determinar el VaR histórico y Mostrar su valor en la pantalla # Calcular el VaR - versión VaR histórico historical.var &lt;- abs(quantile(log_returns, 1-confidence)*value.portfolio) names(historical.var) &lt;- &quot;Historical VaR&quot; historical.var ## Historical VaR ## 2021-03-09 534556.3 18.4.3 VaR Montecarlo Determinar el VaR con base en una simulación Montecarlo # Calcular el VaR - versión VaR Montecarlo # Diferencia principal: parte de retornos simulados # Montecarlo (MC): 10000 iteraciones &quot;intentos hipotéticos con resepcto a los retornos&quot;) MC.returns &lt;- rnorm(10000, statistics[3], statistics[4] ) # MC.returns # log_returns simulados MC.var &lt;- abs(quantile(MC.returns, 1-confidence)*value.portfolio) names(MC.var) &lt;- &quot;MC VaR&quot; MC.var ## MC VaR ## 2021-03-09 457342.2 18.4.4 Comparativo de los tres VaRs Mostrar los 3 VaRs calculados en una tabla (en un vector) # resultado var.vector &lt;- c(parametric.var[[1]], historical.var[[1]], MC.var[[1]]) names(var.vector) &lt;- c(&quot;VaR paramétrico&quot;, &quot;VaR histórico&quot;, &quot;VaR MC&quot;) var.vector ## VaR paramétrico VaR histórico VaR MC ## 466321.5 534556.3 457342.2 # un inversionista debe esperarar de sufrir pérdidas mayor a 534556,3 $ en 5% de los casos Es decir, un inversionista debe esperarar de sufrir pérdidas mayor a 534556,3 $ en 5% de los casos. "],["ST.html", "Sección 19 Serie de tiempo 19.1 Objetivo 19.2 Cargar datos 19.3 Graficar la serie 19.4 Comprobar, si es estacionaria 19.5 Identificando una serie no estacionaria 19.6 ARIMA 19.7 Pronóstico 19.8 Ejercicio", " Sección 19 Serie de tiempo 19.1 Objetivo Realizar un pronóstico con base en una serie de tiempo de datos, utilizando un modelo ARIMA Fuente: El siguiente ejemplo fue publicado por Hassan OUKHOUYA (14/09/2021). Financial Time series Analysis and Forecasting using R. https://rpubs.com/HassanOUKHOUYA/time_series 19.2 Cargar datos Decargar datos de la acción de Google (ticker GOOG) desde la web (yahoo finance), utilizando el paquete quantmod de R Esto para el periodo de 2005-02-07 hasta 2005-07-08 Mostrar los útlimos 6 registros de estos datos if(!require(&#39;quantmod&#39;)) install.packages(&#39;quantmod&#39;); library(quantmod) stockEnv &lt;- new.env() tickers &lt;- c(&#39;GOOG&#39;) startDate &lt;- &#39;2005-02-07&#39; endDate &lt;- &#39;2005-07-08&#39; getSymbols(Symbols = tickers, env = stockEnv, src = &#39;yahoo&#39;, from = startDate, to = endDate) ## [1] &quot;GOOG&quot; data &lt;- stockEnv$GOOG tail(data) ## GOOG.Open GOOG.High GOOG.Low GOOG.Close GOOG.Volume GOOG.Adjusted ## 2005-06-29 150.6852 151.6217 145.5295 145.8135 36734576 145.8135 ## 2005-06-30 146.6204 148.9069 144.9766 146.5258 30301955 146.5258 ## 2005-07-01 146.9691 147.5669 144.0700 145.0812 18524375 145.0812 ## 2005-07-05 145.5046 147.4374 144.5731 147.3029 15044179 147.3029 ## 2005-07-06 148.0949 148.2443 145.1459 145.2157 16060574 145.2157 ## 2005-07-07 144.1547 147.3477 143.7163 147.2182 21424203 147.2182 Seleccionar los precios ajustados (GOOG.Adjusted) únicamente y asignarlos a una variable precios Mostrar los útlimos 2 registros de estos datos Mostrar, de cuál clase (class) es la variable precios # Seleccionar los precios ajustados (GOOG.Adjusted) únicamente precios &lt;- data$GOOG.Adjusted tail(precios,2) ## GOOG.Adjusted ## 2005-07-06 145.2157 ## 2005-07-07 147.2182 # class(precios) # &quot;xts&quot; &quot;zoo&quot; Presentar un resumen estadístico de los precios (de la serie de tiempo) Observar el nombre de la primera columna de estos datos summary(precios) # o summary(precios$GOOG.Adjusted) ## Index GOOG.Adjusted ## Min. :2005-02-07 Min. : 87.17 ## 1st Qu.:2005-03-16 1st Qu.: 93.35 ## Median :2005-04-22 Median :107.50 ## Mean :2005-04-22 Mean :111.94 ## 3rd Qu.:2005-05-31 3rd Qu.:136.89 ## Max. :2005-07-07 Max. :151.48 19.3 Graficar la serie Graficar los datos, utilizando el paquete ggplot2 y un diagrama de línea, donde en el eje horizontal deben salir las fechas (de los precios) y en el eje vertical los precios (del activo) como tal ¿Qué es lo que se puede decir, sobre la tendencia de esta serie de tiempo, basado en la gráfica construida? if(!require(&#39;ggplot2&#39;)) install.packages(&#39;ggplot2&#39;); library(ggplot2) # fortify convierte de la clase un xts / zoo en un data frame p &lt;- ggplot(fortify(precios), aes(x=Index, y=GOOG.Adjusted)) + geom_line() + labs(x = &#39;Fecha&#39;, y = &#39;Precio GOOG&#39;, title = &#39;&#39;) p Graficar los datos, pero ahora utilizando la función chartSeries() del paquete quantmod, aplicando como tipo del diagrama bars (barras) # Graficar los datos, utilizando la función chartSeries() del paquete quantmod chartSeries(precios, type = &quot;bars&quot;, theme=&quot;white&quot;,main=&quot;Google Stock&quot;) 19.4 Comprobar, si es estacionaria Una serie de tiempo es estacionaria, cuando ésta es estable a lo largo del tiempo (es decir, media y varianza son constantes en el tiempo) H0: La serie de datos no es estacionaria H1: Sí, la serie es estacioanria (= series has no unit root) Para realizar esta prueba, con respecto a las hipotésis mencionadas, utilizar el Augmented Dickey-Fuller test (ADF), del paquete tseries de R (función: adf.test()) Si el valor p, que arroja la prueba, es mayor que 5% (0.05), la serie no es estacionaria (non stationary) if(!require(&#39;tseries&#39;)) install.packages(&#39;tseries&#39;); library(tseries) ## Loading required package: tseries adf.test(precios$GOOG.Adjusted) # p-value 0.5848 ## ## Augmented Dickey-Fuller Test ## ## data: precios$GOOG.Adjusted ## Dickey-Fuller = -1.9804, Lag order = 4, p-value = 0.5848 ## alternative hypothesis: stationary 19.5 Identificando una serie no estacionaria Aplicar la función acf(): autocorrelation factor # Aplicar la función acf() del paquete stats acf(precios$GOOG.Adjusted) Nota: Dado que el ACF del precio no cae a cero con relativa rapidez y el valor de la autocorrelación es relativamente alto y positivo, la serie no es estacionaria. 19.5.1 Convertir a estacionaria Hay tres técnicas comúnmente utilizadas para hacer que una serie de tiempo sea estacionaria: Eliminación de la tendencia: se elimina el componente de tendencia de la serie de tiempo Diferenciación: esta es la técnica comúnmente utilizada para eliminar la no estacionariedad. Aquí tratamos de modelar las diferencias de los términos (precios) y no el término real (precio como tal). Esta diferenciación es la parte de la integración en AR(I)MA Estacionalidad: la estacionalidad se puede incorporar fácilmente en el modelo ARIMA directamente. 19.5.2 Retornos log Vamos a calcular el retorno logarítmico para que la serie sea estacionaria, que es exactamente la diferenciación: Primero, calcular entonces los retornos logarítmicos para los precios del activo (nota: esto genera al inicio un registro con NA.) Agregar estos retornos log como una nueva columna a precios Eliminar el registro con NA (p.ej. utilizando la función na.omit()) Mostrar las primeras 6 filas de los datos log.ret &lt;- diff(log(precios$GOOG.Adjusted), lag=1) # genera un NA al inicio precios$log.ret &lt;- log.ret # agregar una nueva columna con los retornos log precios &lt;- na.omit(precios) # omitir registro/s con NA # head(precios) Graficar los retornos log calculados, utilizando ggplot y un diagrama de línea library(ggplot2) p.log &lt;- ggplot(precios, aes(x=Index, y=log.ret)) + geom_line() + labs(x=&#39;Fecha&#39;, y = &#39;retornos log&#39;, title = &#39; &#39;) p.log Se pueden observar aumentos y disminuciones fuertes en la volatilidad de los retornos logarítmicos Es decir, la varianza cambia con el tiempo 19.5.3 Diferenciar (1st order) Intentar estabilizar la serie de tiempo diferenciándola (1st order differencing de los precios (atributo: GOOG.Adjusted) Agregar estos datos diferenciados como una nueva columna al objeto / a la variable precios Graficar los datos (precios) diferenciados, utilizando ggplot # Diferenciar la serie de tiempo (1st order differencing) precio_dif &lt;- diff(precios$GOOG.Adjusted) precios$Adj_dif &lt;- precio_dif precios &lt;- na.omit(precios) #head(precios, 3) library(ggplot2) p.dif &lt;- ggplot(precios, aes(x=Index, y=Adj_dif)) + geom_line() + labs(x=&#39;Fecha&#39;, y = &#39;precios: diferencias&#39;, title = &#39;1st order differencing&#39;) p.dif Se puede observar que los datos de la gráfica no muestran una tendencia (variación de la media en el tiempo). También que, en términos generales, la varianza no cambia mucho en el tiempo Realizar nuevamente la prueba Augmented Dickey-Fuller (ADF), función adf.test(), ahora con los datos diferenciados y utilizando el parámetro alternative=stationary Analizar el valor p (ahora se espera que este se ubica por debejo del umbral de 5%) # ADF para los precios diferenciados adf.test(precios$Adj_dif, alternative=&quot;stationary&quot;) # p-value = 0.01493 ## ## Augmented Dickey-Fuller Test ## ## data: precios$Adj_dif ## Dickey-Fuller = -3.9705, Lag order = 4, p-value = 0.01333 ## alternative hypothesis: stationary Se puede observar que el valor p es alredor de 1,4% (menor que 5%) y por lo tanto la serie de tiempo es ahora estacionaria Ahora, se pueden determinar las parámetros p y q para el modelo ARIMA 19.6 ARIMA 19.6.1 acf Generar primero una gráfica que muestra la autocorrelación normal, utilizando los datos diferenciados (aquí: precios$Adj_dif) y la función acf() # ARIMA # Normal and Partial Autocorrelation Functions ACF &amp; PACF acf(precios$Adj_dif) La gráfica (acf) anterior muestra que el rendimiento diario (o la primera diferencia, 1st order differencing) de los precios de las acciones de Google están cerca del ruido blanco (todos los ACF son cerca de cero). El ACF baja relativamente rapido a cero, lo que indica que la serie de tiempo es estacionaria 19.6.2 pacf Ahora, generar una gráfica que muestra la autocorrelación parcial, utilizando los datos diferenciados (aquí: precios$Adj_dif) y la función pacf() # Partial Autocorrelation Function pacf(precios$Adj_dif) Todos los pacf están cerca cerca de cero, lo que indica que la serie de tiempo es estacionaria 19.6.3 auto.arima Ahora podemos crear un modelo ARIMA (autorregresivo integrado de media móvil), utilizando el paquete forecast de R y la función auto.arima() con los datos diferenciados (precios$Adj_dif) y el parámetro seasonal=FALSE Esto explora combinaciones (p,d,q para ARIMA) mediante la función auto.arima(). El resultado (la combinación) que tenga el BIC y AIC más bajo sería nuestra elección # ARIMA (auto arima) if(!require(forecast)) install.packages(&#39;forecast&#39;); library(forecast) ## Loading required package: forecast ## ## Attaching package: &#39;forecast&#39; ## The following object is masked from &#39;package:sets&#39;: ## ## %&gt;% ## The following object is masked from &#39;package:DescTools&#39;: ## ## BoxCox modelo.ARIMA &lt;- auto.arima((precios$Adj_dif), seasonal=FALSE) modelo.ARIMA # ARIMA(0,0,0) with non-zero mean ## Series: (precios$Adj_dif) ## ARIMA(0,0,0) with non-zero mean ## ## Coefficients: ## mean ## 0.4686 ## s.e. 0.2182 ## ## sigma^2 estimated as 4.95: log likelihood=-228.02 ## AIC=460.04 AICc=460.16 BIC=465.31 Nota: auto.arima resulta con los parámetros p,d,q todos en 0 Recordar: d es la cantidad de veces que se realiza la diferenciación. p es el orden del término Auto Regresivo (AR). Se refiere al número de retrasos. q es el orden del término promedio móvil (MA). Se refiere a la cantidad de errores de pronóstico retrasados. Utilizar auto.arima ahora con los precios (GOOG.Adjusted) de la acción (y no con los precios diferenciados como en el paso anterior) # Comprobando ARIMA (auto arima) if(!require(forecast)) install.packages(&#39;forecast&#39;); library(forecast) modelo1.ARIMA &lt;- auto.arima((precios$GOOG.Adjusted), seasonal=FALSE) modelo1.ARIMA # ARIMA(0,1,0) with drift ## Series: (precios$GOOG.Adjusted) ## ARIMA(0,1,0) with drift ## ## Coefficients: ## drift ## 0.5077 ## s.e. 0.2168 ## ## sigma^2 estimated as 4.841: log likelihood=-224.66 ## AIC=453.32 AICc=453.44 BIC=458.57 Observar que los parámetros para p.q,d son: 0,1,0 De acuerdo con lo anterior, implementar el modelo ARIMA Luego muestra el resumen estadístico para el modelo implementado #Implementar un modelo ARIMA (0,1,0) modelo &lt;- Arima(precios$GOOG.Adjusted, order=c(0,1,0), include.constant=T) summary(modelo) ## Series: precios$GOOG.Adjusted ## ARIMA(0,1,0) with drift ## ## Coefficients: ## drift ## 0.5077 ## s.e. 0.2168 ## ## sigma^2 estimated as 4.841: log likelihood=-224.66 ## AIC=453.32 AICc=453.44 BIC=458.57 ## ## Training set error measures: ## ME RMSE MAE MPE MAPE MASE ## Training set 0.0009215975 2.178703 1.61447 -0.05899551 1.418198 0.9627422 ## ACF1 ## Training set 0.07036134 Comprobar los residuos para el modelo ARIMA(0,1,0) #Comprobar los residuos para el modelo ARIMA (0,1,0) checkresiduals(modelo) ## ## Ljung-Box test ## ## data: Residuals from ARIMA(0,1,0) with drift ## Q* = 3.5602, df = 9, p-value = 0.9379 ## ## Model df: 1. Total lags used: 10 Así podemos confirmar que los residuos son distinguibles de una serie de ruido blanco ya que los resultados son significativos. 19.7 Pronóstico Graficar (con la función plot()) el pronóstico, utilizando la función forecast(), para los próximo 5 días (periodos: parámetro h=5) Mostrar el resumen del pronóstico para los próximos 5 días, utilizando un nivel de confianza de 99% (level=99) y la función summary() para el pronóstico realizado arima_forecast = forecast(modelo,h=5,level=99) # donde level es el nivel de confianza para el pronóstico summary(arima_forecast) ## ## Forecast method: ARIMA(0,1,0) with drift ## ## Model Information: ## Series: precios$GOOG.Adjusted ## ARIMA(0,1,0) with drift ## ## Coefficients: ## drift ## 0.5077 ## s.e. 0.2168 ## ## sigma^2 estimated as 4.841: log likelihood=-224.66 ## AIC=453.32 AICc=453.44 BIC=458.57 ## ## Error measures: ## ME RMSE MAE MPE MAPE MASE ## Training set 0.0009215975 2.178703 1.61447 -0.05899551 1.418198 0.9627422 ## ACF1 ## Training set 0.07036134 ## ## Forecasts: ## Point Forecast Lo 99 Hi 99 ## 104 147.7259 142.0586 153.3931 ## 105 148.2336 140.2189 156.2483 ## 106 148.7413 138.9253 158.5573 ## 107 149.2490 137.9145 160.5835 ## 108 149.7567 137.0843 162.4291 19.8 Ejercicio Estudiar o revisar series de tiempo con base en la siguiente fuente: Morales-Oñate, V. (Junio 2021). Notas de clase - Series de Tiempo. https://bookdown.org/victor_morales/SeriesdeTiempo/ "],["prophet.html", "Sección 20 Serie de tiempo con Prophet 20.1 Objetivo 20.2 Cargar datos 20.3 Convertir a data frame 20.4 Realizar el pronóstico con prophet", " Sección 20 Serie de tiempo con Prophet 20.1 Objetivo Realizar un pronóstico con base en una serie de tiempo de datos, utilizando el paquete Prophet, desarrollado por Facebook 20.2 Cargar datos Vamos a utilizar los mismos datos como en el ejercicio anterior sobre series de tiempo. Es decir: Decargar datos de la acción de Google (ticker GOOG) desde la web (yahoo finance), utilizando el paquete quantmod de R y asignar el resultado a una variable data Esto para el periodo de 2005-02-07 hasta 2005-07-08 Mostrar los útlimos 6 registros de estos datos (de la variable data) Mostrar la clase de la variable data if(!require(&#39;quantmod&#39;)) install.packages(&#39;quantmod&#39;); library(quantmod) stockEnv &lt;- new.env() tickers &lt;- c(&#39;GOOG&#39;) startDate &lt;- &#39;2005-02-07&#39; endDate &lt;- &#39;2005-07-08&#39; getSymbols(Symbols = tickers, env = stockEnv, src = &#39;yahoo&#39;, from = startDate, to = endDate) ## [1] &quot;GOOG&quot; data &lt;- stockEnv$GOOG tail(data) ## GOOG.Open GOOG.High GOOG.Low GOOG.Close GOOG.Volume GOOG.Adjusted ## 2005-06-29 150.6852 151.6217 145.5295 145.8135 36734576 145.8135 ## 2005-06-30 146.6204 148.9069 144.9766 146.5258 30301955 146.5258 ## 2005-07-01 146.9691 147.5669 144.0700 145.0812 18524375 145.0812 ## 2005-07-05 145.5046 147.4374 144.5731 147.3029 15044179 147.3029 ## 2005-07-06 148.0949 148.2443 145.1459 145.2157 16060574 145.2157 ## 2005-07-07 144.1547 147.3477 143.7163 147.2182 21424203 147.2182 class(data) # [1] &quot;xts&quot; &quot;zoo&quot; ## [1] &quot;xts&quot; &quot;zoo&quot; 20.3 Convertir a data frame Ahora, convertir la variable data de xts , zoo a un data frame en R, utilizando la función data.frame() y asignar el resultado a una variable df Este data frame debe tener una columna index con las fechas de la serie de tiempo y en las demás columnas los precios (formato OHLC) Nota: Todos estos precios se pueden asignar mediante el paámetro coredata de data.frame() Mostrar la estructura de df (str()) Mostrar las primeras 6 filas con las fechas de df # convertir fechas en una columna, mediante el cast a un data.frame # y escribir los datos a un archivo csv # write.csv(data.frame(df), &#39;google.csv&#39;) # luego se pueden leer los datos con read.csv, lo que incluye la columna con las fechas # o se puede convertir el objetivo xts a un dataframe df &lt;- data.frame(date=index(data), coredata(data)) str(df) ## &#39;data.frame&#39;: 105 obs. of 7 variables: ## $ date : Date, format: &quot;2005-02-07&quot; &quot;2005-02-08&quot; ... ## $ GOOG.Open : num 102.2 98.1 100 95.6 93 ... ## $ GOOG.High : num 102.8 99.6 100.4 95.7 95.8 ... ## $ GOOG.Low : num 97.4 96.9 94.4 92.3 92.7 ... ## $ GOOG.Close : num 97.6 98.9 95.4 93.6 93.4 ... ## $ GOOG.Volume : num 26017958 23046060 34471726 38107704 26330324 ... ## $ GOOG.Adjusted: num 97.6 98.9 95.4 93.6 93.4 ... head(df[,1]) ## [1] &quot;2005-02-07&quot; &quot;2005-02-08&quot; &quot;2005-02-09&quot; &quot;2005-02-10&quot; &quot;2005-02-11&quot; ## [6] &quot;2005-02-14&quot; Asignar a una variable df2 únicamenete los valores de la primera columna (con la fechas) y de la séptima columna (GOOG.Adjusted) de df Mostrar la estructura de df2 (str()) # subsetting solo columna de la fecha (col 1) y el cierre ajustado (col 7) df2 &lt;- df[ , c(1,7)] str(df2) ## &#39;data.frame&#39;: 105 obs. of 2 variables: ## $ date : Date, format: &quot;2005-02-07&quot; &quot;2005-02-08&quot; ... ## $ GOOG.Adjusted: num 97.6 98.9 95.4 93.6 93.4 ... 20.4 Realizar el pronóstico con prophet Realizar el pronóstico, utilizando el paquete prophet Esto require primero cambiar el nombre de las columnas del data frame df2. Fechas = ds y GOOG.Adjusted = y Mostrar la estructura de df2 Donde: y(t) = g(t) + s(t) + h(t) + epsilon g(t): modela el crecimiento periódico. Prophet deteca automaticamente cambios en la tendencia y señala puntos de cambio s(t): estacionaridad. Prophet usa una serie Fourier y el componente estacional semanal h(t): el compenente de vacacciones epsilon: el término de error, que utiliza prophet # pronóstico con facebook prophet if(!require(&#39;prophet&#39;)) install.packages(&#39;prophet&#39;); library(prophet) ## Loading required package: prophet ## Loading required package: rlang ## ## Attaching package: &#39;rlang&#39; ## The following object is masked from &#39;package:igraph&#39;: ## ## is_named ## The following objects are masked from &#39;package:purrr&#39;: ## ## %@%, as_function, flatten, flatten_chr, flatten_dbl, flatten_int, ## flatten_lgl, flatten_raw, invoke, list_along, modify, prepend, ## splice # y(t) = g(t) + s(t) + h(t) + epsilon # g(t): modela el crecimiento periódico. Prophet deteca automaticamente # cambios en la tendencia y señala puntos de cambio # s(t): estacionaridad. Prophet usa una serie Fourier y el componente estacional semanal # h(t): el compenente de vacacciones # epsilon: el término de error, que utiliza prophet colnames(df2) &lt;- c(&#39;ds&#39;, &#39;y&#39;) str(df2) ## &#39;data.frame&#39;: 105 obs. of 2 variables: ## $ ds: Date, format: &quot;2005-02-07&quot; &quot;2005-02-08&quot; ... ## $ y : num 97.6 98.9 95.4 93.6 93.4 ... 20.4.1 Crear el modelo Crear el modelo de pronóstico, utilizando la función prophet() con df2 y asignar el resultado a una variable model #crear el modelo de pronóstico, utilizando prophet model &lt;- prophet(df2) ## Disabling yearly seasonality. Run prophet with yearly.seasonality=TRUE to override this. ## Disabling daily seasonality. Run prophet with daily.seasonality=TRUE to override this. Con make_future_dataframe() debemos generar un dataframe con las fechas de los futuros periodos y asignar el resultado a una variable future Aquí en el ejemplo aplicamos el model y el parámetro: periods=3*30 al respecto Luego, mostrar las últimas 6 filas (registros) de future # con make_future_dataframe() podemos generar un dataframe con las fechas de # los futuros periodos future &lt;- make_future_dataframe(model,periods=3*30) tail(future) ## ds ## 190 2005-09-30 ## 191 2005-10-01 ## 192 2005-10-02 ## 193 2005-10-03 ## 194 2005-10-04 ## 195 2005-10-05 20.4.2 Pronosticar - predict Luego, aplicar la función predict() para predicir los valores (precios) futuros y asignar el resultado a una variable forecast. Esta función recibe como parámetros: model y future Mostrar las últimas 6 filas de forecast, pero únicamente los valores de las siguientes columnas: ds,yhat, yhat_lower, yhat_upper # aplicar el método predict() para predicir los valores (precios) futuros forecast &lt;- predict(model, future) # tail(forecast) tail(forecast[c(&#39;ds&#39;,&#39;yhat&#39;, &#39;yhat_lower&#39;, &#39;yhat_upper&#39;)]) ## ds yhat yhat_lower yhat_upper ## 190 2005-09-30 177.3840 156.3210 197.7868 ## 191 2005-10-01 177.9774 156.8485 199.3778 ## 192 2005-10-02 178.3117 157.0199 199.7805 ## 193 2005-10-03 178.9650 157.3314 201.0657 ## 194 2005-10-04 179.2917 155.9497 202.2743 ## 195 2005-10-05 179.2408 156.7446 202.3476 Graficar con la función plot() con base en: model y forecast #graficar plot(model, forecast) Utilizando la función prophet_plot_components() con model y forecast para mostrar los componentes de la serie de tiempo, como la tendencia de los precios # componentes en términos de la tendencia y de la estacionalidad semanal prophet_plot_components(model, forecast) Presentar una gráfica más interactiva, utilizando la función dyplot.prophet() # gráfica más interactiva dyplot.prophet(model, forecast) ## Warning: `select_()` was deprecated in dplyr 0.7.0. ## Please use `select()` instead. Intentar mejorar el modelo construido Aplciar: prophet(daily.seasonality = FALSE, yearly.seasonality = FALSE) y asignar el resultado a una variable model2 Agregar: add_seasonality(model2, name=self_defined_cycle, period=8, fourier.order = 8,mode=additive) Finalmente, asignar fit.prophet(model2, df2) a model2 # mejorar el modelo model2 &lt;- prophet(daily.seasonality = FALSE, yearly.seasonality = FALSE) add_seasonality(model2, name=&#39;self_defined_cycle&#39;, period=8, fourier.order = 8,mode=&#39;additive&#39;) ## $growth ## [1] &quot;linear&quot; ## ## $changepoints ## NULL ## ## $n.changepoints ## [1] 25 ## ## $changepoint.range ## [1] 0.8 ## ## $yearly.seasonality ## [1] FALSE ## ## $weekly.seasonality ## [1] &quot;auto&quot; ## ## $daily.seasonality ## [1] FALSE ## ## $holidays ## NULL ## ## $seasonality.mode ## [1] &quot;additive&quot; ## ## $seasonality.prior.scale ## [1] 10 ## ## $changepoint.prior.scale ## [1] 0.05 ## ## $holidays.prior.scale ## [1] 10 ## ## $mcmc.samples ## [1] 0 ## ## $interval.width ## [1] 0.8 ## ## $uncertainty.samples ## [1] 1000 ## ## $specified.changepoints ## [1] FALSE ## ## $start ## NULL ## ## $y.scale ## NULL ## ## $logistic.floor ## [1] FALSE ## ## $t.scale ## NULL ## ## $changepoints.t ## NULL ## ## $seasonalities ## $seasonalities$self_defined_cycle ## $seasonalities$self_defined_cycle$period ## [1] 8 ## ## $seasonalities$self_defined_cycle$fourier.order ## [1] 8 ## ## $seasonalities$self_defined_cycle$prior.scale ## [1] 10 ## ## $seasonalities$self_defined_cycle$mode ## [1] &quot;additive&quot; ## ## $seasonalities$self_defined_cycle$condition.name ## NULL ## ## ## ## $extra_regressors ## list() ## ## $country_holidays ## NULL ## ## $stan.fit ## NULL ## ## $params ## list() ## ## $history ## NULL ## ## $history.dates ## NULL ## ## $train.holiday.names ## NULL ## ## $train.component.cols ## NULL ## ## $component.modes ## NULL ## ## $fit.kwargs ## list() ## ## attr(,&quot;class&quot;) ## [1] &quot;prophet&quot; &quot;list&quot; model2 &lt;- fit.prophet(model2, df2) De aquí en adelante es el viejo código, solo se actualizan los nombres: future2, forecast2 Con make_future_dataframe() podemos generar un dataframe future2 con las fechas de los futuros periodos: periods=3*30 Mostar la últimas 6 filas (registros) de future2 # de aquí en adelante es el &quot;viejo&quot; código, solo se actualizan los nombres: future2, forecast2 # con make_future_dataframe() podemos generar un dataframe con las fechas de # los futuros periodos future2 &lt;- make_future_dataframe(model2,periods=3*30) tail(future2) ## ds ## 190 2005-09-30 ## 191 2005-10-01 ## 192 2005-10-02 ## 193 2005-10-03 ## 194 2005-10-04 ## 195 2005-10-05 Luego, aplicar la función predict() para predicir los valores (precios) futuros y asignar el resultado a una variable forecast2. Esta función recibe como parámetros: model y future2 Mostrar las últimas 6 filas de forecast2, pero únicamente los valores de las siguientes columnas: ds,yhat, yhat_lower, yhat_upper # aplicar el método predict() para predicir los valores (precios) futuros forecast2 &lt;- predict(model2, future2) tail(forecast2) ## ds trend additive_terms additive_terms_lower ## 190 2005-09-30 177.6700 -0.28594278 -0.28594278 ## 191 2005-10-01 178.0042 -0.02678187 -0.02678187 ## 192 2005-10-02 178.3384 -0.02678187 -0.02678187 ## 193 2005-10-03 178.6727 0.29234492 0.29234492 ## 194 2005-10-04 179.0069 0.28477419 0.28477419 ## 195 2005-10-05 179.3412 -0.10036192 -0.10036192 ## additive_terms_upper weekly weekly_lower weekly_upper ## 190 -0.28594278 -0.28594278 -0.28594278 -0.28594278 ## 191 -0.02678187 -0.02678187 -0.02678187 -0.02678187 ## 192 -0.02678187 -0.02678187 -0.02678187 -0.02678187 ## 193 0.29234492 0.29234492 0.29234492 0.29234492 ## 194 0.28477419 0.28477419 0.28477419 0.28477419 ## 195 -0.10036192 -0.10036192 -0.10036192 -0.10036192 ## multiplicative_terms multiplicative_terms_lower multiplicative_terms_upper ## 190 0 0 0 ## 191 0 0 0 ## 192 0 0 0 ## 193 0 0 0 ## 194 0 0 0 ## 195 0 0 0 ## yhat_lower yhat_upper trend_lower trend_upper yhat ## 190 154.2788 200.1447 154.6399 199.1777 177.3840 ## 191 154.0635 200.4067 154.3411 199.8114 177.9774 ## 192 154.2585 200.4490 154.0483 200.4334 178.3117 ## 193 154.3843 201.9193 153.9344 201.0554 178.9650 ## 194 153.5469 202.0202 153.9282 201.7631 179.2917 ## 195 152.7730 204.3152 153.9287 202.6586 179.2408 tail(forecast2[c(&#39;ds&#39;,&#39;yhat&#39;, &#39;yhat_lower&#39;, &#39;yhat_upper&#39;)]) ## ds yhat yhat_lower yhat_upper ## 190 2005-09-30 177.3840 154.2788 200.1447 ## 191 2005-10-01 177.9774 154.0635 200.4067 ## 192 2005-10-02 178.3117 154.2585 200.4490 ## 193 2005-10-03 178.9650 154.3843 201.9193 ## 194 2005-10-04 179.2917 153.5469 202.0202 ## 195 2005-10-05 179.2408 152.7730 204.3152 Graficar con la función plot() con base en: model2 y forecast2 #graficar plot(model2, forecast2) Utilizando la función prophet_plot_components() con model2 y forecast2 para mostrar los componentes de la serie de tiempo, como la tendencia de los precios # componentes en términos de la tendencia y de la estacionalidad semanal prophet_plot_components(model2, forecast2) Presentar una gráfica más interactiva, utilizando la función dyplot.prophet(), con model2 y forecast2 Observar los resultados (el pronóstico) obtenido, navegando de forma interactiva la gráfica # gráfica más interactiva dyplot.prophet(model2, forecast2) "],["posibles-soluciones.html", "Sección 21 Posibles soluciones 21.1 Ejercicio 1 21.2 Ejercicio 2 21.3 Ejercicio 3 21.4 Ejercicio 4 21.5 Ejercicio 5 21.6 Ejercicio 6 21.7 Ejercicio 7 21.8 Ejercicio 8 21.9 Ejercicio 9 21.10 Ejercicio 10 21.11 Ejercicio 11", " Sección 21 Posibles soluciones 21.1 Ejercicio 1 21.1.1 Enunciado Utilizando R, calcular el valor presente de los siguientes flujos de caja: Año 1: -300 Año 2: +100 Año 3: +250 Tasa de descuento: 7.0% anual. 21.1.2 Posible solución a &lt;- -300 b &lt;- +100 c &lt;- +250 d &lt;- 7.0/100 # 7.0% e &lt;- (a/(1+d)^1) + (b/(1+d)^2) + (c/(1+d)^3) e # 11.04 ## [1] 11.04451 También es posible solucionar este ejercicio utilizando p.ej. el paquete FinCal de R, de la siguiente forma: if(!require(FinCal)) install.packages(&#39;FinCal&#39;); library(FinCal) ## Loading required package: FinCal ## ## Attaching package: &#39;FinCal&#39; ## The following object is masked from &#39;package:quantmod&#39;: ## ## lineChart ?npv # net present value tasa &lt;- d flujo.de.caja &lt;- c(0, a, b, c) # 0 para el año 0 f &lt;- npv(r = tasa, cf = flujo.de.caja) f ## [1] 11.04451 21.2 Ejercicio 2 21.2.1 Enunciado - parte a Crear un vector vector1 con los números 3 y 4 y convertirlo a un data frame y asignar el resultado a una variable data1 Mostrar el nombre de las columnas del data frame data1 Acceder al primer elemento de este data frame (3) y mostrarlo en la pantalla 21.2.2 Posible solución vector1 &lt;- c(3,4) vector1 ## [1] 3 4 class(vector1) ## [1] &quot;numeric&quot; data1 &lt;- as.data.frame(vector1) # convierte a un data frame data1 # observe el título de la primera columna del data frame ## vector1 ## 1 3 ## 2 4 class(data1) ## [1] &quot;data.frame&quot; colnames(data1) ## [1] &quot;vector1&quot; data1[1, ] ## [1] 3 21.2.3 Enunciado - parte b Crear un vector vector2 con los siguientes tres caracteres 3, 4 y 5 y convertir este vector a un data frame y asignar el resultado a una variable data2 Mostrar el resultado de la conversión, utilizando la función class() 21.2.4 Posible solución vector2 &lt;- c(&quot;3&quot;, &quot;4&quot;, &quot;5&quot;) class(vector2) ## [1] &quot;character&quot; data2 &lt;- as.data.frame(vector2) class(data2) ## [1] &quot;data.frame&quot; 21.2.5 Enunciado - parte c Ahora, convertir el contenido de este data frame data2 (caracteres) al tipo de dato numeric. Es decir, convertir el contenido a tres números y asignar el resultado a una variable data3 Mostrar el resultado de la conversión, utilizando la función class() 21.2.6 Posible solución data3 &lt;- as.numeric(data2[,1]) class(data3) ## [1] &quot;numeric&quot; data3 ## [1] 3 4 5 21.2.7 Enunciado - parte d Crear un vector vector3 con los 6 estratos (seis categorías: 1 a 6), como se utilizan p.ej. en Colombia. Es decir, crear este vector3 de tipo de dato factor Convertir el contenido de este vector al tipo de dato numeric. Es decir, convertir el contenido a seis números y asignar el resultado a una variable data4 Mostrar el resultado de la conversión, utilizando la función class() 21.2.8 Posible solución vector3 &lt;- as.factor(c(1:6)) class(vector3) ## [1] &quot;factor&quot; vector3 ## [1] 1 2 3 4 5 6 ## Levels: 1 2 3 4 5 6 data4 &lt;- as.numeric(vector3) class(data4) ## [1] &quot;numeric&quot; data4 ## [1] 1 2 3 4 5 6 21.2.9 Enunciado - parte e Crear un data frame df10 con dos columnas. La primera columna x debe contener los datos 1, 2 y 3 y la segunda y los datos 4, 5 y 6. Sin embargo, los tres datos de la primera columna deben ser del tipo de dato numeric (numérico). Mientras los tres datos de la segunda columna deben ser del tipo de dato factor (categórica) Ahora convertir los valores de la segunda columna (y), del tipo de dato factor a numeric Mostrar que los valores de la segunda columna y ahora realmente son del tipo de dato numeric 21.2.10 Posible solución x &lt;- 1:3 y &lt;- as.factor(c(4:6)) df10 &lt;- data.frame(x,y) class(df10) ## [1] &quot;data.frame&quot; df10 ## x y ## 1 1 4 ## 2 2 5 ## 3 3 6 #conversión de factor a númerico #df10$y &lt;- as.numeric(df10$y) #df10 #Ojo: ¿Qué pasó aquí? # Respuesta: Si se utiliza la función as.numeric para un factor, esto convertirá los niveles a numéricos, no a los valores reales. Por lo tanto, se necesita adicionalmente la función as.character para convertir primero el factor a character y luego as.numeric df10$y &lt;- as.numeric(as.character(df10$y)) class(df10$y) ## [1] &quot;numeric&quot; df10$y ## [1] 4 5 6 21.3 Ejercicio 3 21.3.1 Enunciado Crear un archivo de tipo CSV con los siguientes datos, distribuidos en cinco filas y 4 columnas, y seperados por punto y coma (;): #;Estrato;Ingresos;Nombre 1;1;100.0;Jaime 2;2;150;María 3;2;140;Paula 4;5;90;Cristina Cargar estos datos desde el archivo csv a una variable dataset10 en R / RStudio. Los datos de las primeras tres columnas deben ser numéricos (int o num) y de la última de tipo character (chr) Mostrar la estructura del dataset10 en la pantalla Cambiar el nombre de la primera columna al texto numero 21.3.2 Posible solución dataset10 &lt;- read.csv(&#39;ejercicio3.csv&#39;, sep = &quot;;&quot;, header = TRUE, stringsAsFactors = FALSE) str(dataset10) ## &#39;data.frame&#39;: 4 obs. of 4 variables: ## $ X. : int 1 2 3 4 ## $ Estrato : int 1 2 2 5 ## $ Ingresos: num 100 150 140 90 ## $ Nombre : chr &quot;Jaime&quot; &quot;María&quot; &quot;Paula&quot; &quot;Cristina&quot; names(dataset10)[1] &lt;- &quot;numero&quot; str(dataset10) ## &#39;data.frame&#39;: 4 obs. of 4 variables: ## $ numero : int 1 2 3 4 ## $ Estrato : int 1 2 2 5 ## $ Ingresos: num 100 150 140 90 ## $ Nombre : chr &quot;Jaime&quot; &quot;María&quot; &quot;Paula&quot; &quot;Cristina&quot; 21.4 Ejercicio 4 21.4.1 Enunciado Analizar el paquete DataExplorer de R para explorar datos Cargar los datos de la siguiente forma: url=http://freakonometrics.free.fr/german_credit.csv dataset &lt;- read.csv(url, header = TRUE, sep = ,) Luego, utilizar el paquete DataExplorer, utilizando la función plot_str() Visualizar los valores faltantes, utilizando una función adecuada del paquete DataExplorer Crear histogramas para (las variables continúas d)el dataset, utilizando una función adecuada del paquete DataExplorer Crear un data frame dataset2, que contiene los valores de las columnas Age..years. y Credit.Amount del dataset Visualizar las correlaciones entre los valores de las columnas Age..years. y Credit.Amount del dataset2 Aplciar la función plot_bar del paquete DataExplorer al dataset 21.4.2 Posible solución url=&quot;http://freakonometrics.free.fr/german_credit.csv&quot; dataset &lt;- read.csv(url, header = TRUE, sep = &quot;,&quot;) if(!require(DataExplorer)) install.packages(&#39;DataExplorer&#39;); library(DataExplorer) ## Loading required package: DataExplorer plot_str(dataset) plot_missing(dataset) plot_histogram(dataset) col &lt;- c(&quot;Credit.Amount&quot;, &quot;Age..years.&quot;) dataset2 &lt;- dataset[col] plot_correlation(dataset2) plot_bar(dataset) 21.5 Ejercicio 5 21.5.1 Enunciado Cargar el paquete tidyverse Utilizar el conjunto de datos iris, que se instaló con R: data(iris) Ver la siguiente descripción al respecto: https://es.wikipedia.org/wiki/Conjunto_de_datos_flor_iris Mostrar las primeras 5 filas de iris en la pantalla Agrupar los datos de iris por la columna Species y asignar el resultado a una variable iris.por.species, utilizando tidyverse Mostrar las últimas 3 filas de iris.por.species Agregar una columna a iris.por.species, donde se muestra el valor promedio para los valores de la columna Sepal.Length, utilizando tidyverse 21.5.2 Posible solución library(tidyverse) data(iris) head(iris, 5) iris.por.species &lt;- iris %&gt;% group_by(Species) tail(iris.por.species, 3) iris.por.species &lt;- iris.por.species %&gt;% summarize(promedio = mean(Sepal.Length)) tail(iris.por.species, 3) 21.6 Ejercicio 6 21.6.1 Enunciado Utilizar el conjunto de datos iris, que se instaló con R: data(iris) Ver la siguiente descripción al respecto: https://es.wikipedia.org/wiki/Conjunto_de_datos_flor_iris Mostrar las primeras 5 filas de iris en la pantalla Utilizando la función apply, calcular el promedio de cada columna del dataset iris, que contiene números Realizar el mismo cálculo, utilizando la función lapply (en lugar de apply()) Con base en los resultados obtenidos, explicar la diferencia entre apply y lapply Ahora bien, realizar el mismo cálculo (promedio de las columnas), pero utilizando un ciclo (bucle), aplicando la función for() 21.6.2 Posible solución data(iris) head(iris, 5) ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 1 5.1 3.5 1.4 0.2 setosa ## 2 4.9 3.0 1.4 0.2 setosa ## 3 4.7 3.2 1.3 0.2 setosa ## 4 4.6 3.1 1.5 0.2 setosa ## 5 5.0 3.6 1.4 0.2 setosa str(iris) ## &#39;data.frame&#39;: 150 obs. of 5 variables: ## $ Sepal.Length: num 5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ... ## $ Sepal.Width : num 3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ... ## $ Petal.Length: num 1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ... ## $ Petal.Width : num 0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ... ## $ Species : Factor w/ 3 levels &quot;setosa&quot;,&quot;versicolor&quot;,..: 1 1 1 1 1 1 1 1 1 1 ... apply(iris[,-5], 2, mean, na.rm=TRUE) ## Sepal.Length Sepal.Width Petal.Length Petal.Width ## 5.843333 3.057333 3.758000 1.199333 lapply(iris[,-5], mean, na.rm=TRUE) ## $Sepal.Length ## [1] 5.843333 ## ## $Sepal.Width ## [1] 3.057333 ## ## $Petal.Length ## [1] 3.758 ## ## $Petal.Width ## [1] 1.199333 Observe: lapply devuelve una lista, mientras apply devuelve un vector con los resultados Utilizando for en lugar de apply(): output &lt;- NULL # un vector vacío n &lt;- ncol(iris) # número de columnas for(i in 1:(n-1)){ output[i] &lt;- mean(iris[,i]) } print(output) ## [1] 5.843333 3.057333 3.758000 1.199333 21.7 Ejercicio 7 21.7.1 Enunciado Generar en R 15 números aleatorios, con base en una distribución uniforme, entre 1 (minimum) y 50 (máximum) y asignar el resultado a una variable vector.aleatorio1 Luego, generar en R otros 15 numeros aleatorios, con base en una distribución normal, con una media de 0 y una desviación estándar de 1, y asignar el resultado a una variable vector.aleatorio2 Cobinar los valores de los 2 vectores en un único vector vector.aleatorio3 en R / RStudio Realizar el ajuste a la distribución, utilizando el paquete rriskDistributions 21.7.2 Posible solución vector.aleatorio1 &lt;- runif(15, 1, 50) str(vector.aleatorio1) ## num [1:15] 17.2 42.3 24 30.5 42.2 ... vector.aleatorio2 &lt;- rnorm(15, mean = 0, sd = 1) str(vector.aleatorio2) ## num [1:15] -0.342 0.948 0.626 0.275 -0.342 ... vector.aleatorio3 &lt;- c(vector.aleatorio1, vector.aleatorio2) str(vector.aleatorio3) ## num [1:30] 17.2 42.3 24 30.5 42.2 ... library(rriskDistributions) res &lt;- fit.cont(vector.aleatorio3) ## ## Begin fitting distributions --------------------------------------- ## * fitting normal distribution ... OK ## * fitting Cauchy distribution ... OK ## * fitting logistic distribution ... OK ## * fitting beta distribution ... failed ## * fitting exponential distribution ... failed ## * fitting chi-square distribution ... failed ## * fitting uniform distribution ... OK ## * fitting gamma distribution ... failed ## * fitting lognormal distribution ... failed ## * fitting Weibull distribution ... failed ## * fitting F-distribution ... failed ## * fitting Student&#39;s t-distribution ... OK ## * fitting Gompertz distribution ... failed ## * fitting triangular distribution ... failed ## End fitting distributions ----------------------------------------- ## logL AIC BIC Chisq(value) Chisq(p) AD(value) H(AD) ## Normal -124.52 253.05 255.85 122.07 0 2.50 rejected ## Cauchy -124.53 253.05 255.85 55.19 0 8.06 rejected ## Logistic -124.97 253.93 256.74 109.81 0 2.29 rejected ## Uniform NULL NULL NULL 124.51 0 Inf NULL ## Student -120.82 243.65 245.05 41.43 0 8.83 NULL ## KS(value) H(KS) ## Normal 0.27 rejected ## Cauchy 0.31 rejected ## Logistic 0.23 not rejected ## Uniform 0.24 not rejected ## Student 0.33 rejected ## ## Chosen continuous distribution is: NA ## Fitted parameters are: ## [1] NA 21.8 Ejercicio 8 21.8.1 Enunciado Si se requiere saber, cuántas personas de una región están dispuestas de trabajar en el extranjero, y si se puede asumir que la población de la región que trabaja o puede trabajar es de 50 mil personas, ¿qué tan grande debe ser la muestra para una encuesta que busca determinar esta disposición para trabajar en otro país? Asumimos para la generación de esta muestra que el margen de error es de 5% y el nivel de confianza requerido es de 95%. P y Q son 0.5 21.8.2 Posible solución # para poblaciones menor a 100000 muestra.n &lt;- function(N, P, Q, Z, E){ ((Z^2)*P*Q*N) / ((E^2)*(N-1)+(Z^2)*P*Q) } muestra.n(50000, 0.5, 0.5, 1.96, 0.05) ## [1] 381.2385 Respuesta: La muestra debe tener 382 personas 21.9 Ejercicio 9 21.9.1 Enunciado Realizar un árbol decisión en R, utilizando el paquete ISLR y el dataset Smarket, que viene con este paquete, para clasificar los datos del dataset con el objetivo de determinar, si el mercado (índice S&amp;P500) va a subir o bajar. Mostrar las primeras 3 filas de este dataset Smarket y analizar de esta forma las columnas (variables) del dataset. Nota: Las variables Lag.. se refieren a precios determinados en el mercado de capitales (S&amp;P Stock Market Data) y refleja rendimientos diarios de este índice búrsatil, expresado como porcentaje. Utilizar el comando ?Smarket para consultar las páginas de ayuda al respecto Mostrar, la estructura de este dataset, utilizando la función str() Utilizando la semilla 123 (set.seed(123)), dividir los datos en una parte de entrenamiento (train_data) y otra parte de pruebas (test_data). 66% del total de los datos se deben utilizar para el entrenamiento y el resto para las pruebas Analizar el paquete C50, que permite construir un árbol de decisión Construir un árbol de decisión sencillo con el nombre modelo.AD, utilizando el paquete C50 (con C mayúscula), la función C50() y los datos de entrenamiento Mostrar los resultados (output), utilizando la función summary() y analizarlos Realizar la predicción, utilizando el modelo construido y los datos de prueba (test_data), asignando el resultado a una variable pred Mostrar el resultado de la clasificación en una tabla, utilizando p.ej. la función table() Interpretar el resultado obtenido 21.9.2 Posible Solución if(!require(ISLR)) install.packages(&#39;ISLR&#39;); library(ISLR) ## Loading required package: ISLR head(Smarket, n=3) ## Year Lag1 Lag2 Lag3 Lag4 Lag5 Volume Today Direction ## 1 2001 0.381 -0.192 -2.624 -1.055 5.010 1.1913 0.959 Up ## 2 2001 0.959 0.381 -0.192 -2.624 -1.055 1.2965 1.032 Up ## 3 2001 1.032 0.959 0.381 -0.192 -2.624 1.4112 -0.623 Down str(Smarket) # 1250 registros y ## &#39;data.frame&#39;: 1250 obs. of 9 variables: ## $ Year : num 2001 2001 2001 2001 2001 ... ## $ Lag1 : num 0.381 0.959 1.032 -0.623 0.614 ... ## $ Lag2 : num -0.192 0.381 0.959 1.032 -0.623 ... ## $ Lag3 : num -2.624 -0.192 0.381 0.959 1.032 ... ## $ Lag4 : num -1.055 -2.624 -0.192 0.381 0.959 ... ## $ Lag5 : num 5.01 -1.055 -2.624 -0.192 0.381 ... ## $ Volume : num 1.19 1.3 1.41 1.28 1.21 ... ## $ Today : num 0.959 1.032 -0.623 0.614 0.213 ... ## $ Direction: Factor w/ 2 levels &quot;Down&quot;,&quot;Up&quot;: 2 2 1 2 2 2 1 2 2 2 ... # nota: la variable de salida (de predicción) es de tipo factor # Particionar los datos en dos partes 66/34 set.seed(123) d = sort(sample(nrow(Smarket),nrow(Smarket)*0.66, replace=FALSE)) # dividir en una conjunto de training y test set train_data &lt;- Smarket[d, ] test_data &lt;- Smarket[-d, ] library(C50) ?C5.0 # crear el árbol de decisión con los datos de entrenamiento modelo.DT &lt;- C5.0(x = train_data[, -9], y = train_data$Direction) # excluye la columna de la variable de predicción summary(modelo.DT) ## ## Call: ## C5.0.default(x = train_data[, -9], y = train_data$Direction) ## ## ## C5.0 [Release 2.07 GPL Edition] Mon Jan 31 15:53:58 2022 ## ------------------------------- ## ## Class specified by attribute `outcome&#39; ## ## Read 825 cases (9 attributes) from undefined.data ## ## Decision tree: ## ## Today &lt;= -0.001: Down (396) ## Today &gt; -0.001: Up (429) ## ## ## Evaluation on training data (825 cases): ## ## Decision Tree ## ---------------- ## Size Errors ## ## 2 0( 0.0%) &lt;&lt; ## ## ## (a) (b) &lt;-classified as ## ---- ---- ## 396 (a): class Down ## 429 (b): class Up ## ## ## Attribute usage: ## ## 100.00% Today ## ## ## Time: 0.0 secs #Realizar la predicción con los datos de prueba pred &lt;- predict(modelo.DT, test_data) # crear la matriz de clasificación library(gmodels) CrossTable(test_data$Direction, pred) ## ## ## Cell Contents ## |-------------------------| ## | N | ## | Chi-square contribution | ## | N / Row Total | ## | N / Col Total | ## | N / Table Total | ## |-------------------------| ## ## ## Total Observations in Table: 425 ## ## ## | pred ## test_data$Direction | Down | Up | Row Total | ## --------------------|-----------|-----------|-----------| ## Down | 206 | 0 | 206 | ## | 112.849 | 106.151 | | ## | 1.000 | 0.000 | 0.485 | ## | 1.000 | 0.000 | | ## | 0.485 | 0.000 | | ## --------------------|-----------|-----------|-----------| ## Up | 0 | 219 | 219 | ## | 106.151 | 99.849 | | ## | 0.000 | 1.000 | 0.515 | ## | 0.000 | 1.000 | | ## | 0.000 | 0.515 | | ## --------------------|-----------|-----------|-----------| ## Column Total | 206 | 219 | 425 | ## | 0.485 | 0.515 | | ## --------------------|-----------|-----------|-----------| ## ## #Alternativa table(test_data$Direction, pred) ## pred ## Down Up ## Down 206 0 ## Up 0 219 Respuesta: Todo el modelo está dominado por la variable today. Por favor, revisarlo. 21.10 Ejercicio 10 21.10.1 Enunciado Realizar una regresión logística en R, utilizando el paquete ISLR y el dataset Smarket, que viene con este paquete, para clasificar los datos del dataset con el objetivo de determinar, si el mercado (índice S&amp;P500) va a subir o bajar. Mostrar las primeras 3 filas de este dataset Smarket y analizar de esta forma las columnas (variables) del dataset. Nota: Las variables Lag.. se refieren a precios determinados en el mercado de capitales (S&amp;P Stock Market Data) y refleja rendimientos diarios de este índice búrsatil, expresado como porcentaje. Utilizar el comando ?Smarket para consultar las páginas de ayuda al respecto Mostrar, la estructura de este dataset, utilizando la función str() Utilizando la semilla 123 (set.seed(123)), dividir los datos en una parte de entrenamiento (train_data) y otra parte de pruebas (test_data). 66% del total de los datos se deben utilizar para el entrenamiento y el resto para las pruebas Realizar un modelo de regresión logística con los datos de entrenamiento, utilizando como variables de entrada únicamente las variables Lag1, Lag2 y Lag3. Asignar el resultado a una variable modelo.logit, Nota: En este caso no se preocupe de los valores p (p-values) obtenidos para las tres variables de entrada Mostrar el resultado de la regresión en la pantalla, utilizando la función summary() para el modelo de la regresión generada Luego, realizar la predicción para el S&amp;P500, utilizando el modelo generado y los datos de prueba (test_data) y asignar el resultado (probabilidades) a una variable probs Si las probabilidades son mayores que 0.5, asignar el valor 1, en el caso contrario el valor 0 Mostrar el resultado de la clasificación en una tabla, utilizando p.ej. la función table() Interpretar el resultado obtenido 21.10.2 Posible solución library(ISLR) head(Smarket) ## Year Lag1 Lag2 Lag3 Lag4 Lag5 Volume Today Direction ## 1 2001 0.381 -0.192 -2.624 -1.055 5.010 1.1913 0.959 Up ## 2 2001 0.959 0.381 -0.192 -2.624 -1.055 1.2965 1.032 Up ## 3 2001 1.032 0.959 0.381 -0.192 -2.624 1.4112 -0.623 Down ## 4 2001 -0.623 1.032 0.959 0.381 -0.192 1.2760 0.614 Up ## 5 2001 0.614 -0.623 1.032 0.959 0.381 1.2057 0.213 Up ## 6 2001 0.213 0.614 -0.623 1.032 0.959 1.3491 1.392 Up str(Smarket) # 1250 registros ## &#39;data.frame&#39;: 1250 obs. of 9 variables: ## $ Year : num 2001 2001 2001 2001 2001 ... ## $ Lag1 : num 0.381 0.959 1.032 -0.623 0.614 ... ## $ Lag2 : num -0.192 0.381 0.959 1.032 -0.623 ... ## $ Lag3 : num -2.624 -0.192 0.381 0.959 1.032 ... ## $ Lag4 : num -1.055 -2.624 -0.192 0.381 0.959 ... ## $ Lag5 : num 5.01 -1.055 -2.624 -0.192 0.381 ... ## $ Volume : num 1.19 1.3 1.41 1.28 1.21 ... ## $ Today : num 0.959 1.032 -0.623 0.614 0.213 ... ## $ Direction: Factor w/ 2 levels &quot;Down&quot;,&quot;Up&quot;: 2 2 1 2 2 2 1 2 2 2 ... set.seed(123) d = sort(sample(nrow(Smarket),nrow(Smarket)*0.66, replace=FALSE)) # dividir en una conjunto de training y test set train_data &lt;- Smarket[d, ] test_data &lt;- Smarket[-d, ] modelo.logit &lt;- glm(Direction ~ Lag1 + Lag2 + Lag3, family = binomial(&quot;logit&quot;), data =train_data) summary(modelo.logit) ## ## Call: ## glm(formula = Direction ~ Lag1 + Lag2 + Lag3, family = binomial(&quot;logit&quot;), ## data = train_data) ## ## Deviance Residuals: ## Min 1Q Median 3Q Max ## -1.463 -1.203 1.039 1.140 1.465 ## ## Coefficients: ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) 0.08448 0.06997 1.207 0.2273 ## Lag1 -0.12569 0.06256 -2.009 0.0445 * ## Lag2 -0.02529 0.05985 -0.423 0.6726 ## Lag3 0.02817 0.06108 0.461 0.6447 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 1142.4 on 824 degrees of freedom ## Residual deviance: 1137.9 on 821 degrees of freedom ## AIC: 1145.9 ## ## Number of Fisher Scoring iterations: 3 # probabilidades: probs &lt;- predict(modelo.logit, test_data, type = &quot;response&quot;) head(probs) ## 3 5 6 10 11 14 ## 0.4853155 0.5130299 0.5061573 0.4771843 0.5040527 0.4974412 prediccion &lt;- ifelse(probs &gt; 0.5, 1, 0) table(prediccion, test_data$Direction) ## ## prediccion Down Up ## 0 46 53 ## 1 160 166 mean(prediccion) # [1] 0.7670588 ## [1] 0.7670588 Conclusión: El modelo comete muchos errores. 21.11 Ejercicio 11 21.11.1 Enunciado Utilizar el paquete ISLR y el dataset Smarket, que viene con este paquete, y escalar los datos de la columna Lag1 de este dataset, utilizando el paquete scales, y asignar el resultado a una variable Lag1.scaled Mostrar las últimas 10 filas del resultado en la pantalla 21.11.2 Posible solución if(!require(ISRL)) install.packages(&#39;ISLR&#39;); library(ISLR) ## Loading required package: ISRL ## Warning in library(package, lib.loc = lib.loc, character.only = TRUE, ## logical.return = TRUE, : there is no package called &#39;ISRL&#39; ## Warning: package &#39;ISLR&#39; is in use and will not be installed head(Smarket) ## Year Lag1 Lag2 Lag3 Lag4 Lag5 Volume Today Direction ## 1 2001 0.381 -0.192 -2.624 -1.055 5.010 1.1913 0.959 Up ## 2 2001 0.959 0.381 -0.192 -2.624 -1.055 1.2965 1.032 Up ## 3 2001 1.032 0.959 0.381 -0.192 -2.624 1.4112 -0.623 Down ## 4 2001 -0.623 1.032 0.959 0.381 -0.192 1.2760 0.614 Up ## 5 2001 0.614 -0.623 1.032 0.959 0.381 1.2057 0.213 Up ## 6 2001 0.213 0.614 -0.623 1.032 0.959 1.3491 1.392 Up str(Smarket) # 1250 registros ## &#39;data.frame&#39;: 1250 obs. of 9 variables: ## $ Year : num 2001 2001 2001 2001 2001 ... ## $ Lag1 : num 0.381 0.959 1.032 -0.623 0.614 ... ## $ Lag2 : num -0.192 0.381 0.959 1.032 -0.623 ... ## $ Lag3 : num -2.624 -0.192 0.381 0.959 1.032 ... ## $ Lag4 : num -1.055 -2.624 -0.192 0.381 0.959 ... ## $ Lag5 : num 5.01 -1.055 -2.624 -0.192 0.381 ... ## $ Volume : num 1.19 1.3 1.41 1.28 1.21 ... ## $ Today : num 0.959 1.032 -0.623 0.614 0.213 ... ## $ Direction: Factor w/ 2 levels &quot;Down&quot;,&quot;Up&quot;: 2 2 1 2 2 2 1 2 2 2 ... library(scales) Lag1.scaled &lt;- scale(Smarket$Lag1) tail(Lag1.scaled, n=10) ## [,1] ## [1241,] -0.12746154 ## [1242,] -0.25418877 ## [1243,] -0.51732377 ## [1244,] -0.02449567 ## [1245,] 0.21839818 ## [1246,] 0.36800671 ## [1247,] 0.03446769 ## [1248,] -0.84382238 ## [1249,] 0.11103206 ## [1250,] -0.26562942 "],["palabras-finales.html", "Sección 22 Palabras finales", " Sección 22 Palabras finales Terminamos una breve introducción a R con un enfoque financiero y adminstrativo, presentando ejemplos de código al respecto. Ojála, el contenido del librito sea una ayuada para aumentar su productividad. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
